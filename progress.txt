# Ralph Progress Log
Started: Mon Feb 17 2026

## Codebase Patterns
- New packages follow hatchling pattern: `packages = ["src/orbiter"]` in pyproject.toml, no top-level `orbiter/__init__.py` needed (orbiter-core's `pkgutil.extend_path()` handles namespace)
- Add new packages to root pyproject.toml in 3 places: `[tool.uv.workspace] members`, `[dependency-groups] dev`, and `[tool.uv.sources]`
- Streaming event types are frozen Pydantic BaseModels in `packages/orbiter-core/src/orbiter/types.py`
- Use `model_config = {"frozen": True}` for all event types
- `StreamEvent` is a Union type alias at the bottom of `types.py` — all new event types must be added to it
- Existing `TextEvent` and `ToolCallEvent` use `agent_name: str = ""` as default
- The stale `test_streaming_events.py` was rewritten in US-002 with correct PRD field names — future event types (US-003) should add tests to this file
- `_stream()` in `runner.py` uses `detailed=True` to enable rich events — when adding Swarm streaming (US-005), pass `detailed` through to the per-agent stream call
- `StreamChunk` has a `usage` field (populated on final chunk with `total_tokens > 0`) — use this to build `UsageEvent`
- `agent._execute_tools()` wraps errors with "Tool 'X' failed: " prefix — test error messages with `in` not `==`
- Stream tests use `_FakeStreamChunk`, `_FakeToolCallDelta`, `_make_stream_provider` helpers in `test_runner.py` (also duplicated in `test_swarm.py`)
- Agent model string is at `agent.model` (may be empty string or None) — use `getattr(agent, "model", "") or ""`
- Swarm streaming collects text from `TextEvent` objects for output chaining — avoids double LLM execution
- `run.stream()` detects Swarm via `hasattr(agent, 'flow_order')` and delegates to `Swarm.stream()`, same pattern as `run()`
- Swarm `stream()` imports `run` inside methods to avoid circular imports (runner.py → swarm.py cycle)
- Event filtering via `event_types: set[str] | None` — Swarm workflow/handoff must filter at yield points (not inner `run.stream()`) to preserve TextEvent collection for output chaining
- Distributed models use `StrEnum` (not `str, Enum`) per ruff UP042, and frozen Pydantic BaseModels with `Field(default_factory=...)` for mutable defaults
- Distributed package exports from `orbiter.distributed.__init__` — update `__all__` when adding new public types
- Use `# pyright: ignore[reportMissingImports]` on all `from orbiter.distributed.*` imports in source and test files — pyright can't resolve namespace packages across workspace members (same pattern as orbiter-observability)
- fakeredis.aioredis.FakeRedis(decode_responses=True) for Redis integration tests — supports Streams (XADD/XREADGROUP/XACK/XRANGE)
- TaskBroker uses Redis Streams consumer groups: `{queue_name}:group` as group name, worker_id as consumer name, `>` for new messages
- TaskBroker._pending_ids maps task_id → stream message_id for ack/nack correlation
- Redis hash/set async operations (HSET, HGETALL, EXPIRE, SADD, SMEMBERS) need `# type: ignore[misc]` for pyright — type stubs don't properly annotate these as awaitable (unlike Streams operations which work fine)
- Agent/Swarm serialization: `to_dict()`/`from_dict()` in agent.py/swarm.py — tools as dotted paths, handoffs recursive, non-serializable items (closures, hooks, memory, context) raise ValueError
- Tool serialization helpers: `_serialize_tool()`, `_deserialize_tool()`, `_import_object()` in agent.py — reuse these for any import-by-dotted-path needs
- `_EVENT_TYPE_MAP` in `events.py` maps type discriminator → event class for deserialization; `_deserialize_event()` reconstructs `StreamEvent` from JSON dict
- EventPublisher publishes to both Pub/Sub (`orbiter:events:{task_id}`) and Stream (`orbiter:stream:{task_id}`) — Pub/Sub for live, Stream for replay
- EventSubscriber `subscribe()` terminates on terminal StatusEvent (completed/error/cancelled)
- Worker imports `Agent`, `Swarm`, `run`, `TextEvent` inside methods (local imports) to avoid circular deps and pyright issues — patch at source (`orbiter.agent.Agent`, `orbiter.swarm.Swarm`, `orbiter.runner.run`) not at `orbiter.distributed.worker.X` in tests
- Worker heartbeat uses a separate Redis connection — published to `orbiter:workers:{worker_id}` hash with TTL
- `contextlib.suppress(asyncio.CancelledError)` preferred over try/except/pass per ruff SIM105

---

## 2026-02-17 - US-001
- Added `StepEvent` frozen Pydantic BaseModel to `orbiter/types.py`
- Fields: `type: Literal["step"]`, `step_number: int`, `agent_name: str`, `status: Literal["started", "completed"]`, `started_at: float`, `completed_at: float | None`, `usage: Usage | None`
- Updated `StreamEvent` union to include `StepEvent`
- Files changed: `packages/orbiter-core/src/orbiter/types.py`
- **Learnings for future iterations:**
  - Follow the exact frozen BaseModel pattern: `model_config = {"frozen": True}`, type literal with default, required fields first, optional fields with defaults
  - `StreamEvent` union is a simple type alias (not Annotated/Discriminated) — just add `| NewType` at the end
  - There's a pre-existing `packages/orbiter-core/tests/test_streaming_events.py` that uses wrong field names (e.g., `step_num` instead of `step_number`). It needs to be rewritten to match PRD specs in a later story.
  - All 682 existing orbiter-core tests pass with the change — no downstream breakage
---

## 2026-02-17 - US-002
- Added `ToolResultEvent` frozen Pydantic BaseModel to `orbiter/types.py`
- Fields: `type: Literal["tool_result"]`, `tool_name: str`, `tool_call_id: str`, `arguments: dict[str, Any]`, `result: str`, `error: str | None`, `success: bool`, `duration_ms: float`, `agent_name: str`
- Updated `StreamEvent` union to include `ToolResultEvent`
- Rewrote stale `test_streaming_events.py` with correct PRD field names (11 tests)
- Files changed: `packages/orbiter-core/src/orbiter/types.py`, `packages/orbiter-core/tests/test_streaming_events.py`
- **Learnings for future iterations:**
  - The stale test file has been rewritten — US-003 should add new test classes to `test_streaming_events.py` for ReasoningEvent, ErrorEvent, StatusEvent, UsageEvent
  - Required fields for ToolResultEvent are only `tool_name` and `tool_call_id` — all others have sensible defaults
  - `arguments` uses `Field(default_factory=dict)` to avoid mutable default sharing
  - All 693 orbiter-core tests pass (11 new + 682 existing)
---

## 2026-02-17 - US-003
- Added four new streaming event types to `orbiter/types.py`: `ReasoningEvent`, `ErrorEvent`, `StatusEvent`, `UsageEvent`
- `ReasoningEvent`: `type: Literal["reasoning"]`, `text: str`, `agent_name: str`
- `ErrorEvent`: `type: Literal["error"]`, `error: str`, `error_type: str`, `agent_name: str`, `step_number: int | None`, `recoverable: bool`
- `StatusEvent`: `type: Literal["status"]`, `status: Literal["starting", "running", "waiting_for_tool", "completed", "cancelled", "error"]`, `agent_name: str`, `message: str`
- `UsageEvent`: `type: Literal["usage"]`, `usage: Usage`, `agent_name: str`, `step_number: int`, `model: str`
- Updated `StreamEvent` union to include all 8 event types
- Added 24 new tests across 4 test classes + updated union test class (32 total in file)
- Files changed: `packages/orbiter-core/src/orbiter/types.py`, `packages/orbiter-core/tests/test_streaming_events.py`
- **Learnings for future iterations:**
  - `StatusEvent.status` uses a Literal union with 6 values — invalid values correctly rejected by Pydantic validation
  - `UsageEvent` embeds the existing `Usage` model — `.model_dump()` correctly nests it as a dict
  - All required fields for new types: `ReasoningEvent(text)`, `ErrorEvent(error, error_type)`, `StatusEvent(status)`, `UsageEvent(usage)` — rest have defaults
  - Total orbiter-core tests now: 714 (32 streaming + 682 existing)
---

## 2026-02-17 - US-004
- Added `detailed=True` parameter to `_stream()` in `runner.py`
- When `detailed=False` (default): only `TextEvent` and `ToolCallEvent` emitted (backward compatible)
- When `detailed=True`: emits `StatusEvent('starting')` at start, `StepEvent(status='started')` before each LLM call, `UsageEvent` after each LLM call, `ToolCallEvent` for each tool call, `ToolResultEvent` after each tool execution, `StepEvent(status='completed')` at step end, `StatusEvent('completed')` at finish
- `ErrorEvent` emitted on errors regardless of `detailed` flag, re-raises after yielding
- When `detailed=True` and error occurs, also emits `StatusEvent(status='error')`
- Added 18 new tests across 6 test classes: `TestRunStreamDetailedFalse` (2), `TestRunStreamDetailedText` (2), `TestRunStreamDetailedToolCalls` (4), `TestRunStreamDetailedUsage` (2), `TestRunStreamDetailedErrors` (3), `TestRunStreamDetailedStepNumbers` (1)
- Files changed: `packages/orbiter-core/src/orbiter/runner.py`, `packages/orbiter-core/tests/test_runner.py`
- **Learnings for future iterations:**
  - `StreamChunk.usage` is a `Usage` object (not None) — check `total_tokens > 0` to detect actual usage data
  - Usage is typically only on the final chunk — capture it during the stream loop and emit `UsageEvent` after the loop ends
  - Tools execute in parallel via `asyncio.TaskGroup()` — individual tool timing isn't available, so duration is split evenly across tools
  - Error handling in `_stream()` wraps each step in try/except — yields `ErrorEvent` then re-raises to let caller handle
  - `agent.model` attribute holds the model string for `UsageEvent.model` field
  - Total orbiter-core tests now: 728 (37 runner + 32 streaming + 659 other)
---

## 2026-02-17 - US-005
- Added `stream()` method to `Swarm` class with streaming variants for all three modes: workflow, handoff, and team
- Workflow streaming: agents run sequentially, text is collected from `TextEvent` objects for output→input chaining (avoids double execution)
- Handoff streaming: agents delegate dynamically, text collected from `TextEvent` for handoff detection via lightweight `RunResult`
- Team streaming: lead agent streams with delegate tools added temporarily, tools restored after execution (including on error)
- `StatusEvent(status='running')` emitted for each agent transition (workflow steps, handoff transitions, team lead start)
- Handoff streaming emits `StatusEvent` with "Handoff from 'X' to 'Y'" message for agent transitions
- Updated `_stream()` in `runner.py` to detect Swarm via `hasattr(agent, 'flow_order')` and delegate to `Swarm.stream()`
- All events include the correct `agent_name` of the sub-agent that produced them
- Added 14 new test cases across 5 test classes: `TestSwarmStreamWorkflow` (4), `TestSwarmStreamHandoff` (4), `TestSwarmStreamTeam` (4), `TestSwarmStreamUnsupportedMode` (1), `TestSwarmStreamViaRun` (1)
- Files changed: `packages/orbiter-core/src/orbiter/swarm.py`, `packages/orbiter-core/src/orbiter/runner.py`, `packages/orbiter-core/tests/test_swarm.py`
- **Learnings for future iterations:**
  - Key design: collect text from `TextEvent` objects during streaming to avoid double LLM execution (no need for separate non-streaming `call_runner` call)
  - `_detect_handoff()` works with a lightweight `RunResult(output=text)` — just needs `.output` for string matching
  - Swarm's `stream()` uses `from orbiter.runner import run` inside methods to avoid circular imports (runner.py imports from swarm indirectly)
  - Team mode streaming must restore lead tools in a `try/finally` block, same as the non-streaming `_run_team()`
  - Stream test helpers (`_FakeStreamChunk`, `_FakeToolCallDelta`, `_make_stream_provider`) duplicated from `test_runner.py` — consider extracting to a shared conftest.py if more tests need them
  - Total orbiter-core tests now: 742 (37 runner + 32 streaming + 62 swarm + 611 other)
---

## 2026-02-17 - US-006
- Added `event_types: set[str] | None` parameter to `_stream()` in `runner.py`
- When `event_types` is provided, only events whose `type` field matches are yielded
- When `event_types` is `None` (default), all events pass through (respecting `detailed` flag)
- Added `event_types` parameter to `Swarm.stream()` and all three mode methods (`_stream_workflow`, `_stream_handoff`, `_stream_team`)
- Swarm workflow/handoff modes: filtering applied at yield points while still collecting TextEvent text for output chaining (inner `run.stream()` called unfiltered)
- Swarm team mode: `event_types` passed through to inner `run.stream()` (no text collection needed)
- Added 8 new tests in `TestRunStreamEventFiltering` class covering: single type filter, tool_result filter, multiple types, None passthrough, empty set, without detailed, error filtering, error inclusion
- Files changed: `packages/orbiter-core/src/orbiter/runner.py`, `packages/orbiter-core/src/orbiter/swarm.py`, `packages/orbiter-core/tests/test_runner.py`
- **Learnings for future iterations:**
  - Swarm workflow/handoff modes need unfiltered access to TextEvents for output chaining — don't pass `event_types` to inner `run.stream()`, filter at the Swarm level instead
  - Swarm team mode doesn't collect text, so it's safe to pass `event_types` through to inner `run.stream()`
  - All event types have a `.type` string attribute (e.g., `"text"`, `"tool_call"`, `"status"`) which is the discriminator used for filtering
  - The `_passes_filter` helper pattern: `event_types is None or event.type in event_types` is clean and reusable
  - Total orbiter-core tests now: 750 (45 runner + 32 streaming + 62 swarm + 611 other)
---

## 2026-02-17 - US-007
- Created `orbiter-distributed` package scaffold at `packages/orbiter-distributed/`
- `pyproject.toml` follows hatchling pattern from orbiter-observability: `packages = ["src/orbiter"]`
- Dependencies: `orbiter-core`, `redis[hiredis]>=5.0`
- Optional deps: `[temporal]` with `temporalio>=1.7`, `[test]` with `pytest`, `pytest-asyncio`, `fakeredis[lua]`
- Created `src/orbiter/distributed/__init__.py` with `__all__` placeholder
- No separate `orbiter/__init__.py` needed — orbiter-core's `pkgutil.extend_path()` handles namespace sharing
- Created `README.md` placeholder (required by hatchling)
- Added to root `pyproject.toml`: workspace member, dev dependency, uv source, and `fakeredis[lua]` to dev deps
- Created `tests/` directory for future test files
- Package installs cleanly with `uv sync`, pyright passes, ruff passes, all 750 existing tests pass
- Files changed: `packages/orbiter-distributed/pyproject.toml`, `packages/orbiter-distributed/src/orbiter/distributed/__init__.py`, `packages/orbiter-distributed/README.md`, `pyproject.toml`
- **Learnings for future iterations:**
  - Namespace packages in this monorepo work via hatchling's `packages = ["src/orbiter"]` — no top-level `orbiter/__init__.py` needed in sub-packages
  - `orbiter-core`'s `orbiter/__init__.py` has `pkgutil.extend_path()` which enables namespace package splitting across packages
  - Root `pyproject.toml` needs updates in 3 sections when adding a new package: `[tool.uv.workspace] members`, `[dependency-groups] dev`, `[tool.uv.sources]`
  - `fakeredis[lua]` added to root dev deps since it's needed for Redis Stream tests (Streams use Lua scripting internally)
---

## 2026-02-17 - US-009
- Created `TaskPayload`, `TaskResult`, and `TaskStatus` models in `orbiter/distributed/models.py`
- `TaskStatus` is a `StrEnum` with 6 values: PENDING, RUNNING, COMPLETED, FAILED, CANCELLED, RETRYING
- `TaskPayload` is a frozen Pydantic BaseModel with auto-generated `task_id` (uuid4().hex), `agent_config`, `input`, `messages`, `model`, `detailed`, `metadata`, `created_at`, `timeout_seconds`
- `TaskResult` is a frozen Pydantic BaseModel with `task_id`, `status`, `result`, `error`, `started_at`, `completed_at`, `worker_id`, `retries`
- Updated `__init__.py` to export `TaskPayload`, `TaskResult`, `TaskStatus`
- Added 15 tests covering defaults, custom fields, frozen enforcement, JSON serialization round-trips, and all statuses
- Files changed: `packages/orbiter-distributed/src/orbiter/distributed/models.py`, `packages/orbiter-distributed/src/orbiter/distributed/__init__.py`, `packages/orbiter-distributed/tests/test_models.py`
- **Learnings for future iterations:**
  - Use `StrEnum` (not `str, Enum`) per ruff UP042 rule
  - `uuid4().hex` gives a 32-char hex string without dashes — good for task IDs
  - `Field(default_factory=dict)` and `Field(default_factory=list)` for mutable defaults in frozen models
  - All distributed models are in `orbiter.distributed.models` and re-exported from `orbiter.distributed.__init__`
  - Tests at `packages/orbiter-distributed/tests/test_models.py` — use `uv run pytest` to execute
  - Total tests: 765 (15 new distributed + 750 existing)
---

## 2026-02-17 - US-008
- Created `TaskBroker` class in `orbiter/distributed/broker.py` backed by Redis Streams
- Constructor: `TaskBroker(redis_url, *, queue_name='orbiter:tasks', max_retries=3)`
- `connect()` creates Redis client via `redis.asyncio.from_url()` and ensures consumer group exists (XGROUP CREATE with MKSTREAM)
- `disconnect()` closes the Redis connection
- `submit(task)` serializes TaskPayload to JSON and adds to stream via XADD, returns task_id
- `claim(worker_id, *, timeout=5.0)` uses XREADGROUP with blocking to pop next task from consumer group
- `ack(task_id)` acknowledges processing via XACK
- `nack(task_id)` reads original message via XRANGE, acks it, then re-adds to stream for retry by any consumer
- Updated `__init__.py` to export `TaskBroker`
- Added `# pyright: ignore[reportMissingImports]` to all distributed package cross-imports (source + tests) following orbiter-observability pattern
- Added 18 tests across 3 test classes: `TestTaskBrokerInit` (3), `TestTaskBrokerConnect` (4), `TestTaskBrokerWithFakeRedis` (11)
- Files changed: `packages/orbiter-distributed/src/orbiter/distributed/broker.py`, `packages/orbiter-distributed/src/orbiter/distributed/__init__.py`, `packages/orbiter-distributed/tests/test_broker.py`, `packages/orbiter-distributed/tests/test_models.py`
- **Learnings for future iterations:**
  - Use `# pyright: ignore[reportMissingImports]` for all `orbiter.distributed.*` imports — pyright can't resolve namespace packages via .pth editable installs
  - `fakeredis.aioredis.FakeRedis(decode_responses=True)` provides full Redis Streams support for integration tests
  - Redis Streams consumer group pattern: XADD for submit, XREADGROUP with `>` for new messages, XACK for acknowledgment
  - For nack/retry: XRANGE to read original message → XACK to remove from PEL → XADD to re-enqueue
  - `_pending_ids` dict maps task_id → stream message_id for ack/nack correlation — must be initialized in `__init__`
  - `aioredis.ResponseError` with "BUSYGROUP" indicates consumer group already exists — safe to ignore on reconnect
  - Total tests: 783 (33 distributed + 750 existing)
---

## 2026-02-17 - US-010
- Created `TaskStore` class in `orbiter/distributed/store.py` backed by Redis hashes
- Constructor: `TaskStore(redis_url, *, prefix='orbiter:task:', ttl_seconds=86400)`
- `connect()` creates Redis client via `redis.asyncio.from_url()`
- `disconnect()` closes the Redis connection
- `set_status(task_id, status, **kwargs)` stores task state as Redis hash with TTL, maintains secondary index via SADD
- `get_status(task_id)` retrieves task state via HGETALL and parses into `TaskResult`
- `list_tasks(status=None, limit=100)` uses SMEMBERS on secondary index set, filters by status
- `_parse_result()` handles type conversion from Redis strings (floats, ints, JSON-encoded dicts, None via empty string)
- Updated `__init__.py` to export `TaskStore`
- Added 16 tests across 2 test classes: `TestTaskStoreInit` (3), `TestTaskStoreWithFakeRedis` (13)
- Files changed: `packages/orbiter-distributed/src/orbiter/distributed/store.py`, `packages/orbiter-distributed/src/orbiter/distributed/__init__.py`, `packages/orbiter-distributed/tests/test_store.py`
- **Learnings for future iterations:**
  - Redis hash operations (HSET, HGETALL, EXPIRE) and set operations (SADD, SMEMBERS) need `# type: ignore[misc]` for pyright — the redis async type stubs don't properly annotate these as awaitable
  - Secondary index pattern: SADD `{prefix}index` task_id on every `set_status()`, SMEMBERS for `list_tasks()` — simple but effective for listing
  - Redis hashes store everything as strings — need type conversion in `_parse_result()`: empty string → None, JSON.loads for dicts, float() for timestamps, int() for retries
  - `set_status()` uses HSET (not HMSET) with `mapping=` param — HSET with mapping is the modern Redis way
  - Calling `set_status()` multiple times preserves existing fields (HSET merges, doesn't replace the whole hash)
  - Total tests: 799 (49 distributed + 750 existing)
---

## 2026-02-17 - US-015
- Added `to_dict()` and `from_dict()` methods to `Agent` class for serialization/deserialization
- Added `to_dict()` and `from_dict()` methods to `Swarm` class for serialization/deserialization
- Tools serialized as importable dotted paths (`module.qualname`) — FunctionTool uses wrapped `_fn`, custom Tool subclasses use the class path
- Deserialization resolves paths via `importlib.import_module()` + `getattr()` with progressive fallback
- Non-serializable components raise `ValueError`: callable instructions, hooks, memory, context, closures/lambdas
- Handoffs serialized/deserialized recursively
- `output_type` (Pydantic BaseModel subclass) serialized as importable dotted path
- Added 36 tests across 9 test classes covering: to_dict, from_dict, round-trips (including JSON), error cases, Swarm serialization, and helper functions
- Files changed: `packages/orbiter-core/src/orbiter/agent.py`, `packages/orbiter-core/src/orbiter/swarm.py`, `packages/orbiter-core/tests/test_serialization.py`
- **Learnings for future iterations:**
  - `FunctionTool._fn` gives access to the wrapped function for `__module__` and `__qualname__` extraction
  - Closures/lambdas have `<` in their `__qualname__` (e.g., `make_tool.<locals>.my_closure`) — use this to detect non-serializable tools
  - Custom `Tool` subclasses serialize via their class path, not function path — `_deserialize_tool` checks `isinstance(obj, Tool)` first, then `issubclass(obj, Tool)` for classes
  - `_import_object()` tries `rsplit('.', 1)` first, then progressively shorter module paths for nested attributes
  - Agent hooks check uses `any(self.hook_manager.has_hooks(hp) for hp in HookPoint)` — iterates all hook points
  - Swarm `to_dict()` is thin: just agents list + flow/mode/max_handoffs; `from_dict()` delegates agent reconstruction to `Agent.from_dict()`
  - Total tests: 835 (49 distributed + 786 orbiter-core)
---

## 2026-02-17 - US-011
- Created `EventPublisher` and `EventSubscriber` classes in `orbiter/distributed/events.py`
- `EventPublisher` publishes streaming events to both Redis Pub/Sub (live) and Redis Streams (persistent replay)
- `publish(task_id, event)` serializes event as JSON, publishes to `orbiter:events:{task_id}` Pub/Sub channel and appends to `orbiter:stream:{task_id}` Stream with configurable TTL
- `EventSubscriber` provides two consumption modes:
  - `subscribe(task_id)` — live Pub/Sub `AsyncIterator[StreamEvent]`, terminates on terminal StatusEvent (completed/error/cancelled)
  - `replay(task_id, from_id="0")` — reads persisted events from Redis Stream
- Discriminated union deserialization via `_deserialize_event()` using `_EVENT_TYPE_MAP` dict mapping type string → concrete class
- `_deserialize_event()` raises `ValueError` for unknown event types
- Stream TTL configurable (default 3600s = 1 hour), set via EXPIRE on each publish
- Updated `__init__.py` to export `EventPublisher` and `EventSubscriber`
- Added 30 tests across 7 test classes: `TestDeserializeEvent` (10), `TestEventPublisherInit` (3), `TestEventPublisherConnect` (2), `TestEventPublisherWithFakeRedis` (5), `TestEventSubscriberInit` (2), `TestEventSubscriberReplay` (5), `TestEventSubscriberSubscribe` (3)
- Files changed: `packages/orbiter-distributed/src/orbiter/distributed/events.py`, `packages/orbiter-distributed/src/orbiter/distributed/__init__.py`, `packages/orbiter-distributed/tests/test_events.py`
- **Learnings for future iterations:**
  - `_EVENT_TYPE_MAP` dict maps type discriminator strings to concrete event classes — extend this if new event types are added
  - Redis Pub/Sub via `r.pubsub()` + `subscribe()` + `get_message(ignore_subscribe_messages=True)` for async listening; must `unsubscribe()` + `aclose()` in finally block
  - `r.publish()` and `r.expire()` need `# type: ignore[misc]` for pyright (same as HSET/SADD pattern in store.py)
  - fakeredis supports Pub/Sub — shared FakeRedis instance between publisher and subscriber in tests enables end-to-end Pub/Sub testing with `asyncio.gather(consumer, producer)`
  - `subscribe()` terminates on terminal StatusEvent (completed/error/cancelled) — callers don't need to manually stop iteration
  - `replay()` is a simple XRANGE read — no consumer groups needed since it's read-only replay
  - Pub/Sub `get_message()` returns None when no message available — need `await asyncio.sleep(0.01)` to avoid busy-loop
  - Total tests: 865 (79 distributed + 786 orbiter-core)
---

## 2026-02-17 - US-012
- Created `Worker` class in `orbiter/distributed/worker.py` — the core task execution loop
- Constructor: `Worker(redis_url, *, worker_id=None, concurrency=1, queue_name='orbiter:tasks', heartbeat_ttl=30)`
- `start()` connects broker/store/publisher, registers SIGINT/SIGTERM handlers, runs concurrent claim loops + heartbeat
- `stop()` signals graceful shutdown via `asyncio.Event`
- `_claim_loop()` claims tasks with 2s timeout and delegates to `_execute_task()`
- `_execute_task()` lifecycle: set RUNNING → reconstruct agent → run.stream() → publish events → set COMPLETED/FAILED → ack/nack
- `_reconstruct_agent()` detects Agent vs Swarm via `"agents"` key in config dict
- `_run_agent()` streams with `detailed=task.detailed`, publishes each event, collects TextEvent text for result
- Heartbeat: separate Redis connection publishes worker health to `orbiter:workers:{worker_id}` hash with TTL every `heartbeat_ttl/3` seconds
- Retry logic: on failure checks retries vs max_retries — nacks if retries remain, acks if exhausted
- Auto-generated worker_id: `{hostname}-{pid}-{random_hex}`
- Updated `__init__.py` to export `Worker`
- Added 17 tests across 8 test classes: `TestGenerateWorkerId` (2), `TestWorkerInit` (3), `TestWorkerReconstructAgent` (2), `TestWorkerExecuteTask` (4), `TestWorkerRunAgent` (2), `TestWorkerClaimLoop` (2), `TestWorkerStop` (1), `TestWorkerStart` (1)
- Files changed: `packages/orbiter-distributed/src/orbiter/distributed/worker.py`, `packages/orbiter-distributed/src/orbiter/distributed/__init__.py`, `packages/orbiter-distributed/tests/test_worker.py`
- **Learnings for future iterations:**
  - Worker uses local imports for `Agent`, `Swarm`, `run`, `TextEvent` inside methods — avoids circular imports and pyright issues across namespace packages
  - When testing local-import code, patch at the real source module (`orbiter.agent.Agent`, `orbiter.runner.run`) not at `orbiter.distributed.worker.X` — the module-level attribute doesn't exist for local imports
  - `contextlib.suppress(asyncio.CancelledError)` is required by ruff SIM105 instead of try/except/pass
  - `random.randbytes(4).hex()` gives 8-char random hex — good for worker ID suffix
  - Heartbeat uses a separate Redis connection from broker/store to avoid contention
  - `asyncio.Event` for shutdown signaling — checked in `_claim_loop()` while-condition
  - Signal handlers registered via `loop.add_signal_handler()` — must be patched in tests since pytest doesn't support real signal handlers
  - Cancel listener uses separate Redis connection + Pub/Sub on `orbiter:cancel:{task_id}` — sets `CancellationToken.cancelled = True` on signal
  - Worker `_execute_task` creates a cancel listener task per active task — cancelled in `finally` block via `task.cancel()` + `contextlib.suppress(asyncio.CancelledError)`
  - `_run_agent` checks `token.cancelled` between event yields (cooperative cancellation) — emits `StatusEvent(status='cancelled')` and breaks
  - `TaskBroker.cancel()` publishes to Pub/Sub and directly updates task hash status to CANCELLED (uses `orbiter:task:` prefix convention from TaskStore)
  - Total tests: 894 (108 distributed + 786 orbiter-core)
---

## 2026-02-17 - US-013
- Created `CancellationToken` class in `orbiter/distributed/cancel.py` with `cancelled` property and `cancel()` method
- Added `cancel(task_id)` method to `TaskBroker` in `broker.py` — publishes cancel signal to `orbiter:cancel:{task_id}` Pub/Sub and sets task status to CANCELLED in Redis hash
- Updated `Worker._execute_task()` to create a `_listen_for_cancel()` background task per active task — subscribes to Pub/Sub cancel channel and sets token on signal
- Updated `Worker._run_agent()` to accept `CancellationToken` — checks `token.cancelled` between event yields, emits `StatusEvent(status='cancelled')` and breaks when cancelled
- Worker sets task status to CANCELLED (not COMPLETED) when token is cancelled
- Cancel listener uses separate Redis connection (like heartbeat) to avoid contention
- Updated existing `test_worker.py` tests for new `_run_agent(agent, task, token)` signature and `_listen_for_cancel` patching
- Exported `CancellationToken` from `orbiter.distributed.__init__`
- Added 12 new tests across 5 test classes: `TestCancellationToken` (3), `TestTaskBrokerCancel` (3), `TestWorkerListenForCancel` (2), `TestWorkerRunAgentCancellation` (2), `TestWorkerExecuteTaskCancellation` (2)
- Files changed: `packages/orbiter-distributed/src/orbiter/distributed/cancel.py` (new), `packages/orbiter-distributed/src/orbiter/distributed/broker.py`, `packages/orbiter-distributed/src/orbiter/distributed/worker.py`, `packages/orbiter-distributed/src/orbiter/distributed/__init__.py`, `packages/orbiter-distributed/tests/test_cancel.py` (new), `packages/orbiter-distributed/tests/test_worker.py`
- **Learnings for future iterations:**
  - Cancel listener uses separate Redis connection + `r.pubsub()` — `pubsub()` is a sync method on Redis (returns PubSub object), not async
  - When testing with mock Redis, use `MagicMock` for `pubsub` method (sync) and `AsyncMock` for the PubSub object methods (subscribe, get_message, unsubscribe, aclose are async)
  - `TaskBroker.cancel()` directly updates the Redis hash using TaskStore's key convention (`orbiter:task:{task_id}`) — avoids needing TaskStore dependency in broker
  - Worker `_execute_task` always cancels the listener task in `finally` block — important for cleanup even on exceptions
  - Cooperative cancellation: token checked between event yields in `_run_agent`, not between steps — gives finer-grained cancellation response
  - When adding params to `_run_agent`, update ALL existing tests that mock it (both in test_worker.py and test_cancel.py)
  - Total tests: 894 (108 distributed + 786 orbiter-core)
---
