## Codebase Patterns
- SQLiteMemoryStore: import from `orbiter.memory.backends.sqlite`, needs `await store.init()` before use
- Context summarization: `_apply_context_windowing()` in `orbiter.agent` creates a transient `SystemMessage("[Conversation Summary]...")` — NOT persisted to SQLiteMemoryStore; only HumanMemory + AIMemory are persisted; summarization fires when non-system msg_count >= summary_threshold (including loaded history + new user message)
- summary_threshold=4 means summarization fires at turn 3 (turn 1=2 stored items, turn 2=4 stored → 4+1 new=5 >= 4, fires); keep_recent = max(2, summary_threshold//2) = 2
- token_budget_trigger only fires INSIDE the tool loop (when tool calls happen), not between turns — set summary_threshold to test summarization in non-tool scenarios
- `agent.run()` returns `AgentOutput(text, tool_calls, usage)` — NO `output` field; for structured output, use `parse_structured_output(result.text, MyModel)` from `orbiter._internal.output_parser`
- `output_type` on Agent is stored but NOT auto-applied; instruct LLM to return JSON in system prompt and parse manually
- Agent memory persistence: pass `memory=SQLiteMemoryStore(db_path=...)` directly (not AgentMemory) for simple per-store persistence; agent_id and task_id are auto-set; user_id is NOT auto-set
- ContextConfig: import from `orbiter.context.config`; use `ContextConfig(mode="copilot", history_rounds=N, summary_threshold=M, offload_threshold=P)` or `make_config("pilot")`; `summary_threshold <= offload_threshold` is required
- Context windowing test: to test `history_rounds` limits, set `summary_threshold` high (e.g. 50) to prevent summarization injecting context via SystemMessage before windowing runs
- `load_history(rounds=max_steps)` limits how many prior rounds memory loads; set `max_steps >= N_turns` so memory loads full history before context windowing trims it
- For memory history reload: second agent MUST have same `name` as first agent AND same `conversation_id` for `load_history()` to find prior messages
- `MemoryMetadata(user_id=...)` scoping works in SQLiteMemoryStore via `json_extract(metadata, '$.user_id')`
- ChromaVectorMemoryStore: import from `orbiter.memory.backends.vector`, takes EmbeddingProvider, optional `path` for persistence
- SentenceTransformerEmbeddingProvider: local embeddings, no API key needed, import from `orbiter.memory.backends.vector`
- mcp_server decorator: import from `orbiter.mcp`, adds `run()` and `stop()` methods dynamically (type: ignore needed for pyright)
- MCPServerConfig stdio transport: `command=sys.executable, args=[script_path]` — client spawns subprocess per connection
- pyproject.toml testpaths uses glob pattern `"packages/*/tests"` for package tests
- `asyncio_mode = "auto"` in pytest config means all async test/fixture functions auto-detected
- Integration test branch: `ralph/orbiter-integration-tests`
- Streaming API: `run.stream(agent, prompt, provider=provider, detailed=True)` from `orbiter.runner`; `detailed=True` enables StepEvent, UsageEvent, ToolResultEvent, StatusEvent; use `event_types={"text","usage"}` filter so UsageEvent is last in no-tool case
- Gemini parallel tool calls: Vertex/Gemini API requires ALL function responses for a multi-tool step to be in a single turn; orbiter sends them as separate ToolResult messages which can trigger `400 INVALID_ARGUMENT`; avoid by using chained tools (sequential) instead of prompting for parallel independent calls

---

# Ralph Progress Log
Started: Fri Feb 20 03:26:33 AM IST 2026
---

## 2026-02-20 - US-INT-001
- What was implemented: Full integration test infrastructure setup
- Files changed:
  - `tests/__init__.py` (new, empty)
  - `tests/integration/__init__.py` (new, empty)
  - `tests/integration/conftest.py` (new, all 8 fixtures)
  - `tests/integration/helpers/__init__.py` (new, empty)
  - `tests/integration/helpers/mcp_test_server.py` (new, @mcp_server class with get_capital + get_population)
  - `tests/integration/helpers/web_app.py` (new, minimal FastAPI app with /health)
  - `pyproject.toml` (updated testpaths, markers, added pytest-timeout/tenacity/docker/httpx/chromadb/sentence-transformers)
  - `uv.lock` (updated)
- **Learnings for future iterations:**
  - The orbiter-server app (`orbiter_server.app`) has NO `/health` endpoint — a separate `web_app.py` helper was created for uvicorn_server fixture
  - `pytest --collect-only` exits code 5 when no tests collected; that's expected for a new empty test directory
  - Lazy imports (inside fixture bodies) are the right pattern for optional heavy dependencies (chromadb, sentence-transformers)
  - `@mcp_server()` decorator adds `.run()` dynamically — pyright needs `# type: ignore[attr-defined]` at call site
  - `contextlib.suppress(FileNotFoundError)` preferred over try/except/pass (ruff SIM105)
  - After running `uv lock`, need `uv sync --dev` to install packages in the venv
  - Package runs via `uv run` use Python 3.11 venv, not system Python 3.14
---

## 2026-02-20 - US-INT-002
- What was implemented: Agent + memory persistence seam tests
- Files changed:
  - `tests/integration/test_agent_memory.py` (new)
- **Learnings for future iterations:**
  - `agent.run()` returns `AgentOutput` with `text`, `tool_calls`, `usage` — no `output` field for structured Pydantic models
  - For structured output from LLM, instruct in system prompt to return JSON and parse with `parse_structured_output(result.text, Model)` from `orbiter._internal.output_parser`
  - Two agents sharing a SQLiteMemoryStore with same `name` and `conversation_id` will load each other's history via `load_history()` in `MemoryPersistence`
  - `MemoryMetadata(user_id=...)` scoping works correctly in SQLiteMemoryStore; querying by user_id only returns items with that user_id
  - `test_memory_metadata_scoping` tests SQLiteMemoryStore metadata isolation directly (no LLM needed)
---

## 2026-02-20 - US-INT-004
- What was implemented: Agent streaming event ordering tests
- Files changed:
  - `tests/integration/test_agent_streaming.py` (new)
- **Learnings for future iterations:**
  - `run.stream()` lives in `orbiter.runner`; `run.stream` is attached to the `run` callable as `run.stream = _stream`; use `# type: ignore[attr-defined]` at call site
  - `detailed=True` enables StepEvent, UsageEvent, ToolResultEvent, StatusEvent; without it only TextEvent and ToolCallEvent are emitted
  - Use `event_types={"text","usage"}` filter to make UsageEvent the last event in a no-tool stream (StepEvent/StatusEvent are filtered out)
  - Use `event_types={"text","tool_call","tool_result","usage"}` filter for tool call ordering tests
  - Gemini/Vertex API requires ALL function responses for a parallel multi-tool step to be in a SINGLE user turn; orbiter sends separate ToolResult messages which triggers `400 INVALID_ARGUMENT: number of function response parts must equal function call parts`; avoid by using CHAINED tools (sequential dependency) rather than prompting for parallel independent calls
  - StepEvent count: any single tool call creates >= 2 steps (tool step + final response step) → >= 4 StepEvents (started+completed each); chained 2-tool test gives >= 6 StepEvents
---

## 2026-02-20 - US-INT-003
- What was implemented: Agent + context windowing seam tests
- Files changed:
  - `tests/integration/test_agent_context.py` (new)
- **Learnings for future iterations:**
  - `AgentOutput` (from `agent.run()`) has NO `messages` field; PRD's `len(result.messages)` check was adapted to behavioral testing
  - Context windowing (`history_rounds`) trims non-system messages; summarization creates a SystemMessage that is NOT trimmed — so `summary_threshold` must be set high to prevent it from injecting old context
  - `load_history(rounds=max_steps)` limits memory loads; use `max_steps >= N_turns` so context windowing (not memory) is the limiting factor in the test
  - ContextConfig frozen=True — pass all params at creation; `make_config("pilot")` sets `history_rounds=100, summary_threshold=100, offload_threshold=100`
  - Behavioral test pattern: plant unique token in turn 1, pad with N turns, ask about token — windowed agent says "I don't know", pilot agent recalls it
---

## 2026-02-20 - US-INT-005
- What was implemented: Agent multi-tool selection tests
- Files changed:
  - `tests/integration/test_agent_tools.py` (new)
- **Learnings for future iterations:**
  - `AgentOutput.tool_calls` is `list[ToolCall]`; each `ToolCall` has `.name` (str) and `.arguments` (JSON-encoded str); use `json.loads(tc.arguments)` to get the dict
  - For multi-tool selection test, checking `result.tool_calls` (not `result.messages`) is the correct way to inspect tool calls from `agent.run()`
  - For chained tools test (get_capital → get_population), model must sequentially call them because the second depends on the output of the first — this avoids the Gemini parallel-tool-call INVALID_ARGUMENT issue
  - Tests skip gracefully when GOOGLE_CLOUD_PROJECT/GOOGLE_CLOUD_LOCATION are not set (via vertex_model fixture)
---

## 2026-02-20 - US-INT-006
- What was implemented: Structured output validation tests using parse_structured_output
- Files changed:
  - `tests/integration/test_agent_structured_output.py` (new)
- **Learnings for future iterations:**
  - PRD references `result.output` (e.g. `result.output.capital`) but `agent.run()` returns `AgentOutput` with NO `output` field; use `parse_structured_output(result.text, Model)` from `orbiter._internal.output_parser` instead
  - For structured output tests, instruct the agent via system prompt to reply ONLY with the JSON object; the LLM reliably follows this when clearly told the schema and no-other-text
  - Tool call assertions use `result.tool_calls` (list of ToolCall); structured output assertions use `parse_structured_output(result.text, Model)`
  - `temperature_celsius` parsed from JSON may come as int; use `isinstance(x, (int, float))` or just check `isinstance(x, float)` after pydantic coerces it
---

## 2026-02-20 - US-INT-007
- What was implemented: SQLiteMemoryStore persistence, keyword search, and metadata isolation tests
- Files changed:
  - `tests/integration/test_memory_persistence.py` (new)
- **Learnings for future iterations:**
  - PRD says `memory_store.save()` and `memory_store.load(session_id=...)` but actual API uses `add()` and `search(metadata=MemoryMetadata(session_id=...))` — adapt accordingly
  - `search(query="KEYWORD", limit=N)` does SQLite LIKE/FTS matching on content field; returns only items whose content contains the query string
  - `search(metadata=MemoryMetadata(session_id="..."))` filters by session_id via json_extract on metadata column
  - `search(metadata=MemoryMetadata(user_id="..."))` filters by user_id — user isolation works correctly
  - `memory_store` fixture (from conftest.py) yields an already-init'd SQLiteMemoryStore backed by a temp file — no need to call `await store.init()` again
  - Tests that only exercise SQLiteMemoryStore directly (no LLM needed) run in ~0.2s total — very fast
---

## 2026-02-20 - US-INT-009
- What was implemented: Context summarization trigger tests — verifies summarization pipeline works without errors through 6 turns and that input_tokens are bounded after compression
- Files changed:
  - `tests/integration/test_context_summarization.py` (new)
- **Learnings for future iterations:**
  - SummaryMemory does NOT exist as a persistent class; summarization creates transient SystemMessages only (not saved to SQLiteMemoryStore)
  - MemoryPersistence hooks only save HumanMemory (before LLM call) and AIMemory/ToolMemory (via POST_LLM_CALL/POST_TOOL_CALL hooks)
  - SystemMemory items from load_history() CAN be reconstructed IF written to store manually, but the summarization pipeline never writes them
  - token_budget_trigger fires only during the tool loop (lines 964-982 in agent.py) — not between turns; set summary_threshold for turn-to-turn summarization tests
  - summary_threshold=4 means first summarization fires at turn 3 (4 stored messages + 1 new = 5 >= 4)
  - generate_summary() uses the provider to make an extra LLM call for the summary — add extra time budget (~2-3s per summarization event); use timeout(90) not timeout(30)
  - Adapted test_summarization_shortens_context to compare usage.input_tokens (proxy for context length) since AgentOutput has no messages field
  - Adapted test_token_budget_triggers_summarization to verify >= 12 items in store (all 6 turns completed) since SummaryMemory is not persisted
---

## 2026-02-20 - US-INT-008
- What was implemented: ChromaVectorMemoryStore semantic search and similarity threshold tests
- Files changed:
  - `tests/integration/test_memory_vector.py` (new)
- **Learnings for future iterations:**
  - `ChromaVectorMemoryStore.search()` has no `min_score` parameter; to test similarity thresholds, embed query and items manually via `vector_store._embedding_provider.embed()` and compute dot product (unit-norm vectors → dot product = cosine similarity)
  - `all-MiniLM-L6-v2` (SentenceTransformerEmbeddingProvider default) produces unit-norm vectors; dot product of two embeddings equals their cosine similarity
  - Semantic search correctly distinguishes unrelated domains (astronomy vs cooking, cooking vs quantum physics) — at least 2 of 3 relevant items returned in top-5 results
  - `vector_store` fixture is already initialized; no `init()` call needed, just call `await store.add()` directly
  - Test runtime ~20s due to model loading on first use; subsequent tests in same session are faster
---

## 2026-02-20 - US-INT-010
- What was implemented: MCP stdio subprocess integration tests — verifies agent can connect to real stdio MCP server subprocess and call its tools
- Files changed:
  - `tests/integration/test_mcp_stdio.py` (new)
- **Learnings for future iterations:**
  - `await agent.add_mcp_server(mcp_server_config)` connects to MCP server and registers all its tools on the agent; tools are namespaced: `mcp__test_server__get_capital`
  - Check tool registration via `any("get_capital" in name for name in agent.tools.keys())` since names are namespaced
  - `result.tool_calls` (from `agent.run()`) is `list[ToolCall]`; each `.name` is the namespaced name; check with `"get_capital" in tc.name`
  - `result.text` (not `result.output`) contains the LLM's text response — assert keyword presence with `.lower()`
  - MCP stdio client spawns a fresh subprocess per connection (not a long-running process); the `MCPServerConfig` in the fixture just describes how to launch it
  - For sequential MCP tool calls, chain them so second depends on first (avoids Gemini parallel-tool-call INVALID_ARGUMENT)
  - Use timeout(60) not timeout(30) for MCP tests — subprocess spawn + LLM call needs extra headroom
---
