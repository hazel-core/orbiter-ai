# Ralph Progress Log
Started: Sun Feb 15 04:58:56 PM IST 2026

## Codebase Patterns
- UV workspace monorepo: 13 packages under `packages/` (including orbiter-context), root pyproject.toml has NO build-system
- New namespace package setup: create `packages/orbiter-<name>/` dir, add to root pyproject.toml workspace members + dev deps + uv.sources, then `uv sync`
- Namespace packages: `orbiter-core/__init__.py` uses `pkgutil.extend_path()` so other packages add to the `orbiter` namespace
- Meta-package at `packages/orbiter/` uses `_orbiter_meta` dummy package for hatchling compatibility
- Quality checks: `uv run ruff check packages/`, `uv run ruff format --check packages/`, `uv run pyright packages/orbiter-core/`, `uv run pytest`
- Use `Sequence[Message]` (not `list[Message]`) for function params that accept subtype lists — avoids pyright invariance errors
- Use `ClassVar[dict[...]]` for mutable class attributes on dataclass-like test fixtures to avoid RUF012 lint errors
- Use `StrEnum` (not `str, Enum`) for string enums — ruff UP042 enforces this
- Test file names must be unique across all packages (pytest collects `tests/` from multiple packages into one `tests` module)
- pytest-asyncio `asyncio_mode = "auto"` configured in root pyproject.toml — no need for `@pytest.mark.asyncio`
- Import sorting: ruff enforces I001 import block sorting — use `uv run ruff check --fix` to auto-sort
- Forward-compatible params: use `Any` type with `None` default for params whose concrete types come from future packages
- Cross-package error handling: since orbiter-core can't import ModelError from orbiter-models, check error attributes (e.g., `.code`) via `getattr()` on caught exceptions
- Mock provider responses MUST include valid `Usage` objects (not `None`) — `parse_response(usage=None)` causes Pydantic validation failure, silently consumed by retry logic
- pyright ignore comments: put `# pyright: ignore[reportMissingImports]` on the import line itself (not a separate comment line) to avoid ruff I001 import sorting issues
- Within-package namespace imports also need `# pyright: ignore[reportMissingImports]` — e.g., `context.py` importing `config.py` in the same `orbiter.context` package
- Ruff RUF023: `__slots__` entries must be sorted alphabetically — run `uv run ruff check --fix` to auto-sort
- `__slots__` makes instance attributes read-only for `patch.object(instance, "method")` — use `patch.object(ClassName, "method")` instead
- `@asynccontextmanager` returns single-use CMs — when mocking, use `side_effect=lambda: factory()` not `return_value=cm` for multi-call scenarios
- BLE001 (broad exception) ruff rule is NOT enabled — don't add `# noqa: BLE001` comments (triggers RUF100 unused noqa)
- OTel `trace.set_tracer_provider()` can only be called once — in tests, reset `trace._TRACER_PROVIDER_SET_ONCE._done = False` and `trace._TRACER_PROVIDER = None` before each test
- OTel `metrics.set_meter_provider()` can only be called once — in tests, reset `metrics._internal._METER_PROVIDER_SET_ONCE._done = False` and `metrics._internal._METER_PROVIDER = None` before each test
- OTel metrics instruments created at module level bind to the no-op provider — use `metrics.get_meter().create_*()` inside recording functions so instruments always use the current MeterProvider
- OTel SDK may not ship `InMemorySpanExporter` — create a simple `_MemoryExporter(SpanExporter)` subclass that collects spans in a list
- SLF001 (private member access) ruff rule is NOT enabled — `# noqa: SLF001` is unnecessary and triggers RUF100
- Ruff B039: `ContextVar` default cannot be mutable (e.g., `default={}`) — use `default=None` with `T | None` type and handle None in accessor functions
- orbiter-cli is a regular package (`orbiter_cli` import path), NOT a namespace package — it has its own entry point via `typer`
- Typer `no_args_is_help=True` returns exit code 2 (not 0) — test with `assert exit_code in (0, 2)`
- FastAPI routers: use `Request` dependency (`req: Request`) to access app state — `router.app` has pyright typing issues (`MethodType` instead of `FastAPI`)
---

## 2026-02-15 - US-001
- What was implemented: Message builder with build_messages, validate_message_order, extract_last_assistant_tool_calls, merge_usage. Initial commit of entire Orbiter framework infrastructure (Phases 1-4 + partial Phase 5).
- Files changed: packages/ (65 files — all package infrastructure, types, config, registry, events, hooks, tool, models, agent, message_builder, output_parser, and tests)
- **Learnings for future iterations:**
  - The codebase had pre-existing code from prior interactive sessions (Phases 1-4) that was never committed — this first commit captures everything
  - `list[SubType]` is not assignable to `list[BaseType]` in pyright due to list invariance — use `Sequence[BaseType]` for read-only function params
  - `test_agent.py` had RUF012 (mutable class default) and I001 (import sorting) lint errors that needed fixing
  - All 349 tests pass across orbiter-core (222) and orbiter-models (127)
---

## 2026-02-15 - US-002
- What was implemented: Output parser was already fully implemented and committed as part of the US-001 batch commit. Verified all acceptance criteria are met.
- Files: `packages/orbiter-core/src/orbiter/_internal/output_parser.py` (~155 lines), `packages/orbiter-core/tests/test_output_parser.py` (19 tests)
- Key functions: `parse_response()`, `parse_tool_arguments()`, `parse_structured_output()`, `OutputParseError`
- All quality checks pass: ruff check, ruff format, pyright (0 errors), pytest (349 tests)
- **Learnings for future iterations:**
  - US-001's initial commit included code for multiple user stories — check if the next story's code already exists before implementing
  - The PRD's `ParsedOutput` is implemented as `AgentOutput` in the actual code — the types module defines `AgentOutput` with text, tool_calls, usage fields
---

## 2026-02-15 - US-003
- What was implemented: Agent class was already mostly implemented from prior sessions. Added missing `memory` and `context` parameters to `Agent.__init__` (typed as `Any` since orbiter-context and orbiter-memory packages are not yet implemented). Updated test to assert defaults are `None`.
- Files changed: `packages/orbiter-core/src/orbiter/agent.py`, `packages/orbiter-core/tests/test_agent.py`
- **Learnings for future iterations:**
  - Agent class already had 21 tests covering: minimal/full creation, keyword-only enforcement, model parsing, tool/handoff registration with duplicate detection, hook integration, callable instructions, describe(), __repr__
  - `memory` and `context` params use `Any` type since their implementations are in future phases (orbiter-memory Phase 9, orbiter-context Phase 8)
  - Pattern: when PRD references types from future packages, use `Any` with `None` default as a forward-compatible placeholder
---

## 2026-02-15 - US-004
- What was implemented: `Agent.run()` async method with single-turn LLM execution and retry logic. Added `code` parameter to `ModelError` for error classification.
- Files changed: `packages/orbiter-core/src/orbiter/agent.py` (added ~85 lines for run() + _is_context_length_error()), `packages/orbiter-core/tests/test_agent.py` (added 15 tests in 3 new test classes), `packages/orbiter-models/src/orbiter/models/types.py` (added `code` param to ModelError)
- Key implementation details:
  - `run(input, *, messages, provider, max_retries=3)` wires message_builder → LLM call → output_parser
  - PRE_LLM_CALL / POST_LLM_CALL hooks fire at correct points
  - Retry with exponential backoff (2^attempt seconds): 1s, 2s, 4s...
  - Context-length errors (via `ModelError.code == "context_length"` or message text) fail immediately
  - Provider typed as `Any` since orbiter-core doesn't depend on orbiter-models
- **Learnings for future iterations:**
  - orbiter-core can't import from orbiter-models directly — use `Any` type for provider parameter and catch base exceptions
  - `_is_context_length_error()` checks both `.code` attribute and error message text for robustness
  - pyright inline ignore comments on import lines don't break ruff I001 sorting (put `# pyright: ignore[...]` on the same import line, not a separate comment line)
  - All 364 tests pass (15 new: 7 run tests, 4 retry tests, 4 hook tests)
---

## 2026-02-15 - US-005
- What was implemented: Tool execution loop in `Agent.run()` — when LLM returns tool calls, agent executes them in parallel, feeds results back, and re-calls LLM until text response or max_steps.
- Files changed: `packages/orbiter-core/src/orbiter/agent.py` (refactored run() into run() + _call_llm() + _execute_tools(), ~120 new lines), `packages/orbiter-core/tests/test_agent.py` (8 new tests in TestAgentToolLoop class)
- Key implementation details:
  - `run()` now has a `for _step in range(self.max_steps)` loop around `_call_llm()`
  - `_call_llm()` extracted from old `run()` — single LLM call with retry logic and hooks
  - `_execute_tools()` uses `asyncio.TaskGroup` for parallel tool execution
  - Tool errors caught per-tool and returned as `ToolResult(error=...)`, not propagated
  - Unknown tools return `ToolResult(error="Unknown tool '...'")`
  - PRE_TOOL_CALL / POST_TOOL_CALL hooks fire for each tool
  - `parse_tool_arguments()` from output_parser converts ToolCall JSON args to ActionModel
  - Updated existing test `test_run_with_tool_calls_in_response` to account for the tool loop (provider now needs to return text on second call)
- **Learnings for future iterations:**
  - When adding tool loop, existing tests that mock a single tool-call response break because the agent now tries to execute the tool and re-call. Update mocks to return text on the follow-up call.
  - `asyncio.TaskGroup` requires Python 3.11+ — already satisfied by this project
  - The placeholder list pattern `[ToolResult(...)] * len(actions)` creates shared references — must assign by index in the async task, not append
  - All 372 tests pass (8 new tool loop tests)
---

## 2026-02-15 - US-006
- What was implemented: 8 new edge case tests in `TestAgentEdgeCases` class covering: retry during tool loop, agent with handoffs runs normally, handoffs don't appear as tools, sequential tool calls accumulate messages, max_steps=1, empty input, usage from final response, tool with no arguments.
- Files changed: `packages/orbiter-core/tests/test_agent.py` (+161 lines)
- **Learnings for future iterations:**
  - Most edge cases were already covered by earlier test classes (TestAgentToolLoop had 8 tests for the core scenarios)
  - The key gap was retry behavior mid-tool-loop and handoff interaction — these are important to test because they exercise separate code paths in the agent
  - 52 agent tests total across 9 test classes, 380 tests across the full suite
---

## 2026-02-15 - US-007
- What was implemented: Human-in-the-loop tool with `HumanInputHandler` ABC, `ConsoleHandler` (stdin-based), and `HumanInputTool` (Tool subclass with timeout support).
- Files changed: `packages/orbiter-core/src/orbiter/human.py` (~120 lines), `packages/orbiter-core/tests/test_human.py` (21 tests in 4 classes)
- Key implementation details:
  - `HumanInputHandler` ABC with `async get_input(prompt, choices)` — extensible to console, web, Slack, etc.
  - `ConsoleHandler` — reads from stdin via `asyncio.to_thread()`, validates choices, defaults to first choice on invalid input
  - `HumanInputTool` — `Tool` subclass with manually defined JSON schema (prompt required, choices optional array)
  - Timeout via `asyncio.wait_for()` — raises `ToolError` on timeout
  - Tests use `MockHandler` and `SlowHandler` fixtures, plus `monkeypatch` for `ConsoleHandler._read_line`
- **Learnings for future iterations:**
  - `HumanInputTool` manually defines its JSON schema rather than using `_generate_schema()` since it's not a FunctionTool wrapper — this is the pattern for custom Tool subclasses
  - `asyncio.wait_for()` raises `TimeoutError` (Python 3.11+) — catch that and convert to `ToolError` for consistent error handling
  - 401 tests total across full suite (21 new)
---

## 2026-02-15 - US-008
- What was implemented: Run state tracking with `RunNodeStatus` (StrEnum: INIT, RUNNING, SUCCESS, FAILED, TIMEOUT), `RunNode` (Pydantic model with lifecycle transitions: start/succeed/fail/timeout, timing, usage, metadata), and `RunState` (mutable execution tracker with message accumulation, node management, usage aggregation, terminal state detection).
- Files changed: `packages/orbiter-core/src/orbiter/_internal/state.py` (~145 lines), `packages/orbiter-core/tests/test_state.py` (29 tests in 3 classes)
- **Learnings for future iterations:**
  - Use `StrEnum` instead of `str, Enum` — ruff UP042 enforces this pattern
  - `Sequence[Message]` still needed for function params that accept `list[SubType]` — pyright invariance on `list[T]`
  - `RunNode` uses mutable Pydantic model (no `frozen=True`) since state transitions mutate fields — this is the right pattern for stateful objects vs. value objects
  - 430 tests total across full suite (29 new)
---

## 2026-02-15 - US-009
- What was implemented: Core call runner (`call_runner()`) that orchestrates Agent.run() with RunState tracking, node lifecycle management, usage accumulation, and endless loop detection via tool-call signature comparison.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/call_runner.py` (~145 lines), `packages/orbiter-core/tests/test_call_runner.py` (15 tests in 6 classes)
- Key implementation details:
  - `call_runner(agent, input, *, state, messages, provider, max_retries, loop_threshold)` — wraps Agent.run() in RunState lifecycle
  - Creates RunNode per call, tracks INIT → RUNNING → SUCCESS/FAILED transitions
  - Loop detection: `_tool_call_signature()` creates deterministic string from sorted tool name:args pairs; `_check_loop()` counts consecutive matching signatures in node metadata
  - Errors from Agent.run() wrapped in `CallRunnerError`, state/node marked FAILED
  - Agent.instructions resolved via callable check + str() for pyright compatibility (agent param typed as Any)
  - Returns `RunResult` with output text, accumulated messages, total usage, step count
- **Learnings for future iterations:**
  - Since `agent` is typed as `Any` in call_runner, accessing `agent.instructions` returns `object | Any` — must use `str()` cast or explicit type narrowing, not direct assignment to `str` variable
  - Loop detection works across consecutive `call_runner()` invocations with shared state by storing tool signatures in `RunNode.metadata`
  - The call_runner delegates the actual LLM→tool→LLM loop entirely to Agent.run() — it's a thin orchestration layer for state tracking, not a replacement for Agent's internal loop
  - 445 tests total across full suite (15 new)
---

## 2026-02-15 - US-010
- What was implemented: Public `run()` async entry point and `run.sync()` blocking wrapper as the primary API for executing agents. Auto-provider resolution via orbiter.models registry when available.
- Files changed: `packages/orbiter-core/src/orbiter/runner.py` (~100 lines), `packages/orbiter-core/tests/test_runner.py` (13 tests in 5 classes)
- Key implementation details:
  - `run(agent, input, *, messages, provider, max_retries, loop_threshold) -> RunResult` — async, delegates to `call_runner()`
  - `run.sync(...)` — attached as attribute on `run` function, uses `asyncio.run()` internally
  - `_resolve_provider(agent)` — tries `orbiter.models.provider.get_provider()` with graceful fallback to `None`
  - Provider typed as `Any` since orbiter-core doesn't depend on orbiter-models
- **Learnings for future iterations:**
  - Python functions are objects — you can attach attributes like `run.sync = _sync` with `# type: ignore[attr-defined]` for pyright
  - `asyncio.run()` creates a new event loop, so `run.sync()` can't be called from within an existing async context — this is the expected behavior
  - Auto-provider resolution uses try/except to gracefully handle missing orbiter-models package
  - 458 tests total across full suite (13 new)
---

## 2026-02-15 - US-011
- What was implemented: `run.stream()` async generator attached to the `run` function, yielding `TextEvent` for text deltas and `ToolCallEvent` for tool invocations. Supports full tool execution loop with re-streaming after tool results.
- Files changed: `packages/orbiter-core/src/orbiter/runner.py` (added `_stream()` ~110 lines), `packages/orbiter-core/tests/test_runner.py` (added 10 tests in 3 new test classes + streaming helpers)
- Key implementation details:
  - `run.stream(agent, input, ...)` uses `provider.stream()` for chunk-by-chunk text delivery
  - Tool call deltas accumulated from `StreamChunk.tool_call_deltas` by index, then assembled into `ToolCall` objects
  - After tool calls: executes tools via `agent._execute_tools()`, appends results to conversation, re-streams
  - Loop continues until text-only response or `max_steps` reached
  - Error in no-provider case raises `AgentError` immediately
- **Learnings for future iterations:**
  - `_resolve_provider` passes `agent.provider_name` to `get_provider()`, which calls `parse_model_string()` again — a bare name like "nonexistent" gets parsed as `("openai", "nonexistent")` and resolves to OpenAI provider. To test no-provider scenarios, monkeypatch `_resolve_provider` to return `None`
  - Same pyright issue with `agent.instructions` returning `object | Any` — use `str()` cast pattern (instr/raw_instr) consistent with call_runner.py
  - Streaming doesn't use `call_runner()` or `Agent.run()` — it operates at a lower level, directly calling `provider.stream()` and managing the tool loop itself. This is by design for real-time event delivery
  - 468 tests total across full suite (10 new streaming tests)
---

## 2026-02-15 - US-012
- What was implemented: Handler system with `Handler[IN, OUT]` ABC (generic async generator base), `AgentHandler` (routes between agents in swarms), `SwarmMode` enum (workflow/handoff/team), handoff detection, and topology-aware stop checks.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/handlers.py` (~130 lines), `packages/orbiter-core/tests/test_handlers.py` (28 tests in 7 classes)
- Key implementation details:
  - `Handler[IN, OUT]` is a generic ABC with abstract `handle(input) -> AsyncIterator[OUT]` — non-async def returning AsyncIterator avoids pyright type issues with abstract async generators
  - `AgentHandler` implements workflow (sequential, output→input chaining), handoff (follow handoff chains with max_handoffs guard), and team (run lead agent) modes
  - Handoff detection: exact match of `result.output.strip()` against agent's handoff target names, with additional check that the target exists in the swarm's agents dict
  - Stop checks are separate methods (`_check_workflow_stop`, `_check_handoff_stop`, `_check_team_stop`) for composability
  - Delegates actual agent execution to `call_runner()` from the existing call_runner module
- **Learnings for future iterations:**
  - Abstract async generator methods in ABCs: use `def handle(...) -> AsyncIterator[T]` (not `async def`) to avoid pyright issues with `yield` in abstract methods yielding `None` instead of `T`
  - Handoff cycle test: when testing A→B→A→B cycles, the mock provider must alternate responses ("b", "a", "b", "a") since each agent checks handoff targets against its own handoffs dict
  - The handler system is the bridge between the runner layer (run/call_runner) and the swarm layer (US-017+). AgentHandler will be used by Swarm to orchestrate multi-agent execution
  - 496 tests total across full suite (28 new handler tests)
---

## 2026-02-15 - US-013
- What was implemented: ToolHandler (dynamic tool loading, parallel execution via asyncio.TaskGroup, result aggregation) and GroupHandler (parallel and serial agent group execution with dependency resolution via Kahn's topological sort).
- Files changed: `packages/orbiter-core/src/orbiter/_internal/handlers.py` (added ~130 lines for ToolHandler + GroupHandler), `packages/orbiter-core/tests/test_handlers.py` (added 23 tests in 6 new test classes)
- Key implementation details:
  - `ToolHandler` — receives dict of `{tool_call_id: {"name": str, "arguments": dict}}`, resolves tools from registry, executes in parallel, yields `ToolResult` objects. Also has `register()`, `register_many()`, `aggregate()` methods
  - `GroupHandler` — `parallel=True` runs all agents concurrently (same input, TaskGroup), `parallel=False` runs serially with output→input chaining and dependency resolution
  - `_resolve_order()` implements Kahn's algorithm for topological sort with cycle detection — raises `HandlerError` on cyclic dependencies
  - Both handlers follow the `Handler[IN, OUT]` ABC pattern from US-012
- **Learnings for future iterations:**
  - When testing with `_make_provider`, response count must match total LLM calls across all agents — each `call_runner()` invocation triggers at least one `provider.complete()` call
  - Custom mock providers in tests need to return objects with `content`, `tool_calls`, and `usage` attributes matching what `parse_response()` expects — `usage=None` will fail
  - To test "missing agent" in serial mode, either override `_resolve_order()` in a subclass or manipulate the agents dict after construction (since `_resolve_order` only includes keys from `self.agents`)
  - 519 tests total across full suite (23 new handler tests)
---

## 2026-02-15 - US-014
- What was implemented: BackgroundTaskHandler with hot-merge and wake-up-merge patterns. BackgroundTask lifecycle (INIT→RUNNING→SUCCESS/FAILED), PendingQueue for async result queuing, merge callbacks, state node integration.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/background.py` (~230 lines), `packages/orbiter-core/tests/test_background.py` (28 tests in 8 classes)
- Key implementation details:
  - `BackgroundTask` — tracks task_id, parent_task_id, payload, result, error, status, merge_mode
  - `PendingQueue` — async-aware queue with `push()`, `pop_all()`, `wait(timeout)` using `asyncio.Event`
  - `BackgroundTaskHandler` — `submit()` registers tasks, `handle_result()` routes to hot or wake-up merge, `handle_error()` for failures, `drain_pending()` async iterator for wake-up pattern
  - Hot-merge: fires registered callbacks when main task is still running
  - Wake-up-merge: queues to PendingQueue when main task completed; drain via `drain_pending()`
  - State integration: creates RunNode with `bg:{task_id}` agent name, marks SUCCESS/FAILED on completion
  - `on_merge(callback)` for registering async merge callbacks
  - `list_tasks(status=...)` for filtered task listing
- **Learnings for future iterations:**
  - BackgroundTaskHandler is NOT a Handler[IN, OUT] subclass — it's a standalone manager rather than a pipeline handler, since background tasks have their own lifecycle separate from the main execution flow
  - `asyncio.TimeoutError` is deprecated in favor of builtin `TimeoutError` (ruff UP041) — just catch `TimeoutError`
  - Unused imports (ruff F401) must be removed even from type-only usage — `RunNode` was imported but only `RunNodeStatus` and `RunState` were needed
  - 547 tests total across full suite (28 new background handler tests)
---

## 2026-02-15 - US-015
- What was implemented: Runner integration tests covering end-to-end Agent + @tool + run() flows, handler pipelines (workflow, handoff, team), ToolHandler/GroupHandler integration, and background task scenarios (hot-merge, wake-up-merge, error handling, callbacks). Updated `packages/orbiter-core/src/orbiter/__init__.py` with public API exports (Agent, run, tool, Tool, FunctionTool).
- Files changed: `packages/orbiter-core/src/orbiter/__init__.py` (added imports + __all__), `packages/orbiter-core/tests/test_runner_integration.py` (22 new tests in 8 test classes)
- **Learnings for future iterations:**
  - `run.sync()` uses `asyncio.run()` which can't be called from within an async test function (already has a running event loop) — make sync tests use `def test_...` (not `async def`)
  - Ruff N817 flags `import X as A` when `A` is a CamelCase name used as an acronym — use longer aliases like `AgentImport` instead of `A`
  - The `__init__.py` for orbiter-core already uses `pkgutil.extend_path()` for namespace packages — imports of `Agent`, `run`, `tool`, `Tool` go after that line
  - 569 tests total across full suite (22 new integration tests)
---

## 2026-02-15 - US-016
- What was implemented: Graph utilities module with `Graph` dataclass (adjacency list), `topological_sort()` (Kahn's algorithm with deterministic ordering), cycle detection, and `parse_flow_dsl()` for parsing flow DSL strings like `"a >> b >> c"` and `"(a | b) >> c"` into Graph objects.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/graph.py` (~130 lines), `packages/orbiter-core/tests/test_graph.py` (31 tests in 4 classes)
- Key implementation details:
  - `Graph` is a `@dataclass` with `_adjacency: dict[str, list[str]]` — add_node (idempotent), add_edge (duplicate-safe, auto-creates nodes), nodes/edges properties, successors(), in_degree()
  - `topological_sort()` uses Kahn's algorithm with `deque` — sorts queue entries for deterministic ordering
  - `parse_flow_dsl()` tokenizes by `>>`, handles `(a | b)` parallel groups via regex, creates edges between all members of consecutive stages
  - `GraphError` raised for cycles, unknown nodes, empty/malformed DSL
- **Learnings for future iterations:**
  - GroupHandler in `handlers.py` already has an inline topo sort (`_resolve_order`) — could be refactored to use graph.py in a future iteration, but not required now
  - `deque.popleft()` is O(1) vs `list.pop(0)` which is O(n) — prefer deque for BFS-style queue operations
  - The `parse_flow_dsl` returns a `Graph` (not just edges) so callers can use `topological_sort()` directly on the result
  - 600 tests total across full suite (31 new graph tests)
---

## 2026-02-15 - US-017
- What was implemented: Swarm class with workflow mode (`packages/orbiter-core/src/orbiter/swarm.py`, ~120 lines). Workflow mode runs agents sequentially with output→input chaining. Uses `parse_flow_dsl()` and `topological_sort()` from graph.py for execution ordering. Updated `runner.py` to detect Swarm (via `hasattr(agent, "flow_order")`) and delegate to `swarm.run()`.
- Files changed: `packages/orbiter-core/src/orbiter/swarm.py` (new, ~120 lines), `packages/orbiter-core/tests/test_swarm.py` (new, 20 tests in 5 classes), `packages/orbiter-core/src/orbiter/runner.py` (added Swarm detection in `run()`)
- Key implementation details:
  - `Swarm.__init__` accepts `agents` (list), `flow` (DSL string, optional), `mode` (default "workflow")
  - Without flow DSL, agents execute in list order. With flow DSL, topological sort determines order
  - `Swarm.run()` delegates to `call_runner()` per agent, chaining output→input
  - Validates: no duplicate agent names, all flow DSL nodes are known agents, no cycles
  - `SwarmError` for all swarm-level errors
  - `describe()` and `__repr__()` for introspection
  - Swarm has a `name` attribute for runner compatibility
- **Learnings for future iterations:**
  - Swarm detection in `run()` uses duck-typing (`hasattr(agent, "flow_order")`) rather than isinstance to avoid circular imports — this works because Agent doesn't have a `flow_order` attribute
  - Swarm.run() has its own `provider` and `max_retries` params, but doesn't take `loop_threshold` (that's Agent-level via call_runner)
  - The AgentHandler from handlers.py already has workflow mode — Swarm is a higher-level API that wraps the same call_runner() directly without going through AgentHandler. Future handoff/team modes (US-018, US-019) may leverage AgentHandler's existing implementations
  - 620 tests total across full suite (20 new swarm tests)
---

## 2026-02-15 - US-018
- What was implemented: Swarm handoff mode (`mode='handoff'`) with dynamic agent-to-agent delegation. Added `_run_handoff()` (handoff chain execution with conversation history transfer), `_detect_handoff()` (output-based handoff detection matching agent's declared handoff targets), and `max_handoffs` parameter for loop detection.
- Files changed: `packages/orbiter-core/src/orbiter/swarm.py` (added ~70 lines for handoff mode), `packages/orbiter-core/tests/test_swarm.py` (added 15 tests in 4 new test classes)
- Key implementation details:
  - `_run_handoff()` starts with the first agent in flow_order, runs it via `call_runner()`, checks output against handoff targets
  - `_detect_handoff()` matches `result.output.strip()` against agent's `handoffs` dict keys, also requires target exists in `swarm.agents`
  - `max_handoffs` uses `>` semantics (default 10): allows exactly `max_handoffs` transitions before raising `SwarmError`
  - Conversation history from each agent's run (`result.messages`) is passed to the next agent as `all_messages`
  - Handoff target not in swarm's agents dict → no handoff (agent output returned as-is)
- **Learnings for future iterations:**
  - `max_handoffs` boundary: use `>` not `>=` so that `max_handoffs=N` allows exactly N handoffs. The AgentHandler in handlers.py uses `>=` which is slightly different semantics
  - `call_runner` builds messages internally per agent — the `result.messages` from RunState are minimal (system + user + assistant). Passing them as `all_messages` to the next call_runner allows conversation history transfer, but each agent still builds its own message list
  - Ruff RUF043: regex metacharacters in `pytest.raises(match=...)` require raw strings (e.g., `match=r"Max handoffs.*3.*exceeded"`)
  - 635 tests total across full suite (15 new handoff tests)
---

## 2026-02-15 - US-019
- What was implemented: Swarm team mode (`mode='team'`) with lead-worker delegation pattern. Lead agent gets auto-generated `_DelegateTool` instances (`delegate_to_{worker_name}`) that invoke worker agents when called. Workers run via `call_runner()` and return their output as tool results. Lead synthesizes final output after receiving worker results.
- Files changed: `packages/orbiter-core/src/orbiter/swarm.py` (added `_run_team()` ~50 lines, `_DelegateTool` class ~50 lines), `packages/orbiter-core/tests/test_swarm.py` (added 13 tests in 4 new test classes)
- Key implementation details:
  - `_DelegateTool` is a `Tool` subclass with manually defined JSON schema (task parameter), calls `call_runner()` on the worker
  - `_run_team()` temporarily adds delegate tools to lead's `self.tools`, runs `call_runner(lead, ...)`, then restores original tools in a `finally` block
  - Team mode requires at least 2 agents (lead + at least one worker)
  - Workers receive the lead's tool-call argument `task` as their input, not the original user input
- **Learnings for future iterations:**
  - Mock providers for team mode need `Usage` objects (not `None`) in dict-form responses — `parse_response(usage=None)` causes `AgentOutput` Pydantic validation to fail, which gets caught by `_call_llm`'s retry loop, consuming the next response instead
  - The provider `complete()` call count is shared across lead + worker agents since the mock is a single closure — responses must be ordered accounting for worker calls interleaved with lead calls
  - `_DelegateTool` follows the same pattern as `HumanInputTool` — custom `Tool` subclass with manually defined JSON schema rather than `_generate_schema()` from a function
  - Using `finally` block to restore tools ensures cleanup even on errors (important for tool-loop exceptions propagating up)
  - 648 tests total across full suite (13 new team mode tests)
---

## 2026-02-15 - US-020
- What was implemented: ParallelGroup (concurrent agent execution via `asyncio.TaskGroup` with configurable result aggregation) and SerialGroup (sequential output→input chaining) in `packages/orbiter-core/src/orbiter/_internal/agent_group.py`. Both integrate as nodes in Swarm workflow via `is_group` marker attribute. Swarm's `_run_workflow()` updated to detect groups and delegate to their `run()` method.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/agent_group.py` (new, ~236 lines), `packages/orbiter-core/tests/test_agent_group.py` (new, 27 tests in 7 classes), `packages/orbiter-core/src/orbiter/swarm.py` (updated `_run_workflow` for group detection)
- Key implementation details:
  - `ParallelGroup` — concurrent execution via `asyncio.TaskGroup`, default join with `\n\n` separator, optional custom `aggregate_fn(list[RunResult]) -> str`, usage/steps summed across all agents
  - `SerialGroup` — sequential execution with output→input chaining, accumulated usage/steps, final agent's output is the group output
  - Both have `is_group = True` marker, `name` attribute, `run()` method matching Agent/Swarm interface, and `describe()`/`__repr__()` for introspection
  - Swarm detects groups via `getattr(agent, "is_group", False)` in `_run_workflow()` — similar duck-typing pattern as Swarm detection in `runner.py`
  - Groups can be used standalone (without Swarm) or as nodes in Swarm flow DSL
- **Learnings for future iterations:**
  - Groups need the same interface as agents from Swarm's perspective: `name` attribute and `run(input, *, messages, provider, max_retries)` method
  - Duck-typing via `is_group` marker is cleaner than isinstance checks since it avoids circular imports
  - The existing `GroupHandler` in `handlers.py` has similar parallel/serial logic but operates at the handler layer — `ParallelGroup`/`SerialGroup` are the public-facing API while `GroupHandler` is the internal handler abstraction
  - 675 tests total across full suite (27 new agent group tests)
---

## 2026-02-15 - US-021
- What was implemented: Nested swarm support via `SwarmNode` wrapper class in `packages/orbiter-core/src/orbiter/_internal/nested.py`. `SwarmNode` wraps a Swarm so it can be used as a node in another Swarm's agent list. Context isolation: inner swarm gets clean message history (outer messages NOT forwarded). Updated `Swarm._run_workflow()` to detect `is_swarm` marker via duck-typing.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/nested.py` (new, ~107 lines), `packages/orbiter-core/tests/test_nested.py` (new, 14 tests in 5 classes), `packages/orbiter-core/src/orbiter/swarm.py` (1-line change in `_run_workflow`)
- Key implementation details:
  - `SwarmNode` has `is_swarm = True` marker, `name` attribute, and `run()` method — same interface pattern as `ParallelGroup`/`SerialGroup` with `is_group`
  - `_run_workflow()` condition: `getattr(agent, "is_group", False) or getattr(agent, "is_swarm", False)` — both groups and nested swarms use `agent.run()` directly
  - Context isolation: `SwarmNode.run()` does NOT forward outer `messages` to inner swarm — each level maintains its own conversation context
  - Inner swarm can use any mode (workflow, handoff, team) — tested with both workflow and handoff modes
  - `NestedSwarmError` for validation errors, `describe()` includes inner swarm metadata
- **Learnings for future iterations:**
  - The duck-typing pattern (`is_group`, `is_swarm`) is consistent across the codebase for detecting node types without isinstance checks
  - `Agent.__init__` expects `handoffs` as `list[Agent]`, NOT `dict` — the dict is built internally by `_register_handoff()`
  - SwarmNode's context isolation is a design choice: inner swarm starts fresh each time, which prevents message pollution between nesting levels
  - 689 tests total across full suite (14 new nested swarm tests)
---

## 2026-02-15 - US-022
- What was implemented: Swarm integration with the public `run()` API and public API exports. Updated `packages/orbiter-core/src/orbiter/__init__.py` to export `Swarm`, `SwarmNode`, `ParallelGroup`, `SerialGroup`. Created comprehensive integration tests covering all swarm modes and features via the public `run()` entry point.
- Files changed: `packages/orbiter-core/src/orbiter/__init__.py` (added 6 new exports), `packages/orbiter-core/tests/test_swarm_integration.py` (new, 21 tests in 8 classes)
- Integration test coverage:
  - Workflow mode: 2-agent, 3-agent pipeline, no-flow-DSL, sync wrapper
  - Handoff mode: simple handoff, A→B→C chain, no-handoff-returns-directly
  - Team mode: lead-delegates-to-worker, lead-no-delegation
  - Groups: ParallelGroup in workflow, SerialGroup in workflow, custom aggregation
  - Nested swarms: nested workflow, nested handoff-inside-workflow
  - Public API: Swarm/SwarmNode/ParallelGroup/SerialGroup importable from `orbiter`, run() detects Agent vs Swarm
  - Tools in workflows: agent uses @tool then chains to next agent
- **Learnings for future iterations:**
  - Swarm was already wired into `run()` via `hasattr(agent, "flow_order")` from US-017 — this story only needed to add public exports and integration tests
  - The `_make_provider` mock must account for ALL LLM calls across ALL agents in a swarm (e.g., 3-agent pipeline = 3 responses, team with delegation = lead + worker + lead = 3 responses)
  - `__init__.py` imports must be sorted alphabetically by module path for ruff I001 compliance
  - 710 tests total across full suite (21 new swarm integration tests)
---

## 2026-02-15 - US-023
- What was implemented: Created `orbiter-context` package from scratch — added workspace registration, pyproject.toml, directory structure. Implemented `ContextConfig` (Pydantic v2 frozen model with `AutomationMode` enum: pilot/copilot/navigator, history_rounds, summary_threshold, offload_threshold, enable_retrieval, neuron_names tuple, extra dict, threshold validation) and `make_config()` factory with preset defaults per automation level. Implemented `ContextState` (hierarchical key-value store with parent chain lookup, write isolation, get/set/update/delete/pop/clear/to_dict/local_dict/keys).
- Files changed:
  - `pyproject.toml` (root — added orbiter-context to workspace members, dev deps, uv.sources)
  - `packages/orbiter-context/pyproject.toml` (new package config)
  - `packages/orbiter-context/src/orbiter/context/__init__.py` (new)
  - `packages/orbiter-context/src/orbiter/context/config.py` (~120 lines — AutomationMode, ContextConfig, make_config)
  - `packages/orbiter-context/src/orbiter/context/state.py` (~130 lines — ContextState)
  - `packages/orbiter-context/tests/test_context_config.py` (22 tests: defaults, frozen, validation, neuron coercion, serialization, factory)
  - `packages/orbiter-context/tests/test_context_state.py` (35 tests: read/write, delete/pop/clear, update, parent inheritance, introspection, bool, repr)
- **Learnings for future iterations:**
  - Creating a new namespace package requires adding it to 3 places in root pyproject.toml: `[tool.uv.workspace] members`, `[dependency-groups] dev`, and `[tool.uv.sources]`
  - Same pyright `reportMissingImports` issue applies to orbiter-context test files — use `# pyright: ignore[reportMissingImports]` on import lines
  - `ContextState` uses `__slots__` for memory efficiency — all instance attributes (`_data`, `_parent`) must be declared there
  - Pydantic v2 frozen models: use `model_validator(mode="after")` for cross-field validation (e.g., summary_threshold <= offload_threshold)
  - Use `tuple[str, ...]` (not `list`) for frozen model fields that should be immutable; accept `list` via `model_validator(mode="before")` coercion
  - 767 tests total across full suite (57 new context tests)
---

## 2026-02-15 - US-024
- What was implemented: Context class with fork/merge for hierarchical task decomposition. `ContextError` exception. `Context.__init__` accepts task_id (required), config, parent, state. Properties: task_id, config, parent, state, children, token_usage. `add_tokens()` for token tracking. `fork(task_id)` creates child context with state inheritance and token snapshot. `merge(child)` consolidates child local state and net token deltas back into parent.
- Files changed: `packages/orbiter-context/src/orbiter/context/context.py` (new, ~160 lines), `packages/orbiter-context/tests/test_context.py` (new, 35 tests in 8 classes), `packages/orbiter-context/tests/test_context_config.py` (import sorting fix from ruff)
- Key implementation details:
  - `_token_snapshot` stores parent's usage at fork time (immutable copy), separate from `_token_usage` which tracks current usage. Merge computes net = current - snapshot
  - `fork()` auto-sets child's config from parent (shared immutable reference), creates ContextState with parent chain, copies token usage as starting point
  - `merge()` validates child.parent identity, merges child's `local_dict()` state, adds net-positive token deltas
  - `__slots__` for memory efficiency, sorted alphabetically per ruff RUF023
- **Learnings for future iterations:**
  - Within-package imports (e.g., `context.py` importing from `config.py` in the same `orbiter.context` namespace package) also need `# pyright: ignore[reportMissingImports]` due to `.pth`-based editable installs
  - Ruff RUF023 requires `__slots__` entries to be sorted alphabetically — use `--fix` to auto-sort
  - For net token merge calculation, storing a separate `_token_snapshot` at fork time is essential — the `_token_usage` dict gets mutated by `add_tokens()` and can't serve as its own baseline
  - 802 tests total across full suite (35 new context tests)
---

## 2026-02-15 - US-025
- What was implemented: TokenTracker — per-agent, per-step token tracking for cost analysis and budget enforcement. `TokenStep` (frozen dataclass with agent_id, step index, prompt/output tokens, total_tokens property). `TokenUsageSummary` (frozen dataclass for aggregated usage). `TokenTracker` (add_step with auto step indexing, get_trajectory, total_usage, agent_usage, agent_ids, steps, len/repr).
- Files changed: `packages/orbiter-context/src/orbiter/context/token_tracker.py` (new, ~130 lines), `packages/orbiter-context/tests/test_token_tracker.py` (new, 24 tests in 7 classes)
- **Learnings for future iterations:**
  - TokenTracker is standalone (no dependencies on Context/ContextState) — it can be used independently or composed into Context
  - `dataclass(frozen=True, slots=True)` is the right pattern for immutable value objects like TokenStep/TokenUsageSummary
  - Step index is per-agent (computed by counting existing steps for the agent), not global — this makes trajectories self-contained
  - The `field` import from dataclasses wasn't needed (no mutable defaults) — ruff F401 catches unused imports
  - 826 tests total across full suite (24 new token tracker tests)
---

## 2026-02-15 - US-026
- What was implemented: Neuron ABC with `__slots__`, `neuron_registry` (Registry[Neuron]), and three built-in neurons: `SystemNeuron` (priority 100 — date/time/platform via `datetime.UTC`), `TaskNeuron` (priority 1 — task_id, input, output, subtask plan from context state), `HistoryNeuron` (priority 10 — windowed conversation history using `ctx.config.history_rounds`).
- Files changed: `packages/orbiter-context/src/orbiter/context/neuron.py` (new, ~130 lines), `packages/orbiter-context/tests/test_neuron.py` (new, 32 tests in 6 classes)
- Key implementation details:
  - Neuron ABC has `name` (str) and `priority` (int) properties, abstract `async format(ctx, **kwargs) -> str`
  - XML-like tags wrap neuron output (e.g., `<system_info>`, `<task_info>`, `<conversation_history>`) for LLM clarity
  - HistoryNeuron windowing: `history_rounds * 2` messages from end (each round = user + assistant)
  - SystemNeuron uses `datetime.UTC` (not `timezone.utc`) per ruff UP017
  - Built-in neurons registered at module level: `neuron_registry.register("system", SystemNeuron())`
- **Learnings for future iterations:**
  - `datetime.UTC` is the preferred alias over `timezone.utc` — ruff UP017 enforces this
  - Registry[Neuron] from orbiter-core works well for neuron discovery across packages
  - The two-level design from old AWorld (format_items → format) was simplified to single `format()` — the old pattern was over-engineered for most use cases
  - 858 tests total across full suite (32 new neuron tests)
---

## 2026-02-15 - US-027
- What was implemented: Six extended neurons (TodoNeuron, KnowledgeNeuron, WorkspaceNeuron, SkillNeuron, FactNeuron, EntityNeuron) added to `neuron.py` with proper priorities. Dynamic variable system (`DynamicVariableRegistry`) with nested path resolution, callable/static resolver registration, decorator form, and `resolve_template()` for `${path}` substitution in `variables.py`.
- Files changed: `packages/orbiter-context/src/orbiter/context/neuron.py` (+180 lines — 6 new neuron classes + registration), `packages/orbiter-context/src/orbiter/context/variables.py` (new, ~132 lines), `packages/orbiter-context/tests/test_extended_neurons.py` (new, 46 tests in 11 classes)
- Key implementation details:
  - All extended neurons follow the same pattern: read from `ctx.state`, return empty string if no data, format with XML-like tags
  - TodoNeuron reads `todos` (list of {item, done}), KnowledgeNeuron reads `knowledge_items` (list of {source, content}), WorkspaceNeuron reads `workspace_artifacts` (list of {name, type, size}), SkillNeuron reads `skills` (list of {name, description, active}), FactNeuron reads `facts` (list of strings), EntityNeuron reads `entities` (list of {name, type})
  - DynamicVariableRegistry: registered resolvers take priority over nested path lookup. `resolve()` checks resolvers first, then falls back to `_resolve_nested()` which walks dot-separated paths through dicts/ContextState/objects. `resolve_template()` uses regex to substitute `${path}` placeholders
  - All 9 neurons are registered at module level in neuron_registry
- **Learnings for future iterations:**
  - Extended neurons are intentionally simple — each reads from a well-known state key and formats it. Complex logic (populating those state keys) belongs in processors/tools, not neurons
  - DynamicVariableRegistry is separate from neuron system — neurons produce prompt fragments, variables resolve individual values. The PromptBuilder (US-028) will likely use both
  - `re.sub` with a callable replacement function is clean for template resolution with error handling per-variable
  - 904 tests total across full suite (46 new: 32 neuron tests, 14 variable tests)
---

## 2026-02-15 - US-028
- What was implemented: PromptBuilder — composes neurons in priority order to build rich system prompts. `PromptBuilder.__init__(ctx, *, variables, separator)`, `add(neuron_name, **kwargs)` for registry lookup, `add_neuron(neuron, **kwargs)` for direct instances, `async build()` resolves all neurons by priority, filters empty results, joins with separator, and optionally resolves `${path}` template variables via DynamicVariableRegistry. Also: `clear()`, `__len__`, `__repr__`, method chaining. Internal `_NeuronEntry` pairs neuron with kwargs.
- Files changed: `packages/orbiter-context/src/orbiter/context/prompt_builder.py` (new, ~130 lines), `packages/orbiter-context/tests/test_prompt_builder.py` (new, 30 tests in 9 classes)
- Test coverage: init/repr (3), add neurons by name/instance/chaining (5), build with empty/single/multiple/custom separator/filtered empty (6), priority ordering/stability/registered neurons (3), variable resolution/unresolvable/no-vars/multiple/across-neurons (5), kwargs forwarding (1), clear (2), context traversal with parent state/overridden state (2), integration with built-in neurons and full composition (3)
- **Learnings for future iterations:**
  - Ruff I001 import sorting and pyright `reportMissingImports` ignore comments conflict on multi-line parenthesized imports: ruff reformats `from X import Y  # pyright: ignore[...]` into `from X import (\n    Y,  # pyright: ignore[...]\n)`, but pyright reports the error on the `from` line, not the import name line. Solution: put `# pyright: ignore[reportMissingImports]` on the `from` line: `from X import (  # pyright: ignore[reportMissingImports]\n    Y,\n)`
  - PromptBuilder's `build()` uses Python's stable sort (`sorted()`) to preserve insertion order for neurons with equal priority — important for deterministic prompt construction
  - Template variable resolution happens AFTER joining all neuron fragments — this means variables can span across neuron outputs but resolution applies to the final composed string
  - 934 tests total across full suite (30 new prompt builder tests)
---

## 2026-02-15 - US-029
- What was implemented: ContextProcessor pipeline — event-driven context processing system. `ContextProcessor` ABC with `event` (str) and `async process(ctx, payload)`. `ProcessorPipeline` with `register()` (chaining), `unregister()`, `fire(event, ctx, payload)`, `has_processors()`, `list_processors()`, `clear()`, `__len__`, `__repr__`. Two built-in processors: `SummarizeProcessor` (`pre_llm_call` — marks context for summarization when history exceeds `ctx.config.summary_threshold`, stores excess messages as `summary_candidates`), `ToolResultOffloader` (`post_tool_call` — offloads large tool results exceeding `max_size` to `offloaded_results` in state, replaces payload with truncated reference).
- Files changed: `packages/orbiter-context/src/orbiter/context/processor.py` (new, ~190 lines), `packages/orbiter-context/tests/test_context_processor.py` (new, 39 tests in 7 classes)
- Test coverage: ABC tests (5: create, name, empty event error, repr, abstract enforcement), Pipeline registration (10: register, multiple same event, different events, unregister, unregister-not-registered, chaining, clear, list-all, list-filtered, repr), Pipeline fire (7: calls processor, no-match, default payload, sequential order, state mutation, error propagation, stops on first error), SummarizeProcessor (5: defaults, no history, below threshold, at threshold, exceeds threshold + pipeline), ToolResultOffloader (7: defaults, custom max_size, no result, small result, large result offload, multiple accumulate, default tool name + pipeline), Integration (3: multiple events, chain mutation, full lifecycle)
- **Learnings for future iterations:**
  - Ruff SIM105 requires `contextlib.suppress(ValueError)` instead of try/except/pass — already consistent with HookManager pattern in hooks.py
  - ProcessorPipeline follows similar patterns to HookManager (sequential execution, error propagation) but uses string event types instead of enum values, which is more flexible for user-defined events
  - ToolResultOffloader mutates the `payload` dict in-place to replace tool results — this is by design since the caller needs to see the modified payload
  - 973 tests total across full suite (39 new processor tests)
---

## 2026-02-15 - US-030
- What was implemented: Workspace + artifact system — persistent artifact storage with versioning and observer notifications. `WorkspaceError`, `ArtifactType` (StrEnum: TEXT, CODE, MARKDOWN, JSON, CSV, IMAGE), `ArtifactVersion` (immutable snapshot with content + timestamp), `Artifact` (named artifact with type, content, version history), `ObserverCallback` type alias, `Workspace` (workspace_id, storage_path, write/read/get/list/delete, version_history/revert_to_version, observer on/notify, filesystem persistence).
- Files changed: `packages/orbiter-context/src/orbiter/context/workspace.py` (new, ~210 lines), `packages/orbiter-context/tests/test_workspace.py` (new, 40 tests in 8 classes)
- Test coverage: ArtifactType (2: values, StrEnum), ArtifactVersion (3: creation, auto-timestamp, repr), Artifact (4: creation, default type, add version, repr), Workspace init (4: creation, empty id, storage path, repr), CRUD (10: write/read, read missing, get, get missing, empty name, list all, list by type, delete, delete missing, overwrite), Versioning (6: history, missing history, revert, revert missing, invalid version, negative version), Observers (6: on_create, on_update, on_delete, multiple, chaining, no observer), Filesystem (5: write persists, delete removes, overwrite updates, no storage path, revert persists)
- **Learnings for future iterations:**
  - `shutil.rmtree()` is the clean way to recursively delete artifact directories on delete
  - Observer pattern uses `dict[str, list[ObserverCallback]]` — simple and extensible for custom event names beyond on_create/on_update/on_delete
  - `Workspace.on()` returns `self` for chaining — consistent with ProcessorPipeline.register() pattern
  - Artifact versioning uses append-only `_versions` list — revert creates a NEW version with old content rather than truncating history
  - 1013 tests total across full suite (40 new workspace tests)
---

## 2026-02-15 - US-031
- What was implemented: Workspace-retriever integration — `KnowledgeStore` with in-memory artifact indexing, text chunking with overlap, keyword search (TF-IDF-like scoring), and chunk range queries. Workspace auto-indexes artifacts on write/update and de-indexes on delete via `knowledge_store` parameter.
- Files changed:
  - `packages/orbiter-context/src/orbiter/context/_internal/__init__.py` (new, empty)
  - `packages/orbiter-context/src/orbiter/context/_internal/knowledge.py` (new, ~195 lines — KnowledgeError, Chunk, SearchResult, chunk_text(), KnowledgeStore with add/remove/get/get_range/search)
  - `packages/orbiter-context/src/orbiter/context/workspace.py` (modified — added `knowledge_store` param, `_index_artifact`, `_deindex_artifact` methods, auto-indexing in write/delete)
  - `packages/orbiter-context/tests/test_knowledge.py` (new, 41 tests in 11 classes)
- Test coverage: chunk_text (8: short/empty/exact/overlap/no-overlap/invalid-size/invalid-overlap/negative), Chunk (2: creation, immutability), SearchResult (1), KnowledgeStore init (3: defaults, custom, repr), add (5: short/long/empty-name/re-add/multiple), remove (2: existing/missing), get (2: existing/missing), get_range (3: range/missing/no-overlap), search (7: keyword/multi-term/no-results/empty/top_k/ranking/empty-store), workspace integration (8: auto-index/update-re-index/delete-removes/no-store/round-trip/multi-artifact/property/default)
- **Learnings for future iterations:**
  - `_internal/` directory pattern: US-033 will enhance KnowledgeStore with more features — the module is in `_internal/knowledge.py` so US-033 can extend it
  - Workspace `knowledge_store` typed as `Any` to avoid circular import — duck-typing: any object with `add(name, content)` and `remove(name)` methods works
  - chunk_text's loop uses `end >= len(text)` break condition, so the last chunk may be full-size (not always short) when end exactly equals text length
  - TF-IDF scoring uses `log(1 + tf)` per term, which dampens high-frequency terms — simple but effective for keyword search
  - 1054 tests total across full suite (41 new knowledge/integration tests)
---

## 2026-02-15 - US-032
- What was implemented: Checkpoint system — save and restore complete execution state for long-running tasks. `Checkpoint` (frozen dataclass with task_id, version, values, token_usage, metadata, created_at; includes `to_dict()`/`from_dict()` serialization). `CheckpointStore` (per-session versioned store with `save()`, `get(version)`, `latest`, `list_versions()`). `Context.snapshot()` captures state + token usage into a versioned checkpoint. `Context.restore()` classmethod creates a fresh context from a checkpoint.
- Files changed:
  - `packages/orbiter-context/src/orbiter/context/checkpoint.py` (new, ~160 lines — CheckpointError, Checkpoint, CheckpointStore)
  - `packages/orbiter-context/src/orbiter/context/context.py` (added ~70 lines — `_checkpoint_store` slot, `checkpoints` property, `snapshot()`, `restore()` classmethod)
  - `packages/orbiter-context/tests/test_checkpoint.py` (new, 35 tests in 7 classes)
- Test coverage: Checkpoint creation/metadata/immutable/repr/to_dict/from_dict/roundtrip (7), CheckpointStore creation/empty-id/save/version-increment/metadata/get/invalid-version/latest/list-versions/repr (10), Context.snapshot basic/empty/metadata/version-increment/captures-current (5), Context.restore basic/config/fresh-context/no-parent/no-checkpoints/invalid-type (6), Checkpoints property/per-context/forked-own-store (3), Full roundtrip/old-version/serialization/fork-snapshot (4)
- **Learnings for future iterations:**
  - Checkpoint is a frozen dataclass (not Pydantic) since it's a simple value object — no need for validation beyond what the store provides
  - CheckpointStore uses 1-based versioning (version starts at 1, not 0) — consistent with user-facing version numbering
  - Context.restore() is a classmethod that creates a completely fresh context with no parent/children/checkpoint-history — it's a clean slate with restored state values
  - Forked child's `snapshot()` captures `to_dict()` which includes inherited parent values — so restoring captures the full merged view, not just local state
  - 1089 tests total across full suite (35 new checkpoint tests)
---

## 2026-02-15 - US-033
- What was implemented: US-033 acceptance criteria were already fully satisfied by US-031's implementation. Verified: `_internal/__init__.py` exists, `_internal/knowledge.py` has complete KnowledgeStore (234 lines) with `add`, `search`, `get`, `get_range`, `remove`, `artifact_names`, `total_chunks`. Basic chunking via `chunk_text()` with overlap support. TF-IDF keyword search serving as the in-memory search for testing. 41 existing tests cover all criteria.
- Files: No changes needed — all code already in place from US-031
- Quality checks: ruff check ✓, ruff format ✓, pyright 0 errors ✓, pytest 1089 passed ✓
- **Learnings for future iterations:**
  - US-031 (workspace-retriever integration) already implemented the full KnowledgeStore that US-033 was supposed to create — check for pre-existing implementations before coding
  - When a PRD story's acceptance criteria are already met by prior work, verify quality checks and mark as passing rather than duplicating code
---

## 2026-02-15 - US-034
- What was implemented: Context tools — planning, knowledge, and file tools for agent self-management. `_ContextTool` subclass of `Tool` with `bind(ctx)` pattern to inject context at execution time while hiding `ctx` from JSON schema. Planning tools (`add_todo`, `complete_todo`, `get_todo`) for task checklist management via `ctx.state`. Knowledge tools (`get_knowledge`, `grep_knowledge`, `search_knowledge`) for artifact retrieval via workspace and knowledge store. File tool (`read_file`) with path traversal protection via `resolve()` + prefix check.
- Files changed:
  - `packages/orbiter-context/src/orbiter/context/tools.py` (new, ~255 lines — _ContextTool, 7 tools, 4 factory functions)
  - `packages/orbiter-context/tests/test_context_tools.py` (new, 38 tests in 11 classes)
- Key implementation details:
  - `_ContextTool` extends `Tool` ABC with `bind(ctx)` method — context injected at runtime, stripped from JSON schema via post-processing of `_generate_schema()` output
  - Planning tools store todos as `list[dict]` in `ctx.state["todos"]` with `{item, done}` shape
  - Knowledge tools read from `ctx.state["workspace"]` (Workspace) and `ctx.state["knowledge_store"]` (KnowledgeStore)
  - `grep_knowledge` uses `re.compile(pattern, re.IGNORECASE)` with invalid regex error handling
  - `read_file` prevents path traversal via `Path.resolve()` + `str.startswith()` prefix check against working directory
  - Factory functions: `get_planning_tools()`, `get_knowledge_tools()`, `get_file_tools()`, `get_context_tools()` (all 7)
- **Learnings for future iterations:**
  - orbiter-context depends on orbiter-core, so `@tool` decorator and `Tool` ABC can be imported directly — no need for cross-package workarounds
  - `_ContextTool` pattern: custom Tool subclass that strips `ctx` from schema and injects it via `bind()` — this avoids exposing internal context to the LLM while keeping tools testable
  - Module-level tool singletons (e.g., `planning_tool_add`) are mutable via `bind()` — tests must call `bind(ctx)` before each test to set the right context
  - ruff auto-fix may move `# pyright: ignore[reportMissingImports]` from the `from` line to individual import names inside parenthesized imports — the ignore must stay on the `from` line for pyright to see it
  - 1127 tests total across full suite (38 new context tools tests)
---

## 2026-02-15 - US-035
- What was implemented: Context package public API (`__init__.py` with 23 exports) and 26 integration tests. All exports organized in `__all__`. Agent context wiring already in place from US-003 (verified by integration tests).
- Files changed:
  - `packages/orbiter-context/src/orbiter/context/__init__.py` (rewritten — 23 public exports: Context, ContextConfig, ContextState, ContextError, AutomationMode, make_config, PromptBuilder, Neuron, neuron_registry, ContextProcessor, ProcessorPipeline, SummarizeProcessor, ToolResultOffloader, Workspace, ArtifactType, Checkpoint, CheckpointStore, TokenTracker, get_context_tools, get_planning_tools, get_knowledge_tools, get_file_tools)
  - `packages/orbiter-context/tests/test_context_integration.py` (new, 26 tests in 7 test classes)
- Integration test coverage:
  - Public API imports (8 tests): core classes, prompt building, processors, workspace, checkpoint, config, token tracker, tool factories
  - Context+PromptBuilder E2E (4 tests): basic prompt building, history, todos, full composition with priority ordering
  - Context+Processor E2E (3 tests): SummarizeProcessor trigger, ToolResultOffloader, multi-processor pipeline
  - Context+Workspace E2E (3 tests): write + knowledge search round-trip, versioning via context state, filesystem persistence
  - Full lifecycle (3 tests): create→populate→process→build prompt→checkpoint→restore, fork/merge with workspace, context tools with workspace
  - Custom processor (2 tests): custom processor mutates state, mixed with built-in processors
  - Agent context wiring (3 tests): Agent accepts context, default None, describe() stability
- **Learnings for future iterations:**
  - TaskNeuron reads from `task_input` state key (not `input`) — use the correct state key names as defined in each neuron's docstring
  - Agent.context is already wired as `Any` type from US-003 — no additional code changes needed in agent.py for this story
  - The `__init__.py` pattern for namespace packages: use `# pyright: ignore[reportMissingImports]` on each `from` line since editable installs use `.pth` files
  - 1153 tests total across full suite (26 new integration tests)
---

## 2026-02-15 - US-036
- What was implemented: Memory interface + types for the orbiter-memory package. `MemoryStatus` (StrEnum: draft/accepted/discard) with valid transition map. `MemoryMetadata` (frozen Pydantic: user_id, session_id, task_id, agent_id, extra). `MemoryItem` base class with id (auto UUID), content, memory_type, status, metadata, timestamps, `transition()` method with validation. Four subtypes: `SystemMemory` (system prompts), `HumanMemory` (user messages), `AIMemory` (assistant + tool_calls list), `ToolMemory` (tool results + tool_call_id, tool_name, is_error). `MemoryStore` runtime_checkable Protocol with async add/get/search/clear methods.
- Files changed: `packages/orbiter-memory/src/orbiter/memory/base.py` (new, ~120 lines), `packages/orbiter-memory/tests/test_memory_base.py` (new, 38 tests in 10 classes)
- Test coverage: MemoryStatus (2), MemoryMetadata (4: defaults, values, extra, frozen), MemoryItem (5: creation, custom id, default metadata, with metadata, draft status), Status transitions (7: valid transitions, invalid transitions, timestamp update), SystemMemory (2), HumanMemory (2), AIMemory (3), ToolMemory (3), Protocol conformance (10: isinstance, add/get, search by type/query/metadata/status/limit, clear all, clear with filter)
- **Learnings for future iterations:**
  - orbiter-memory package stub already existed (pyproject.toml, __init__.py, backends/__init__.py) — just needed base.py
  - For test classes that aren't dataclasses, ruff RUF012 does NOT apply to mutable class attributes — no need for ClassVar. But pyright DOES flag `ClassVar` + `__init__` reassignment as `reportAttributeAccessIssue`. Best to avoid ClassVar in regular classes.
  - `runtime_checkable` Protocol allows `isinstance()` checks — useful for verifying that store implementations satisfy the protocol
  - MemoryItem uses mutable Pydantic model (no frozen=True) since `transition()` mutates status and updated_at — same pattern as RunNode from state.py
  - Status transitions use an explicit transition map dict rather than methods per status — cleaner and more maintainable
  - 1191 tests total across full suite (38 new memory tests)
---

## 2026-02-15 - US-037
- What was implemented: ShortTermMemory — in-memory conversation store implementing MemoryStore protocol with scope-based filtering, configurable windowing, and tool call/response integrity filtering.
- Files changed: `packages/orbiter-memory/src/orbiter/memory/short_term.py` (new, ~130 lines), `packages/orbiter-memory/tests/test_short_term.py` (new, 32 tests in 8 classes)
- Key implementation details:
  - `ShortTermMemory(scope, max_rounds)` — scope: "user"|"session"|"task" (default "task"), max_rounds: 0 = unlimited
  - `_matches_metadata()` — scope-aware metadata matching: user scope ignores session/task, session scope ignores task, task scope checks all
  - `_window()` — finds human message positions, cuts at Nth-from-last, always preserves system messages before the cut
  - `_filter_incomplete_pairs()` — walks backwards removing trailing AI messages with unmatched tool_calls and orphan ToolMemory without matching AI call
  - All MemoryStore protocol methods implemented: add, get, search, clear
- Test coverage: init (5), add/get (3), basic search (5), scope filtering (4), windowing (4), tool call integrity (5), clear (3), integration (3)
- **Learnings for future iterations:**
  - Test helper functions with `**kw: str` conflict with other keyword args (e.g., `tool_calls: list`) when called with `**dict` — pyright treats the dict as potentially containing any string key. Fix: use explicit `meta` parameter instead of `**kw` pattern
  - Windowing by counting rounds from the end: use forward scan to find human message positions, then slice at `positions[-max_rounds]` — much simpler than backward counting which gets the boundary wrong
  - `_filter_incomplete_pairs` walks backwards in a `while` loop, popping trailing items that violate integrity — this handles both dangling AI tool calls and orphan tool results
  - 1223 tests total across full suite (32 new short-term memory tests)
---

## 2026-02-15 - US-038
- What was implemented: Summary trigger logic and multi-template summary generation. `SummaryTemplate` (StrEnum: conversation/facts/profiles) with default prompt templates. `SummaryConfig` (frozen dataclass: message_threshold, token_threshold, templates, prompts, keep_recent, token_estimate_ratio) with `get_prompt()` fallback. `check_trigger()` detects when message count or estimated token count exceeds thresholds. `Summarizer` runtime_checkable Protocol for pluggable LLM backends. `generate_summary()` splits items into compress-vs-keep-recent, formats conversation text, runs each configured template through the summarizer. `SummaryResult` with summaries dict, compressed_items, original_count. Helper: `_estimate_tokens()` (char/ratio), `_format_items()` (role-tagged lines).
- Files changed: `packages/orbiter-memory/src/orbiter/memory/summary.py` (new, ~130 lines), `packages/orbiter-memory/tests/test_summary.py` (new, 33 tests in 10 classes)
- Test coverage: SummaryTemplate values + default prompts (2), SummaryConfig defaults/custom/frozen/get_prompt (6), _estimate_tokens empty/single/multiple/custom-ratio (4), TriggerResult creation (1), check_trigger below/message/token/exact/empty/priority (6), _format_items empty/single/multi-type (3), generate_summary empty/single/multi-template/keep-recent/larger-than/custom-prompt/formatted-items (7), SummaryResult creation/defaults (2), Summarizer protocol conformance (2)
- **Learnings for future iterations:**
  - `Sequence` import: ruff UP035 requires `from collections.abc import Sequence` instead of `from typing import Sequence`
  - `SummaryConfig` uses frozen dataclass (not Pydantic) since it's a simple value object with no validation beyond defaults — consistent with `TokenStep` and `Checkpoint` patterns
  - The `Summarizer` protocol is intentionally minimal (single `async summarize(prompt) -> str` method) — callers wrap their LLM provider in this interface, keeping the summary module decoupled from any specific provider
  - `generate_summary` always generates summaries for all configured templates, even when `keep_recent >= len(items)` — this is by design since the summaries capture information from the conversation regardless of compression
  - 1256 tests total across full suite (33 new summary tests)
---

## 2026-02-15 - US-039
- What was implemented: Long-term memory orchestrator with `LongTermMemory` (MemoryStore-compatible persistent store with content deduplication and namespace isolation), `MemoryOrchestrator` (async LLM extraction of UserProfile, AgentExperience, Facts), `ExtractionTask` (lifecycle: PENDING→RUNNING→COMPLETED/FAILED), `Extractor` protocol, `OrchestratorConfig`, and processing task queue with status tracking.
- Files changed: `packages/orbiter-memory/src/orbiter/memory/long_term.py` (new, ~290 lines), `packages/orbiter-memory/tests/test_long_term.py` (new, 47 tests in 12 classes)
- Key implementation details:
  - `LongTermMemory` stores items in a dict[str, MemoryItem] for O(1) lookup by ID. Deduplicates by content+memory_type match (skips duplicate adds). Search sorts by created_at descending (newest first).
  - `ExtractionType` (StrEnum): user_profile, agent_experience, facts — each with default extraction prompts containing `{content}` placeholder.
  - `ExtractionTask` dataclass with start()/complete(result)/fail(error) lifecycle methods and completion timestamps.
  - `Extractor` runtime_checkable Protocol (single `async extract(prompt) -> str` method) — decoupled from LLM provider, similar to `Summarizer` protocol in summary.py.
  - `MemoryOrchestrator` manages task queue: `submit()` creates tasks (one per extraction type), `process()` runs single task through extractor and stores result in LongTermMemory, `process_all()` processes all pending tasks, `get_task()`/`list_tasks()` for task introspection.
  - Failed extraction tasks mark FAILED with error message but don't store anything in memory — clean failure handling.
- **Learnings for future iterations:**
  - `Extractor` protocol follows the same pattern as `Summarizer` — minimal single-method protocol for LLM integration. Callers wrap their provider.
  - `LongTermMemory` deduplication is by exact content+type match — intentionally simple. More sophisticated deduplication (semantic similarity) would require vector embeddings (US-042).
  - `_format_extraction_items` reuses the same `[ROLE]: content` format as `_format_items` in summary.py — could be shared but kept separate to avoid cross-module coupling.
  - `MemoryOrchestrator.process()` stores extracted knowledge with the extraction type as `memory_type` (e.g., "facts", "user_profile") — this allows `search(memory_type="facts")` to filter by extraction type.
  - 1303 tests total across full suite (47 new long-term memory tests)
---

## 2026-02-15 - US-040
- What was implemented: SQLiteMemoryStore — SQLite-backed persistent memory store implementing the MemoryStore protocol. Uses `aiosqlite` for async database access. Features: JSON metadata indexes via `json_extract()`, soft deletes (deleted flag), upsert with version bumping (`ON CONFLICT DO UPDATE SET version = version + 1`), async context manager lifecycle (`async with SQLiteMemoryStore(...) as store:`), and full MemoryItem subtype reconstruction on read (dispatches to SystemMemory/HumanMemory/AIMemory/ToolMemory based on `memory_type` column).
- Files changed:
  - `packages/orbiter-memory/src/orbiter/memory/backends/sqlite.py` (new, ~230 lines — SQLiteMemoryStore, _extra_fields, _row_to_item, SQL schema with indexes)
  - `packages/orbiter-memory/tests/test_sqlite.py` (new, 34 tests in 9 classes)
- Test coverage: ProtocolConformance (1: isinstance MemoryStore check), Lifecycle (5: init/close, double init idempotent, context manager, pre-init RuntimeError, repr), AddGet (6: add+get, get nonexistent, upsert, SystemMemory, AIMemory with tool_calls, ToolMemory), Search (9: all, query, memory_type, status, metadata user_id, limit, newest-first ordering, session+task metadata, agent_id metadata), Clear (5: clear all, clear with metadata filter, soft-delete hides from get, soft-delete preserved in DB, re-add after soft-delete), Version (2: initial version=1, version increments on upsert), Count (3: empty, active, with deleted), FilePersistence (2: data persists across connections, metadata persists), CustomMemoryType (1: unknown type returns base MemoryItem)
- **Learnings for future iterations:**
  - `aiosqlite` needs to be installed separately — it's an optional dep (`orbiter-memory[sqlite]`), but `uv pip install aiosqlite` for dev
  - SQLite `json_extract()` works well for metadata filtering — no need for separate metadata columns
  - Soft delete pattern: `deleted INTEGER DEFAULT 0` with `WHERE deleted = 0` in all queries, `SET deleted = 1` for clear — allows `count(include_deleted=True)` for auditing
  - Upsert via `ON CONFLICT(id) DO UPDATE` is cleaner than separate INSERT/UPDATE logic
  - Row factory `aiosqlite.Row` enables dict-like access (`row["column_name"]`)
  - Subtype reconstruction from DB: dispatch on `memory_type` column to construct the right Pydantic model class, extra fields (tool_calls, tool_call_id, etc.) stored in `extra_json` column
  - ruff S608 (SQL injection) is not enabled in this project — no need for `# noqa: S608` comments
  - 1337 tests total across full suite (34 new SQLite backend tests)
---

## 2026-02-15 - US-041
- What was implemented: PostgresMemoryStore — asyncpg-backed persistent memory store implementing the MemoryStore protocol. Uses `asyncpg.create_pool()` for connection pooling, JSONB columns for metadata (with expression indexes), soft deletes, upsert with version bumping via `ON CONFLICT`, `$N` positional parameter binding, ILIKE for case-insensitive text search, and full MemoryItem subtype reconstruction on read.
- Files changed:
  - `packages/orbiter-memory/src/orbiter/memory/backends/postgres.py` (new, ~230 lines — PostgresMemoryStore, _parse_rowcount, _extra_fields, _row_to_item, SQL schema with JSONB indexes)
  - `packages/orbiter-memory/tests/test_postgres.py` (new, 39 tests — 33 unit + 6 integration)
- Test coverage: ProtocolConformance (1), Lifecycle (5: init/close, double init, context manager, pre-init RuntimeError, repr), AddGet (2: add+get, get nonexistent), Search (6: all, query/ILIKE, memory_type, status, metadata/JSONB, limit), Clear (2: all, with metadata filter), Count (3: empty, active, includes deleted), Helpers (7: _parse_rowcount x4, _extra_fields x3), RowToItem (7: human, system, ai+tool_calls, tool, unknown type, metadata from dict, metadata from JSON string), Integration (6: skipped — add+get, search, clear+count, upsert, metadata search, subtype reconstruction)
- **Learnings for future iterations:**
  - asyncpg `Pool.acquire()` returns a synchronous context manager (not a coroutine) — mock it with `MagicMock()` (not `AsyncMock()`) for `acquire`, but use `AsyncMock` for `__aenter__`/`__aexit__`
  - asyncpg uses `$N` positional parameters (not `?` like SQLite) — build parameter index counter (`idx`) when constructing dynamic WHERE clauses
  - asyncpg `conn.execute()` for UPDATE returns a status string like `"UPDATE 3"` — parse with `_parse_rowcount()` to get affected row count
  - asyncpg JSONB columns return Python dicts directly (not JSON strings) — `_row_to_item` handles both `str` and `dict` for metadata/extra_json via `isinstance` check
  - PostgreSQL uses `ILIKE` for case-insensitive LIKE (vs SQLite's case-insensitive `LIKE` by default)
  - `_mock_pool()` returns `(pool, conn)` tuple — pool uses `MagicMock` (sync `.acquire()`), conn uses `AsyncMock` (async `.execute()`, `.fetchrow()`, etc.)
  - 1370 tests total across full suite (33 new unit tests, 6 skipped integration tests)
---

## 2026-02-15 - US-042
- What was implemented: Embeddings ABC + VectorMemoryStore for semantic memory retrieval. `Embeddings` ABC with `embed()` (sync), `aembed()` (async), and `dimension` property. `OpenAIEmbeddings` (OpenAI-compatible provider with lazy import, dimension support, `asyncio.to_thread()` for async). `_cosine_similarity()` for vector comparison. `VectorMemoryStore` implementing MemoryStore protocol with in-memory vector storage, cosine similarity ranking, and post-filtering by metadata/memory_type/status.
- Files changed:
  - `packages/orbiter-memory/src/orbiter/memory/backends/vector.py` (new, ~195 lines — Embeddings ABC, OpenAIEmbeddings, VectorMemoryStore, _cosine_similarity, _matches_metadata)
  - `packages/orbiter-memory/tests/test_vector.py` (new, 35 tests in 9 classes)
- Test coverage: EmbeddingsABC (5: instantiation, implements, sync/async, empty text), OpenAIEmbeddings (2: subclass, dimension), CosineSimilarity (5: identical, opposite, orthogonal, zero, known value), VectorProtocol (1: isinstance MemoryStore), VectorLifecycle (2: init, repr), VectorAddGet (5: add+get, nonexistent, computes embedding, multiple, upsert), VectorSearch (8: semantic ranking, no-query newest, limit, empty, memory_type, status, metadata, combined filters), VectorClear (4: all, metadata, removes vectors, empty), EmbeddingCalls (3: add calls embed, search calls for query, no query no embed)
- **Learnings for future iterations:**
  - `zip()` requires `strict=` parameter — ruff B905 enforces this. Use `strict=False` for embedding cosine similarity where vectors should be same length but we don't want to crash on mismatch
  - ruff SIM103 requires inlining final `if X: return False; return True` as `return not X` — cleaner for metadata matching
  - MockEmbeddings pattern for tests: deterministic vectors from char-code hashing, plus FixedEmbeddings with pre-set lookup table for precise similarity testing
  - VectorMemoryStore is in-memory only — production use would integrate with chromadb (already in optional deps as `orbiter-memory[vector]`). The in-memory implementation serves as the base pattern and test interface
  - 1405 tests total across full suite (35 new vector store tests)
---

## 2026-02-15 - US-043
- What was implemented: Memory package public API (`__init__.py` with 28 exports and `__all__`) and `MemoryEventEmitter` for event-driven memory integration. Updated `__init__.py` to export all memory types, stores, summary utilities, and event constants. Created `events.py` with `MemoryEventEmitter` wrapping any MemoryStore + EventBus to emit `memory:added`, `memory:searched`, `memory:cleared` events on operations. Agent already accepts `memory` param from US-003 — integration tests verify wiring.
- Files changed:
  - `packages/orbiter-memory/src/orbiter/memory/__init__.py` (rewritten — 28 public exports: base types, short-term, long-term, summary, events)
  - `packages/orbiter-memory/src/orbiter/memory/events.py` (new, ~85 lines — MEMORY_ADDED/SEARCHED/CLEARED constants, MemoryEventEmitter)
  - `packages/orbiter-memory/tests/test_memory_integration.py` (new, 25 tests in 10 classes)
- Test coverage: PublicAPIImports (6: base types, subtypes, short-term, long-term, summary, events), EventEmitterInit (3: defaults, custom bus, repr), EventEmitterAdd (2: emits event, persists to store), EventEmitterGet (2: delegates, missing), EventEmitterSearch (2: emits event, filters), EventEmitterClear (2: emits event, metadata filter), AgentMemoryWiring (3: store, emitter, default none), EndToEnd (5: short→summary pipeline, short→long extraction, event-driven pipeline, protocol conformance, multi-handler)
- **Learnings for future iterations:**
  - RUF022 requires `__all__` to be sorted alphabetically (isort-style) — ruff `--unsafe-fixes` auto-sorts but moves comment groups around. Best to just sort alphabetically from the start and skip grouping comments.
  - `MemoryEventEmitter` follows a decorator/wrapper pattern rather than subclassing MemoryStore — this avoids Protocol subclassing issues while still satisfying the protocol interface duck-typing
  - Agent.memory was already wired as `Any` from US-003 — no additional code changes needed in agent.py. The memory param accepts any MemoryStore or MemoryEventEmitter
  - The `events.py` module imports `EventBus` from orbiter-core (which orbiter-memory depends on) — no additional workspace deps needed
  - 1430 tests total across full suite (25 new integration tests)
---

## 2026-02-15 - US-044
- What was implemented: MCP client with multiple transport support (stdio, SSE, streamable-http) and server instance caching/reuse. `MCPClientError` exception, `MCPTransport` (StrEnum: stdio/sse/streamable_http), `MCPServerConfig` (validated config with transport-specific fields), `MCPServerConnection` (live connection with connect/list_tools/call_tool/cleanup, async context manager, tool caching with invalidation), `MCPClient` (high-level multi-server manager with auto-connect, caching/reuse, connect_all/disconnect_all).
- Files changed:
  - `packages/orbiter-mcp/src/orbiter/mcp/client.py` (new, ~280 lines — MCPClientError, MCPTransport, MCPServerConfig, MCPServerConnection, MCPClient)
  - `packages/orbiter-mcp/tests/test_mcp_client.py` (new, 45 tests in 14 classes)
- Test coverage: MCPTransport (2), MCPServerConfig (9: creation, validation, defaults, custom, repr), MCPServerConnectionInit (2), MCPServerConnectionConnect (4: success, idempotent, failure, validation), MCPServerConnectionListTools (4: list, not-connected, cached, invalidate), MCPServerConnectionCallTool (2: call, not-connected), MCPServerConnectionCleanup (2: cleanup, async-ctx), MCPServerConnectionTransports (3: stdio, sse, streamable-http), MCPClientInit (6: creation, add, multiple, remove, remove-nonexistent, validates), MCPClientConnect (4: single, unknown, cached, connect-all), MCPClientDisconnect (2: single, disconnect-all), MCPClientToolOperations (3: list, call, auto-connect), MCPClientContextManager (2: async-ctx, repr)
- **Learnings for future iterations:**
  - `__slots__` makes attributes read-only at instance level — `patch.object(instance, "method")` fails. Use `patch.object(ClassName, "method")` instead to patch at class level
  - `@asynccontextmanager` functions return single-use context managers — when mocking a method that returns an async context manager and the method is called multiple times, use `side_effect=lambda: factory()` instead of `return_value=single_cm` so each call gets a fresh context manager
  - MCP SDK `mcp>=1.0` provides `stdio_client`, `sse_client`, `streamablehttp_client` — all return async context managers yielding `(read_stream, write_stream)` or `(read_stream, write_stream, get_session_id)` for streamable-http
  - `ClientSession` is itself an async context manager — enter it after entering the transport to get initialize → session lifecycle management
  - 1475 tests total across full suite (45 new MCP client tests)
---

## 2026-02-15 - US-045
- What was implemented: MCP tool schema extraction, conversion to Orbiter Tool format, namespace mapping, and filtering. `MCPToolError` exception. `MCPToolFilter` with include/exclude whitelist/blacklist (exclude takes priority). `namespace_tool_name()` creates `{ns}__{server}__{tool}` names with special char sanitization. `parse_namespaced_name()` for reverse parsing. `extract_schema()` extracts JSON Schema from MCPTool inputSchema. `MCPToolWrapper` (Tool subclass) wraps MCP tools for Orbiter agent use — delegates `execute()` to a `call_fn(tool_name, arguments)` async callable, handles error results and multi-content responses. `convert_mcp_tools()` batch conversion with optional filtering. `load_tools_from_connection()` and `load_tools_from_client()` high-level loaders.
- Files changed:
  - `packages/orbiter-mcp/src/orbiter/mcp/tools.py` (new, ~240 lines — MCPToolError, MCPToolFilter, namespace functions, extract_schema, MCPToolWrapper, convert/load functions)
  - `packages/orbiter-mcp/tests/test_mcp_tools.py` (new, 44 tests in 10 classes)
- Test coverage: MCPToolFilterInit (5: defaults, include-only, exclude-only, exclude-priority, repr), MCPToolFilterApply (3: empty, include, exclude), NamespaceToolName (4: basic, custom-ns, sanitize-special, preserve-underscores), ParseNamespacedName (5: basic, roundtrip, nested-underscores, invalid-format, invalid-one-separator), ExtractSchema (3: basic, empty, returns-copy), MCPToolWrapperInit (5: creation, custom-ns, default-desc, schema-extraction, to_schema), MCPToolWrapperExecute (5: success, empty-args, error-result, call-fn-exception, multi-content), ConvertMCPTools (5: basic, with-filter, custom-ns, empty, all-filtered), LoadFromConnection (5: basic, filter, error, custom-ns, execution-wired), LoadFromClient (4: single, multiple, filter, empty)
- **Learnings for future iterations:**
  - `CallToolResult.content` is a union of `TextContent | ImageContent | AudioContent | ResourceLink | EmbeddedResource` — pyright errors on `hasattr(item, "text")` since some union members lack `.text`. Use `getattr(item, "text", None)` instead
  - `MCPToolWrapper.execute()` passes `kwargs or None` to the call_fn — when kwargs is empty `{}`, MCP `call_tool` expects `None` (not `{}`) for no-argument tools
  - `MCPToolFilter` uses sets internally for O(1) lookup — simple and fast for typical tool counts
  - Namespace format `mcp__server__tool` uses double underscore as separator with `split("__", 2)` to handle tool names that may contain `__`
  - 1519 tests total across full suite (44 new MCP tools tests)
---

## 2026-02-15 - US-046
- What was implemented: `@mcp_server()` class decorator that converts Python classes into MCP servers via FastMCP. `MCPServerError` exception. `MCPServerRegistry` (singleton class/instance store with register, get_class, get_instance, has, clear, names). `_register_methods()` helper that discovers public methods (excluding private, `run`, `stop`) and registers them as MCP tools via `FastMCP.tool()`. Decorator adds `_mcp` (FastMCP instance), `_tool_names` (list of registered tool names), `run(transport=)`, and `stop()` to the decorated class. Module-level `server_registry` global singleton.
- Files changed: `packages/orbiter-mcp/src/orbiter/mcp/server.py` (new, ~120 lines), `packages/orbiter-mcp/tests/test_mcp_server.py` (new, 32 tests in 10 classes)
- Test coverage: MCPServerRegistryInit (2), MCPServerRegistryRegister (4: register, multiple, overwrite, missing), MCPServerRegistryInstance (4: get, singleton, args, missing), MCPServerRegistryClear (2: clear, has), DecoratorRegistration (3: global registry, default name, custom name), DecoratorInit (3: creates mcp, uses docstring, preserves init), DecoratorMethods (4: registers public, skips private, skips run/stop, tool_names attr), DecoratorRun (4: run added, default transport, not-initialized raises, stop added), RegisterMethods (3: sync, async, empty), GlobalRegistry (3: exists, decorator uses, cleared)
- **Learnings for future iterations:**
  - FastMCP.__init__ uses `instructions=` not `description=` — the old AWorld code used `description=` which was valid in older mcp versions but mcp>=1.26 uses `instructions`
  - pyright may not see overloaded parameters that exist at runtime (e.g., `FastMCP.tool(description=...)`) — use `# pyright: ignore[reportCallIssue]` for known-valid calls that pyright's stubs miss
  - Dynamically added attributes via class decorator (`_mcp`, `run`, `stop`) are invisible to pyright — test files need `# pyright: ignore[reportAttributeAccessIssue]`
  - The `_register_methods` helper uses default argument capture (`_m=method`) to avoid closure variable binding issues in for-loops — same pattern as old AWorld's `create_tool_wrapper(method_to_call)`
  - 1551 tests total across full suite (32 new MCP server tests)
---

## 2026-02-15 - US-047
- What was implemented: MCP execution utilities — retry logic with configurable timeout, env var substitution for mcp.json config files, config file loading, and integration tests. `MCPExecutionError` (subclass of `MCPClientError`). `call_tool_with_retry()` with exponential backoff (`backoff_base * 2^attempt`), per-attempt timeout via `asyncio.wait_for()`, non-retryable `MCPClientError` pass-through, and client vs connection dispatch via duck-typing. `substitute_env_vars()` with `${VAR}` regex pattern, `_substitute_recursive()` for nested dicts/lists. `load_mcp_config()` parses mcp.json format (`mcpServers` key), applies env var substitution to all string values, creates `MCPServerConfig` instances. `load_mcp_client()` convenience wrapper.
- Files changed: `packages/orbiter-mcp/src/orbiter/mcp/execution.py` (new, ~180 lines), `packages/orbiter-mcp/tests/test_mcp_execution.py` (new, 31 tests in 9 classes)
- Test coverage: RetrySuccess (4: first try, arguments, retry, connection dispatch), RetryFailure (3: exhausted, no retries, MCPClientError not retried), RetryTimeout (2: triggers retry, exhausts retries), RetryBackoff (1: custom base), SubstituteEnvVars (6: simple, multiple, unset, no vars, empty, nested braces), SubstituteRecursive (3: dict, list, passthrough), LoadMCPConfig (8: stdio, multiple, nested env, missing file, invalid json, invalid type, empty, defaults), LoadMCPClient (1: creates client), Integration (3: retry E2E, config E2E, error hierarchy)
- **Learnings for future iterations:**
  - `MCPExecutionError` extends `MCPClientError` so callers can catch both specific and general MCP errors with a single except clause
  - `call_tool_with_retry` distinguishes MCPClient (has `server_names`) from MCPServerConnection (no `server_names`) via `hasattr` — MCPClient.call_tool takes `(server_name, tool_name, args)` while connection takes `(tool_name, args)`
  - mcp.json format uses `"mcpServers"` key (matching VS Code / Claude Code convention) — each value is a server config dict with transport/command/args/env/url/headers fields
  - `asyncio.wait_for()` wraps each individual attempt, not the total retry sequence — this prevents a single slow attempt from blocking all retries
  - Within-package imports in orbiter-mcp source also need `# pyright: ignore[reportMissingImports]` (same namespace package issue as orbiter-core/orbiter-models)
  - 1582 tests total across full suite (31 new execution tests)
---

## 2026-02-15 - US-048
- What was implemented: YAML agent & swarm loader with variable substitution and factory dispatch. `LoaderError` exception. `_substitute()` recursive variable replacement for `${ENV_VAR}` (from os.environ) and `${vars.KEY}` (from YAML's `vars` section), with full-match type preservation (int, float, bool). `_build_agent()` factory with builtin Agent construction and custom class dispatch via `register_agent_class()`. `load_yaml()` loads + substitutes. `load_agents()` returns named agent instances. `load_swarm()` creates Swarm with mode (workflow/handoff/team), flow DSL, explicit order, handoff edge wiring.
- Files changed: `packages/orbiter-core/src/orbiter/loader.py` (new, ~150 lines), `packages/orbiter-core/tests/test_loader.py` (37 tests in 9 classes), `packages/orbiter-core/pyproject.toml` (added `pyyaml>=6.0` dependency)
- Key implementation details:
  - Two substitution modes: `fullmatch()` preserves original type (e.g., `${vars.TEMP}` → 0.7 as float), `sub()` for partial matches always returns string
  - `_build_agent()` supports `system_prompt` alias for `instructions` (matching old AWorld convention)
  - `load_swarm()` handles 3 topology patterns: workflow (default, with optional explicit order or flow DSL), handoff (with `edges` for wiring handoff targets), team (lead + workers via order)
  - `register_agent_class(name, cls)` for custom agent types via YAML `type:` field
  - Missing env vars / vars keys return the original `${...}` string unchanged (no error, matches old AWorld behavior)
- **Learnings for future iterations:**
  - `pyyaml>=6.0` needed to be added as a dependency to orbiter-core's pyproject.toml — previously not needed by any orbiter-core module
  - `_VAR_RE.fullmatch()` vs `_VAR_RE.sub()` distinction is critical for type preservation: full match returns the resolved value directly (preserving int/float/bool), partial match always converts to string
  - YAML `vars:` section is popped from data before substitution to avoid leaking into the returned dict — consistent with old AWorld's approach
  - ruff auto-format adjusts whitespace in function signatures — run format before committing
  - sqlite/postgres tests have collection errors due to missing deps (aiosqlite/asyncpg not installed) — this is pre-existing, not caused by this change
  - 1552 tests pass (37 new loader tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-049
- What was implemented: Multi-source skill registry (`orbiter/skills.py`, ~240 lines) with:
  - `Skill` class with name, description, usage, tool_list, skill_type, active, path
  - `SkillRegistry` — register local/GitHub sources, load_all(), get(), search(), list_names()
  - `parse_github_url()` — regex-based GitHub URL parsing (owner, repo, branch, subdir)
  - `extract_front_matter()` — YAML front-matter extraction from markdown skill files
  - `_clone_github()` — shallow git clone with branch support, cached at ~/.orbiter/skills/
  - `_collect_skills()` — recursive directory walking for skill.md/SKILL.md files
  - `ConflictStrategy` enum: keep_first, keep_last, raise
  - Search with case-insensitive query, type filter, active_only filter
- Files changed: `packages/orbiter-core/src/orbiter/skills.py` (new, ~240 lines), `packages/orbiter-core/tests/test_skills.py` (new, 44 tests)
- **Learnings for future iterations:**
  - Skill files use `skill.md` or `SKILL.md` — both names are supported
  - Skill name falls back to parent directory name if not in front-matter
  - `tool_list` field is JSON-parsed from front-matter (not YAML within YAML)
  - `active` field is string "True"/"False" in front-matter, converted to bool
  - `__slots__` entries must be alphabetically sorted (ruff RUF023)
  - ruff N802 disallows uppercase in test function names — use descriptive lowercase instead
  - 1596 tests pass (44 new), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-050
- What was implemented: Sandbox ABC and LocalSandbox implementation with full lifecycle management. `SandboxStatus` (StrEnum: INIT, RUNNING, IDLE, ERROR, CLOSED) with explicit valid transition map. `Sandbox` ABC with `__slots__`, workspace/mcp_config/agents properties (return copies for safety), status transition validation, abstract lifecycle methods (start/stop/cleanup), describe(), repr(). `LocalSandbox` implementation with start→RUNNING, stop→IDLE, cleanup→CLOSED, `run_tool()` (requires RUNNING status), async context manager support.
- Files changed: `packages/orbiter-sandbox/src/orbiter/sandbox/base.py` (new, ~130 lines), `packages/orbiter-sandbox/tests/test_sandbox_base.py` (new, 27 tests in 7 classes)
- Test coverage: SandboxStatus values + StrEnum (2), Sandbox ABC instantiation + defaults + custom init + property copies (4), Status transitions valid 7-case + invalid 3-case (10), LocalSandbox lifecycle start/stop/restart/cleanup/context-manager (6), run_tool running/not-running/after-stop (3), describe + repr (2)
- **Learnings for future iterations:**
  - orbiter-sandbox package stub already existed (pyproject.toml, __init__.py, tests/__init__.py) — just needed `base.py`
  - Status transition validation via `_VALID_TRANSITIONS` dict is cleaner than individual method checks — easy to reason about allowed transitions
  - Properties returning copies (`list(self._workspace)`, `dict(self._mcp_config)`) prevent external mutation of internal state
  - `__slots__` entries must be sorted alphabetically (ruff RUF023 enforced) — pre-sorted to avoid fix cycle
  - 1623 tests pass (27 new), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-051
- What was implemented: Built-in sandbox tools — `FilesystemTool` (sandboxed filesystem access with allowed-directory restrictions) and `TerminalTool` (command execution with dangerous command blacklist, platform detection, and timeout).
- Files changed: `packages/orbiter-sandbox/src/orbiter/sandbox/tools.py` (new, ~130 lines), `packages/orbiter-sandbox/tests/test_sandbox_tools.py` (new, 31 tests in 11 classes)
- Key implementation details:
  - `FilesystemTool` — read/write/list actions with `_validate_path()` checking `Path.resolve().relative_to()` against allowed directories. Path traversal (`..`) blocked by resolving before validation. Write auto-creates parent directories. List returns sorted entries with name/type.
  - `TerminalTool` — `_check_command()` extracts base executable (strips path prefix via `rsplit`), case-insensitive match against blacklist. Execution via `asyncio.create_subprocess_shell` with `asyncio.wait_for` timeout. Returns exit_code, stdout, stderr, platform.
  - `_DANGEROUS_COMMANDS` frozenset: rm, rmdir, mkfs, dd, shutdown, reboot, halt, poweroff, kill, killall, pkill, format, del, erase, rd
  - Both tools follow the `Tool` ABC pattern with manually defined JSON schemas (same as `HumanInputTool` and `_DelegateTool`)
- **Learnings for future iterations:**
  - orbiter-sandbox depends on orbiter-core, so `Tool` and `ToolError` can be imported directly (with pyright ignore for namespace package resolution)
  - B904 ruff rule: all `raise` in `except` blocks need `from exc` or `from None` — even for `FileNotFoundError` / `NotADirectoryError` re-wrapping
  - Unused variable detection (F841) — be careful with placeholder variables like `shell = True`
  - 1654 tests total across full suite (31 new sandbox tool tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-052
- What was implemented: `SandboxBuilder` — fluent builder for constructing `Sandbox` instances with method chaining and lazy evaluation (auto-build on first non-builder attribute access via `__getattr__`).
- Files changed: `packages/orbiter-sandbox/src/orbiter/sandbox/builder.py` (new, ~115 lines), `packages/orbiter-sandbox/tests/test_sandbox_builder.py` (new, 28 tests in 7 classes)
- Key implementation details:
  - Fluent setters: `with_sandbox_id()`, `with_workspace()`, `with_mcp_config()`, `with_agents()`, `with_timeout()`, `with_sandbox_class()`, `with_extra()`
  - `build()` constructs the Sandbox once and caches it (`_built`); subsequent calls return the same instance
  - `reset()` clears the cached instance for builder reuse
  - `__getattr__` triggers lazy `build()` and delegates to the sandbox — builder methods are resolved via normal `__slots__` lookup so they're never intercepted
  - `__slots__` for memory efficiency, defensive copies on `with_workspace()`, `with_mcp_config()`, `with_agents()`
  - Default sandbox class is `LocalSandbox`, overridable via constructor or `with_sandbox_class()`
- **Learnings for future iterations:**
  - `__getattr__` is only called when normal attribute lookup fails — builder methods defined via `__slots__` and actual method definitions are found before `__getattr__`, so no need for an explicit builder-method whitelist
  - Ruff F401 catches unused imports even when they seem semantically relevant (e.g., `SandboxError` imported but not used in builder.py)
  - 1682 tests total across full suite (28 new builder tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-053
- What was implemented: KubernetesSandbox — Kubernetes-based sandbox for remote agent execution. Extends `Sandbox` ABC with full pod + service lifecycle management (create, poll readiness, delete), lazy kubernetes client loading, configurable namespace/image via constructor or env vars, async context manager support, and detailed `describe()` output.
- Files changed: `packages/orbiter-sandbox/src/orbiter/sandbox/kubernetes.py` (new, ~280 lines), `packages/orbiter-sandbox/tests/test_kubernetes_sandbox.py` (new, 22 tests in 8 classes)
- Key implementation details:
  - `_load_client()` lazy-loads `kubernetes` package with fallback: KUBECONFIG env → in-cluster config → default kubeconfig
  - `_pod_manifest()` and `_service_manifest()` generate minimal K8s manifests with `orbiter-{sandbox_id}` naming
  - `_wait_for_pod()` polls `read_namespaced_pod` up to 30 times at 2-second intervals for Running phase
  - `start()` creates pod + waits for readiness + creates service; errors set status to ERROR
  - `stop()` and `cleanup()` both delete resources via `_delete_resources()` which tolerates delete failures (logged as warnings)
  - `run_tool()` returns execution metadata including pod name and cluster IP
  - All K8s API calls wrapped in `asyncio.to_thread()` for async compatibility
  - Tests use `_mock_k8s_api()` helper that returns a MagicMock CoreV1Api with configurable pod phase and service cluster_ip
- Test coverage: init defaults/custom/env vars (4), load client missing/cached (2), manifests pod/service (2), start creates/polls/error/timeout (4), stop deletes/no-client (2), cleanup closes/tolerates-errors (2), run_tool running/not-running (2), context manager (1), describe before/after start + repr (3)
- **Learnings for future iterations:**
  - BLE001 (broad exception) ruff rule is NOT enabled in this project — `# noqa: BLE001` comments are unnecessary and trigger RUF100 (unused noqa)
  - `patch.dict("sys.modules", {"kubernetes": None})` is the pattern for testing missing optional dependencies — set the module and all submodules to `None`
  - `asyncio.to_thread()` wraps sync kubernetes client calls for async compatibility — this is the standard pattern for blocking I/O in async code
  - 1704 tests total across full suite (22 new kubernetes sandbox tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-054
- What was implemented: TraceConfig (Pydantic frozen model with backend selection via TraceBackend StrEnum: otlp/memory/console, endpoint, service_name, sample_rate with 0.0-1.0 validation, enabled toggle, headers, namespace, extra dict) and comprehensive semantic conventions (gen_ai.* — 21 constants for OpenTelemetry GenAI semconv; orbiter.agent.* — 7 agent observability attrs; orbiter.tool.* — 7 tool attrs; orbiter.task/session/user — 5 context attrs; 4 span name prefixes).
- Files changed: `packages/orbiter-trace/src/orbiter/trace/config.py` (new, ~120 lines), `packages/orbiter-trace/tests/test_trace_config.py` (new, 55 tests in 10 classes)
- Test coverage: TraceBackend (2: values, StrEnum), TraceConfigDefaults (3: defaults, frozen, repr), TraceConfigCustom (9: backend, endpoint, service_name, sample_rate, disabled, headers, namespace, extra, string-to-enum), TraceConfigValidation (5: sample_rate low/high/boundary-zero/one, invalid backend), TraceConfigSerialisation (2: model_dump, JSON roundtrip), GenAIConventions (11: system, request model/max_tokens/temperature/top_p/streaming, prompt+completion, duration, response attrs, usage tokens, operation+server), AgentConventions (6), ToolConventions (7), TaskSessionConventions (5), SpanPrefixes (5: agent/tool/llm/task, concatenation usage)
- **Learnings for future iterations:**
  - orbiter-trace uses `orbiter.` prefix (not `aworld.`) for namespace-scoped attributes — this is the Orbiter convention replacing old AWorld's configurable `ATTRIBUTE_NAME_SPACE` env var
  - TraceConfig follows the same Pydantic frozen model pattern as ContextConfig (context/config.py) — use `model_validator(mode="after")` for cross-field validation
  - The `gen_ai.*` constants follow OpenTelemetry's GenAI semantic conventions directly (no namespace prefix) — these are industry-standard attribute names
  - 1759 tests total across full suite (55 new trace config tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-055
- What was implemented: `@traced` decorator with full function type support (sync, async, generators, async generators), `extract_metadata()` for function introspection, `is_user_code()` + `get_user_frame()` for stack frame analysis with user-code filtering, and `span_sync()`/`span_async()` context managers for manual span creation.
- Files changed: `packages/orbiter-trace/src/orbiter/trace/decorator.py` (new, ~120 lines), `packages/orbiter-trace/tests/test_trace_decorator.py` (new, 37 tests in 10 classes)
- Key implementation details:
  - `@traced(name=, attributes=, extract_args=)` decorator detects function type via `inspect.isasyncgenfunction()` → `inspect.isgeneratorfunction()` → `asyncio.iscoroutinefunction()` → sync fallback
  - Each wrapper creates span via `tracer.start_as_current_span()`, records exceptions via `span.record_exception()`, and re-raises
  - `extract_metadata()` extracts `code.function` (qualname), `code.module`, `code.lineno`, `code.filepath` (relative to CWD), `code.parameters` (excluding self)
  - `_build_attrs()` merges metadata + extra attributes + extracted args (if enabled), flattens list values to strings for OTel attribute compatibility
  - `is_user_code()` filters out trace module paths and dynamic code (`<string>`, `<module>`)
  - `get_user_frame()` walks `sys._getframe()` chain to find first user-code frame
  - Custom `_MemoryExporter(SpanExporter)` in tests since OTel SDK version may not ship InMemorySpanExporter
- Test coverage: IsUserCode (4: normal, dynamic, eval, trace-module), GetUserFrame (3: returns frame, positive lineno, function name), ExtractMetadata (8: qualname, module, lineno, filepath, parameters, method self exclusion, lambda, builtin), SpanSync (3: creates, attributes, exception), SpanAsync (2: creates, exception), TracedSync (7: basic, custom name, extra attributes, extract args, metadata, exception, preserves functools metadata), TracedAsync (3: basic, exception, extract args), TracedGenerator (2: sync gen, gen exception), TracedAsyncGenerator (2: async gen, async gen exception), EdgeCases (3: nested, list flattened, async with custom name+attrs)
- **Learnings for future iterations:**
  - OTel `trace.set_tracer_provider()` is a one-shot global — tests must reset `trace._TRACER_PROVIDER_SET_ONCE._done = False` and `trace._TRACER_PROVIDER = None` before each test fixture to get a clean provider
  - OTel SDK installed in this project does NOT have `InMemorySpanExporter` — use a custom `_MemoryExporter(SpanExporter)` that collects spans in a list
  - `inspect.signature(len)` returns `(obj, /)` in Python 3.11+ — builtins DO have signatures now, so don't assume empty parameters for builtins
  - SLF001 (private member access like `sys._getframe`) ruff rule is NOT enabled — no need for `# noqa: SLF001`
  - 1796 tests total across full suite (37 new decorator tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-056
- What was implemented: Agent/tool instrumentation module with OpenTelemetry metrics. Metric name constants (`METRIC_AGENT_RUN_DURATION`, `METRIC_AGENT_RUN_COUNTER`, `METRIC_AGENT_TOKEN_USAGE`, `METRIC_TOOL_STEP_DURATION`, `METRIC_TOOL_STEP_COUNTER`). Instrument factory functions (`create_agent_run_duration()`, etc.). Attribute builders (`build_agent_attributes()`, `build_tool_attributes()`) using semantic conventions from config.py. Recording helpers (`record_agent_run()`, `record_tool_step()`) that create instruments from the current MeterProvider on each call. `Timer` class for duration measurement.
- Files changed: `packages/orbiter-trace/src/orbiter/trace/instrumentation.py` (new, ~120 lines), `packages/orbiter-trace/tests/test_trace_instrumentation.py` (new, 36 tests in 9 classes)
- Test coverage: MetricNames (5), InstrumentFactory (5), BuildAgentAttributes (3: defaults, all fields, None→empty), BuildToolAttributes (2), RecordAgentRun (5: success, failure, no tokens, token attributes, empty attributes), RecordToolStep (4: success, failure, empty, no mutation), Timer (5: timing, chaining, elapsed, match, initial), HistogramBuckets (4: fractional, large, small, token), Integration (3: agent flow, tool flow, multiple recordings)
- **Learnings for future iterations:**
  - OTel `metrics.set_meter_provider()` is one-shot like `trace.set_tracer_provider()` — reset `metrics._internal._METER_PROVIDER_SET_ONCE._done = False` and `metrics._internal._METER_PROVIDER = None` in test fixtures
  - Module-level instruments (`_meter.create_histogram(...)`) bind to the no-op provider at import time and won't see later `set_meter_provider()` calls — recording functions must call `metrics.get_meter().create_*()` each time to use the current provider
  - OTel SDK's `InMemoryMetricReader.get_metrics_data()` can return `None` — always guard with `if data is None: return`
  - The `create_*()` pattern (factory functions) gives callers flexibility while `record_*()` functions handle the common case internally
  - 1832 tests total across full suite (36 new instrumentation tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-057
- What was implemented: W3C Baggage propagation and span consumer plugin system in `packages/orbiter-trace/src/orbiter/trace/propagation.py` (~180 lines). Carrier protocol + DictCarrier for header abstraction. ContextVar-backed baggage storage (get/set/clear). BaggagePropagator with extract (parses comma-separated URL-encoded pairs with size limits) and inject (encodes and writes to carrier). SpanConsumer ABC with registry: register_span_consumer (direct + decorator), get_span_consumer, list_span_consumers, dispatch_spans, clear_span_consumers.
- Files changed: `packages/orbiter-trace/src/orbiter/trace/propagation.py` (new, ~180 lines), `packages/orbiter-trace/tests/test_trace_propagation.py` (new, 52 tests in 10 classes)
- Test coverage: DictCarrier (6: creation, headers, get/set, protocol, repr), BaggageContext (7: empty, set/get, missing, multiple, overwrite, clear, copy), Extract (11: single, multiple, url-encoded, empty, no-header, whitespace, oversized-header, oversized-pair, no-equals, max-pairs, stores-in-context), Inject (7: single, multiple, url-encoded, empty, from-context, oversized-pair, none-uses-context), Roundtrip (3: basic, special-chars, repr), SpanConsumerABC (3: concrete, consume, abstract enforcement), Registration-direct (5: register, list, get-missing, clear, overwrite), Registration-decorator (2: decorator-on-class, still-usable), Dispatch (4: single, multiple, empty, no-consumers), Constants (4: header, max-lengths, max-pairs)
- **Learnings for future iterations:**
  - Ruff B039 disallows mutable default for ContextVar — use `default=None` with `ContextVar[T | None]` and handle None in accessor functions
  - BaggagePropagator is stateless — extract/inject work on any Carrier instance, baggage state is in the ContextVar
  - `register_span_consumer` supports both direct instance registration and bare `@register_span_consumer` decorator on classes (class is instantiated with no args)
  - 1884 tests total across full suite (52 new propagation tests), excluding sqlite/postgres collection errors
---
## 2026-02-15 - US-058
- What was implemented: Structured LLM execution logger with token breakdown by role, context window usage analysis, and multi-modal content support. `estimate_tokens()` (chars/ratio heuristic), `TokenBreakdown` (frozen dataclass: system/user/assistant/tool/other with total property and percentages method), `compute_token_breakdown()` (handles plain strings, multi-modal content lists with text/image_url/tool_use items, tool_calls in assistant messages), `_content_tokens()` and `_tool_calls_tokens()` helpers. `ExecutionLogEntry` (mutable dataclass with format_summary() producing human-readable multi-line output with k-based token display and percentage breakdown). `PromptLogger` class with configurable logger and ratio, `log_execution()` method that computes breakdown, creates entry, logs structured output, and returns the entry.
- Files changed: `packages/orbiter-trace/src/orbiter/trace/prompt_logger.py` (new, ~130 lines), `packages/orbiter-trace/tests/test_trace_prompt_logger.py` (new, 35 tests in 7 classes)
- Test coverage: estimate_tokens (4: empty, short, long, custom ratio), TokenBreakdown (5: defaults, total, percentages, zero window, frozen), compute_token_breakdown (8: empty, system, multiple roles, tool, unknown role, tool_calls, None content, custom ratio), MultiModal (4: text item, image_url, tool_use, mixed), ExecutionLogEntry (4: defaults, with context window, without context window, no tools), PromptLogger (7: init default, custom, returns entry, emits log, custom level, with tools, empty), Integration (3: full flow, multimodal, percentages sum)
- **Learnings for future iterations:**
  - No new packages or dependencies needed — prompt_logger.py only imports stdlib (logging, dataclasses, collections.abc, typing)
  - The old AWorld `PromptLogger` was tightly coupled to `BaseAgent`, `ApplicationContext`, and `ModelUtils` — the Orbiter version is decoupled, accepting plain message dicts and returning structured data
  - `dataclass(frozen=True, slots=True)` for `TokenBreakdown` is the right pattern for immutable value objects — consistent with `TokenStep`, `Checkpoint`
  - Multi-modal content detection uses `isinstance(content, list)` and dispatches on `item.get("type")` — handles text, image_url, and tool_use content items
  - Image tokens use a fixed estimate (85) since base64 payload sizes vary wildly — matching industry practice for vision token estimation
  - 1919 tests total across full suite (35 new prompt logger tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-059
- What was implemented: Eval types + base evaluator in `packages/orbiter-eval/src/orbiter/eval/base.py` (~190 lines). `EvalError` exception. `EvalStatus` (StrEnum: passed/failed/not_evaluated). `ScorerResult` (frozen dataclass: scorer_name, score, status, details). `EvalCaseResult` (frozen: case_id, input, output, scores dict). `EvalResult` (mutable: case_results, summary, pass_at_k). `EvalCriteria` (frozen: metric_name, threshold, judge() method). `EvalTarget` ABC with `predict()`. `Scorer` ABC with `score()`. `Evaluator` class with parallel execution via `asyncio.Semaphore` + `asyncio.gather()`, `repeat_times` for multiple runs per case, criteria-based pass/fail judgment, mean score summarization, and pass@k computation.
- Files changed: `packages/orbiter-eval/src/orbiter/eval/base.py` (new, ~190 lines), `packages/orbiter-eval/tests/test_eval_base.py` (new, 36 tests in 11 classes)
- Test coverage: EvalStatus (2), ScorerResult (3: creation, frozen, details), EvalCaseResult (2), EvalResult (2), EvalCriteria (4: defaults, judge pass/fail, frozen), EvalTarget ABC (2), Scorer ABC (2), Evaluator init (4: defaults, invalid parallel, invalid repeat_times, with criteria), Evaluator evaluate (8: single, multiple, empty, multiple scorers, criteria pass/fail, parallel, case without id), Pass@k (6: no repeats, all pass, none pass, partial, multiple cases, no criteria), Repr (1)
- **Learnings for future iterations:**
  - A002/A003 (builtin shadow) ruff rules are NOT enabled in this project — `# noqa: A002`/`# noqa: A003` comments are unnecessary and trigger RUF100
  - `replace_all` in the Edit tool replaces ALL occurrences including mid-line — when removing `# noqa: ...` comments that are at end of lines followed by code on next line, the replacement merges lines. Be careful with `replace_all` on patterns that appear at line endings.
  - Eval package already had stub (pyproject.toml, __init__.py, tests/__init__.py) — just needed base.py
  - Pass@k groups results by consecutive position (idx // repeat_times) rather than by case_id — this ensures correct grouping when cases are evaluated with asyncio.gather preserving order
  - 1955 tests total across full suite (36 new eval tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-060
- What was implemented: Rule-based scorers for the evaluation framework. Six concrete `Scorer` subclasses: `FormatValidationScorer` (validates JSON, XML, YAML, Markdown, CSV format), `SchemaValidationScorer` (minimal JSON Schema validation — type checking, required fields, nested property validation), `OutputCorrectnessScorer` (ground truth matching with normalization + keyword presence checking), `OutputLengthScorer` (min/max length bounds), `OutputRelevanceScorer` (keyword overlap between input and output), `OutputCompletenessScorer` (required section presence checking).
- Files changed:
  - `packages/orbiter-eval/src/orbiter/eval/scorers.py` (new, ~260 lines — 6 scorer classes)
  - `packages/orbiter-eval/tests/test_scorers.py` (new, 47 tests in 12 classes)
- Test coverage: FormatValidationScorerInit (3: default, custom name, unsupported format), FormatJSON (3: valid, invalid, array), FormatXML (3: valid, invalid, malformed), FormatMarkdown (4: heading, list, bold, plain text), FormatCSV (4: valid, tab-delimited, too few rows, inconsistent), FormatNoneOutput (1), SchemaValidation (6: valid object, missing required, wrong type, invalid JSON, nested, custom name), OutputCorrectness (8: exact, normalized, no match, normalize off, keywords all/partial/none, no criteria), OutputLength (5: within range, too short/long, empty, details), OutputRelevance (5: full/partial/no overlap, empty input, custom name), OutputCompleteness (5: all/some/none present, empty sections, case insensitive)
- **Learnings for future iterations:**
  - Within-package namespace imports (e.g., `scorers.py` importing `base.py`) also need `# pyright: ignore[reportMissingImports]` — same pattern as cross-package imports
  - `ClassVar[dict[...]]` is needed for mutable class attributes (RUF012) — even for internal validator dispatch tables
  - FormatValidationScorer uses a `_VALIDATORS` ClassVar dict populated after class definition for a clean dispatch pattern
  - SchemaValidationScorer implements minimal JSON Schema validation (type + required + properties + nesting) without external dependencies — sufficient for rule-based evaluation
  - 2002 tests total across full suite (47 new scorer tests)
---

## 2026-02-15 - US-061
- What was implemented: LLM-as-Judge scorers and multi-dimensional quality assessment. `extract_json()` (brace-counting JSON extraction supporting nested objects). `LLMAsJudgeScorer` (base scorer with configurable `judge` async callable, overridable `build_prompt()` and `parse_response()` hooks, score clamping to [0.0, 1.0]). `OutputQualityScorer` (weighted 5-dimensional: correctness 40%, relevance 20%, completeness 20%, clarity 10%, professionalism 10%, with quality labels: Excellent/Good/Medium/Pass/Fail). `LogicConsistencyScorer` (weighted: contradiction 0.5, causal 0.3, data 0.2). `ReasoningValidityScorer` (fallacy detection, reasoning type classification). `ConstraintSatisfactionScorer` (binary PASS/FAIL per constraint, computed from constraint_results or fallback score field).
- Files changed: `packages/orbiter-eval/src/orbiter/eval/llm_scorer.py` (new, ~130 lines), `packages/orbiter-eval/tests/test_llm_scorer.py` (new, 43 tests in 12 classes)
- Test coverage: extract_json (4: simple, no json, invalid, empty), LLMAsJudgeScorerInit (3), LLMAsJudgeScorerScore (7: no judge, with judge, clamp high/low, missing score, prompt with/without input), OutputQualityScorerInit (3), OutputQualityScorerScore (6: full, weighted, mixed, missing dims, labels, prompt dims), LogicConsistencyScorerInit (2), LogicConsistencyScorerScore (4: weighted, partial, missing, no judge), ReasoningValidityScorerInit (1), ReasoningValidityScorerScore (3: valid, fallacies, no judge), ConstraintSatisfactionScorerInit (2), ConstraintSatisfactionScorerScore (6: all pass, partial, all fail, fallback, prompt, no judge), Integration (2: protocol, subclass)
- **Learnings for future iterations:**
  - Regex `\{[^{}]*\}` can't handle nested JSON objects (e.g., `dimension_scores` dict inside outer object) — use brace-counting approach instead
  - `judge` parameter is `Any` async callable `(prompt: str) -> str` — keeps scorers decoupled from any specific LLM provider
  - Subclass pattern: override `_default_system_prompt()` as `@staticmethod` for class-specific defaults, override `build_prompt()` and `parse_response()` for custom behavior
  - Quality labels use a threshold list sorted descending — first match wins
  - 2045 tests total across full suite (43 new LLM scorer tests)
---

## 2026-02-15 - US-062
- What was implemented: Trajectory + time scorers with scorer registry. `scorer_register()` decorator for automatic scorer discovery, `get_scorer()` lookup, `list_scorers()`. `TrajectoryValidator` (validates trajectory step lists for required keys like `step`/`id` and `action`, scores fraction of valid steps). `TimeCostScorer` (reads `_time_cost_ms` from output dict, scores inversely relative to max budget). `AnswerAccuracyLLMScorer` (LLMAsJudgeScorer subclass comparing agent response to reference answer, configurable question/answer keys). `LabelDistributionScorer` (per-case placeholder + `summarize()` for dataset-level label distribution with counts, fractions, and skew).
- Files changed: `packages/orbiter-eval/src/orbiter/eval/trajectory_scorers.py` (new, ~200 lines — 4 scorers, registry, helper), `packages/orbiter-eval/tests/test_trajectory_scorers.py` (new, 40 tests in 8 classes)
- Test coverage: ScorerRegistry (4: register decorator, builtins registered, missing key, sorted), ParseTrajectory (5: list, wrapped dict, empty, non-list, filters), TrajectoryValidator (8: valid, empty, missing action/step/id, partial, custom keys, custom name), TimeCostScorer (7: zero, half budget, over budget, no key, non-dict, details, custom name), AnswerAccuracyLLMScorer (6: no judge, with judge, prompt content, custom keys, non-dict input, custom name), LabelDistributionScorer (5: placeholder, no label, non-dict, custom key, custom name), LabelDistributionSummarize (5: balanced, skewed, empty, no labels, single label)
- **Learnings for future iterations:**
  - Scorer registry uses module-level dict `_SCORER_REGISTRY` — simple and effective, registered at class definition time via `@scorer_register("name")`
  - `LabelDistributionScorer.summarize()` is a separate method (not part of the `Scorer.score()` ABC) since it operates on aggregated results rather than individual cases
  - `AnswerAccuracyLLMScorer` inherits from `LLMAsJudgeScorer` (not `Scorer` directly) — reuses the judge callable pattern and `parse_response()` from US-061
  - `TrajectoryValidator` accepts both `"step"` and `"id"` as valid step identifier keys — flexible for different trajectory formats
  - 2085 tests total across full suite (40 new scorer tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-063
- What was implemented: Reflection framework with LLM-powered analysis. `ReflectionType` enum (SUCCESS, FAILURE, OPTIMIZATION, PATTERN, INSIGHT). `ReflectionLevel` enum (SHALLOW, MEDIUM, DEEP, META). `ReflectionResult` frozen dataclass (summary, key_findings, root_causes, insights, suggestions, metadata). `ReflectionHistory` mutable tracker with add(), get_recent(), get_by_type(), summarize(). `Reflector` ABC with three-step template: analyze() → insight() → suggest() orchestrated by reflect(). `GeneralReflector` LLM-powered implementation with configurable judge callable, prompt builder, and JSON response parser with fallback.
- Files changed: `packages/orbiter-eval/src/orbiter/eval/reflection.py` (new, ~130 lines of core logic), `packages/orbiter-eval/tests/test_reflection.py` (new, 30 tests in 10 classes)
- Test coverage: ReflectionType (2), ReflectionLevel (2), ReflectionResult (3: creation, frozen, all fields), ReflectionHistory (5: empty, counters, get_recent, get_by_type, summarize), ReflectorABC (4: cannot instantiate, concrete subclass, pipeline, defaults), GeneralReflectorInit (2), GeneralReflectorNoJudge (1), GeneralReflectorWithJudge (5: full, error context, prompt content, malformed JSON, partial JSON), ParseResponse (4: valid, no JSON, empty, nested), Integration (2: reflect+history, multiple types)
- **Learnings for future iterations:**
  - The three-step template (analyze → insight → suggest) passes analysis dict to both insight() AND suggest() — suggest() needs the full analysis, not just the insight output, because suggestions come from analyze() in the LLM response
  - `GeneralReflector._parse_response` reuses the same brace-counting JSON extraction as `llm_scorer.extract_json()` — could be shared in a future refactor
  - ReflectionHistory uses simple counters for success/failure but get_by_type() iterates all entries — sufficient for typical reflection history sizes
  - 2115 tests total across full suite (30 new reflection tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-064
- What was implemented: Ralph loop state + config module in `packages/orbiter-eval/src/orbiter/eval/ralph/config.py` (~160 lines). `StopType` (StrEnum with 9 values, `is_success()`/`is_failure()` predicates). Three frozen sub-configs: `ValidationConfig` (scorer_names tuple, min_score_threshold with [0,1] validation, parallel, timeout), `ReflectionConfig` (level, max_history), `StopConditionConfig` (max_iterations with >=1 validation, timeout, max_cost, max_consecutive_failures, score_threshold, enable_user_interrupt). `RalphConfig` (frozen, aggregates all three sub-configs + metadata). `LoopState` (mutable dataclass with iteration/cost/tokens tracking, score_history + reflection_history lists, record_score/record_reflection/record_success/record_failure mutations, elapsed/success_rate/latest_score/best_score queries, to_dict serialisation, repr).
- Files changed: `packages/orbiter-eval/src/orbiter/eval/ralph/__init__.py` (new), `packages/orbiter-eval/src/orbiter/eval/ralph/config.py` (new, ~160 lines), `packages/orbiter-eval/tests/test_ralph_config.py` (new, 41 tests in 9 classes)
- **Learnings for future iterations:**
  - Ralph subpackage goes under `packages/orbiter-eval/src/orbiter/eval/ralph/` — no new workspace registration needed since it's a subdirectory of an existing package
  - `__post_init__` on frozen dataclasses works for validation — the object is already constructed but fields can't be reassigned after
  - `time.monotonic()` is better than `time.time()` for elapsed timing — not affected by system clock adjustments
  - `LoopState.record_success()` resets `consecutive_failures` to 0 — this is the key mechanic for the stop detector's consecutive failure tracking
  - 2156 tests total across full suite (41 new ralph config tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-065
- What was implemented: Ralph loop stop detectors — `StopDetector` ABC, `StopDecision` frozen dataclass, five built-in detectors (`MaxIterationDetector`, `TimeoutDetector`, `CostLimitDetector`, `ConsecutiveFailureDetector`, `ScoreThresholdDetector`), and `CompositeDetector` for aggregating multiple detectors with first-match-wins semantics.
- Files changed: `packages/orbiter-eval/src/orbiter/eval/ralph/detectors.py` (new, ~100 lines of core logic), `packages/orbiter-eval/tests/test_ralph_detectors.py` (new, 41 tests in 8 classes)
- Key implementation details:
  - `StopDecision` is a frozen dataclass with `__bool__` returning `should_stop` — enables `if decision:` pattern
  - Shared `_CONTINUE` singleton for the common no-stop case (avoids allocating new StopDecision per check)
  - Each detector takes `(state: LoopState, config: StopConditionConfig)` — reads thresholds from config, current values from state
  - Disabled detectors: `timeout=0.0`, `max_cost=0.0`, `score_threshold=0.0`, `max_consecutive_failures=0` all return `_CONTINUE` immediately
  - `ScoreThresholdDetector` uses mean of all scorer values in the latest score snapshot for threshold comparison
  - `CompositeDetector` supports `add()` chaining, `__len__`, `__repr__`, and is itself a `StopDetector` subclass
- Test coverage: StopDecision (4: falsy, truthy, metadata, frozen), ABC (2: cannot instantiate, concrete subclass), MaxIteration (4: below/at/above limit, metadata), Timeout (4: disabled, within, exceeded, metadata), CostLimit (5: disabled, below/at/above, metadata), ConsecutiveFailure (5: disabled, below/at/above threshold, metadata), ScoreThreshold (9: disabled, no scores, below/at/above, multi-scorer mean, below mean, uses latest only, metadata), Composite (8: empty, first match, second triggers, none triggers, add chaining, len, repr, all-five integration)
- **Learnings for future iterations:**
  - Ralph subpackage `ralph/` is already set up under `orbiter-eval` — just add new `.py` files, no package registration needed
  - `StopDetector.check()` is async for consistency with the old AWorld `should_stop()` pattern and to allow future detectors that need I/O (e.g., user interrupt via file check)
  - Shared `_CONTINUE` singleton is safe because `StopDecision` is frozen — no mutation risk
  - 2197 tests total across full suite (41 new detector tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-066
- What was implemented: RalphRunner — iterative refinement loop implementing the 5-phase Run→Analyze→Learn→Plan→Halt cycle. `RalphResult` (frozen dataclass: output, stop_type, reason, iterations, scores, state, reflections). `RalphRunner` class with `run(input)` async entry point, `_execute()` (calls execute_fn, tracks success/failure in LoopState), `_analyze()` (scores output via configured Scorers, records to state), `_learn()` (reflects via Reflector when execution failed or scores below threshold), `_plan()` (re-prompts by appending reflection suggestions to original input), `_halt()` (checks CompositeDetector with all 5 built-in detectors).
- Files changed: `packages/orbiter-eval/src/orbiter/eval/ralph/runner.py` (new, ~130 lines), `packages/orbiter-eval/tests/test_ralph_runner.py` (new, 23 tests in 9 classes)
- Test coverage: RalphResult (3: creation, frozen, with reflections), Init (2: defaults, custom config), Single iteration (3: success, no scorers, failure), Score improvement (2: threshold stop, max iterations), Early stopping (2: consecutive failures, failure recovery), Reflection (4: low scores, high scores, execution failure, no reflector), Plan re-prompt (1: suggestions appended), Scorer edge cases (3: failing scorer ignored, validation disabled, reflection disabled), State tracking (2: state in result, mixed success/failure), Repr (1)
- **Learnings for future iterations:**
  - RalphRunner's `_learn()` triggers reflection when execution fails OR mean score is below `config.validation.min_score_threshold` — both conditions checked separately
  - The `_plan()` phase always re-prompts from original input (not accumulated), appending new suggestions — this prevents prompt explosion from chaining suggestions across iterations
  - `_execute()` catches all exceptions and records failure via `state.record_failure()` — the error message becomes the "output" for that iteration
  - The runner composes all 5 built-in detectors in `_build_detector()` rather than taking a detector parameter — keeps the API simple while still supporting all stop conditions via config
  - 2220 tests total across full suite (23 new runner tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-067
- What was implemented: A2A protocol types module in `packages/orbiter-a2a/src/orbiter/a2a/types.py` (~130 lines). `TransportMode` (StrEnum: jsonrpc/grpc/websocket), `TaskState` (StrEnum: submitted/working/completed/failed/canceled), `AgentSkill` (frozen Pydantic: id, name, description, tags), `AgentCapabilities` (frozen: streaming, push_notifications, state_transition_history), `AgentCard` (frozen: name, description, version, url, capabilities, skills, input/output modes, supported transports), `ServingConfig` (frozen: host, port, endpoint, streaming, version, skills, modes, transports, extra), `ClientConfig` (frozen: streaming, timeout with >0 validation, transports, accepted_output_modes, extra), `TaskStatus` (frozen: state, reason), `TaskStatusUpdateEvent` (frozen: task_id, status), `TaskArtifactUpdateEvent` (frozen: task_id, text, last_chunk).
- Files changed: `packages/orbiter-a2a/src/orbiter/a2a/types.py` (new, ~130 lines), `packages/orbiter-a2a/tests/__init__.py` (new), `packages/orbiter-a2a/tests/test_a2a_types.py` (new, 36 tests in 10 classes)
- Test coverage: TransportMode (2), TaskState (2), AgentSkill (5: creation, full, frozen, coercion, serialization), AgentCapabilities (3: defaults, custom, frozen), AgentCard (5: minimal, full, frozen, JSON roundtrip, model_dump), ServingConfig (4: defaults, custom, frozen, serialization), ClientConfig (5: defaults, custom, frozen, timeout validation, serialization), TaskStatus (3: creation, reason, frozen), TaskStatusUpdateEvent (3: creation, failed, serialization), TaskArtifactUpdateEvent (4: creation, last_chunk, defaults, serialization)
- **Learnings for future iterations:**
  - orbiter-a2a package stub already existed (pyproject.toml, __init__.py) — just needed types.py and tests directory
  - All Pydantic models use `frozen=True` since they're value objects — consistent with TraceConfig and ContextConfig patterns
  - Tuple fields with `model_validator(mode="before")` for list→tuple coercion is the established pattern from ContextConfig (US-023)
  - `from __future__ import annotations` is needed at top of file for forward reference support with frozen Pydantic models
  - 2256 tests total across full suite (36 new A2A type tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-068
- What was implemented: FastAPI-based A2A server with agent card discovery, task execution, and streaming support. `A2AServerError` exception. `TaskStore` runtime_checkable Protocol (get/save/delete). `InMemoryTaskStore` in-memory implementation. `AgentExecutor` wrapping any Orbiter Agent with `execute(text, provider=)` async method. `A2AServer` class with `build_app()` creating FastAPI app: `GET /.well-known/agent-card` (returns agent card JSON), `POST /` (task execution with submitted→working→completed/failed lifecycle), `GET /tasks/{task_id}` (task lookup), `POST /stream` (NDJSON streaming when `config.streaming=True`).
- Files changed: `packages/orbiter-a2a/src/orbiter/a2a/server.py` (new, ~130 lines), `packages/orbiter-a2a/tests/test_a2a_server.py` (new, 34 tests in 11 classes)
- Test coverage: InMemoryTaskStore (7: save/get, missing, delete, delete missing, overwrite, protocol, repr), AgentExecutorInit (3: default, streaming, fallback name), AgentExecutorExecute (4: basic, with provider, empty text, None text), AgentExecutorRepr (1), A2AServerInit (4: defaults, custom config, skills, custom store), AgentCardEndpoint (2: get card, card with skills), TaskExecution (5: success, custom task_id, auto task_id, failure, stores task), TaskLookup (2: existing, missing), StreamingEndpoint (3: disabled, success, failure), BuildApp (2: returns app, idempotent), Repr (1)
- **Learnings for future iterations:**
  - httpx `ASGITransport` + `AsyncClient` is the pattern for testing FastAPI apps without running a server — `AsyncClient(transport=ASGITransport(app=app), base_url="http://test")`
  - `build_app()` creates a new FastAPI app each call (not cached) — each call wires fresh route handlers that close over `self`
  - Task lifecycle: SUBMITTED → WORKING → COMPLETED/FAILED, each state saved to TaskStore for retrieval via `GET /tasks/{task_id}`
  - Streaming uses NDJSON (`application/x-ndjson`) — one JSON object per line, parsed by splitting on newlines
  - `AgentExecutor` wraps any object with `run(input, **kwargs)` and `name` attribute — duck-typed to avoid importing orbiter.agent directly
  - 2290 tests total across full suite (34 new A2A server tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-069
- What was implemented: A2A HTTP client, thread-safe ClientManager, and RemoteAgent for calling remote A2A agents. `A2AClientError` exception. `A2AClient` class with agent card resolution (from URL via httpx or local JSON file), `send_task()` for synchronous task execution, `send_task_streaming()` for NDJSON streaming, and `close()` lifecycle. `ClientManager` with per-thread `A2AClient` instances via `threading.local()`, thread-safe registry with `threading.Lock()`, and `shutdown()` to close all clients. `RemoteAgent` with `run(input)` returning `AgentOutput`, `describe()` returning agent card metadata, and `close()`. `_extract_text()` helper for response parsing (artifact.text → result → empty string fallback).
- Files changed: `packages/orbiter-a2a/src/orbiter/a2a/client.py` (new, ~130 lines of core logic), `packages/orbiter-a2a/tests/test_a2a_client.py` (new, 42 tests in 12 classes)
- Test coverage: A2AClientInit (6: card, url, file, empty, invalid type, default config), ResolveCard (7: already resolved, from file, file not found, invalid json, from url, url failure, caching), SendTask (3: success, custom task_id, failure), Streaming (3: not supported, success, failure), Lifecycle (4: close, repr resolved/url/source), ClientManager (6: get_client, same thread, different threads, shutdown, repr, custom config), RemoteAgentInit (3: basic, config, repr), RemoteAgentRun (3: success, empty response, result field), Describe (1), Close (1), ExtractText (5: artifact, result, empty, empty text fallback, non-dict artifact)
- **Learnings for future iterations:**
  - httpx `AsyncClient` requires `aclose()` (not `close()`) for proper async cleanup — our `A2AClient.close()` delegates to `self._http.aclose()`
  - `ClientManager` uses `threading.local()` for per-thread client storage and `threading.Lock()` for the shared registry — simpler than the old AWorld `ThreadSafeManager` which had a daemon monitor thread and `RLock`
  - `RemoteAgent` is NOT an `Agent` subclass — it's a standalone class with a compatible `run()` interface. This avoids pulling in Agent's LLM/tool dependencies for a pure HTTP proxy
  - Response text extraction uses a priority chain: `artifact.text` (from A2A server's TaskArtifactUpdateEvent) → `result` field (server stores it) → empty string
  - The A2A package already depends on `httpx>=0.27` in pyproject.toml — no new dependencies needed
  - 2332 tests total across full suite (42 new client tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-070
- What was implemented: CLI entry point with Typer-based argument parsing and YAML config file loading. `CLIError` exception. `find_config(directory)` for auto-discovery of `.orbiter.yaml` / `orbiter.config.yaml` (first found wins). `load_config(path)` delegates to `orbiter.loader.load_yaml()` with validation. `resolve_config(config_path)` for explicit-path-or-auto-discovery resolution. Typer `app` with `--verbose` / `-v` callback, `run` command with `--config` / `-c`, `--model` / `-m`, `--stream` / `-s` options and input text argument.
- Files changed: `packages/orbiter-cli/src/orbiter_cli/main.py` (new, ~155 lines), `packages/orbiter-cli/tests/test_cli_main.py` (new, 33 tests in 9 classes)
- Test coverage: CLIError (2), find_config (5: .orbiter.yaml, orbiter.config.yaml, precedence, none, cwd default), load_config (6: valid, missing, invalid, env var substitution, vars section, string path), resolve_config (4: explicit, auto-discovery, none, explicit overrides), CLI run (8: no args help, no config exit 1, with config, explicit config, model flag, stream flag, verbose, invalid path), CLI help (2: top-level, run subcommand), config precedence (3: first wins, fallback, ignores non-config), edge cases (3: empty dict, nested vars, Path object)
- **Learnings for future iterations:**
  - orbiter-cli package stub already existed with `typer>=0.12` and `rich>=13.0` deps, entry point `orbiter = "orbiter_cli.main:app"`
  - Typer's `no_args_is_help=True` returns exit code 2 (not 0) — test with `assert result.exit_code in (0, 2)` for compatibility
  - `typer.testing.CliRunner` for testing CLI invocations — similar to Click's runner but supports Typer-specific features
  - `load_config` uses lazy import of `orbiter.loader.load_yaml` to avoid import errors when orbiter-core isn't fully initialized
  - orbiter-cli is a regular package (not namespace) — uses `orbiter_cli` import path, not `orbiter.cli`
  - 2365 tests total across full suite (33 new CLI tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-071
- What was implemented: Agent discovery and loading module for orbiter-cli. `AgentLoadError` exception. `_parse_front_matter()` for markdown YAML front-matter extraction. Three file-type loaders: `load_python_agent()` (dynamic import via `importlib.util`, expects `create_agent()` factory returning Agent or dict), `load_yaml_agents()` (delegates to `orbiter.loader.load_agents`), `load_markdown_agent()` (front-matter fields: name, model, instructions, temperature, max_tokens, max_steps; body as fallback instructions). `discover_agent_files()` scans directory for `.py`, `.yaml`, `.md` files (sorted, non-recursive). `validate_agent()` checks for `name` and `run` attributes. `scan_directory()` orchestrates: discover → load → validate → merge with duplicate detection.
- Files changed: `packages/orbiter-cli/src/orbiter_cli/loader.py` (new, ~170 lines), `packages/orbiter-cli/tests/test_cli_loader.py` (new, 45 tests in 9 classes)
- Test coverage: AgentLoadError (2), _parse_front_matter (7: basic, no front matter, unclosed, empty body, multiline, lowercase keys, no-colon skip), load_markdown_agent (11: basic, name defaults to stem, explicit instructions, model, temperature, max_tokens, max_steps, invalid temp/tokens/steps, no front matter), load_python_agent (6: basic, dict return, no factory, module error, factory error, name attr), load_yaml_agents (3: basic, missing section, missing file), discover_agent_files (5: types, sorted, empty, not-a-dir, skips subdirs), validate_agent (3: valid, missing name, missing run), scan_directory (8: markdown, python, yaml, empty, duplicate, validate off/on, mixed types)
- **Learnings for future iterations:**
  - Python agent files use `create_agent()` convention (not `@agent` decorator) — simpler for the Orbiter ecosystem where agents are plain `Agent` instances, not decorated swarm factories like old AWorld
  - `importlib.util.spec_from_file_location()` + `exec_module()` is the clean pattern for dynamic loading — remember to register/unregister from `sys.modules`
  - Markdown agent body becomes `instructions` (not `system_prompt`) — Orbiter Agent uses `instructions` parameter
  - ruff I001 import sorting: `from orbiter.agent import Agent` must come before `from orbiter_cli.loader import ...` (third-party before first-party)
  - 2410 tests total across full suite (45 new loader tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-072
- What was implemented: Interactive REPL console for chatting with agents. `StreamEvent` protocol for streaming events. `parse_command()` for slash-command parsing. `format_agents_table()` for Rich table display. `InteractiveConsole` class with: agent registry, current agent selection, command handlers (/help, /exit, /quit, /agents, /switch, /info, /clear), streaming and non-streaming execution modes, async readline via `asyncio.to_thread(sys.stdin.readline)`, Rich-formatted output.
- Files changed: `packages/orbiter-cli/src/orbiter_cli/console.py` (new, ~130 lines), `packages/orbiter-cli/tests/test_cli_console.py` (new, 39 tests in 7 classes)
- Test coverage: ParseCommand (7: slash, slash+arg, non-command, empty, whitespace, case-insensitive, multi-word arg), FormatAgentsTable (4: empty, single, multiple, no describe), ConsoleInit (4: requires agents, defaults, streaming without/with stream_fn), ConsoleCommands (7: help, agents, switch success/unknown/empty, info, clear), ConsoleExecution (4: normal, error, streaming, no output attr), ConsoleLoop (11: exit, quit, eof, empty skip, unknown cmd, help+exit, agents+exit, switch+exit, info+exit, clear+exit, user message executes), Properties (2: current agent, agents copy)
- **Learnings for future iterations:**
  - SLF001 (private member access) ruff rule is NOT enabled — `# noqa: SLF001` triggers RUF100 (unused noqa). Same for BLE001 and D102.
  - `RichConsole(file=MagicMock(), no_color=True)` is the pattern for creating a silent Rich console in tests
  - `patch.object(InteractiveConsole, "_read_input", side_effect=[...])` is the pattern for testing the REPL loop — each list item is one readline return value
  - `sys.stdin.readline` returns "" on EOF (not None) — check `if not line` for EOF detection
  - 2449 tests total across full suite (39 new console tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-073
- What was implemented: LocalExecutor — local agent execution wrapper with Rich output formatting, timeout support, streaming, and error handling. `ExecutorError` exception. `ExecutionResult` (output, steps, elapsed, usage dict, raw result; summary() for human-readable stats). `LocalExecutor` class with `execute()` (wraps `orbiter.runner.run` with timeout via `asyncio.wait_for`, usage extraction, verbose timing), `stream()` (wraps `run.stream()` yielding text chunks), `print_result()` (Rich Panel), `print_error()` (Rich formatted error).
- Files changed: `packages/orbiter-cli/src/orbiter_cli/executor.py` (new, ~120 lines), `packages/orbiter-cli/tests/test_cli_executor.py` (new, 28 tests in 8 classes)
- Test coverage: ExecutorError (1), ExecutionResult creation (3: defaults, full, usage-is-copy), ExecutionResult summary (4: basic, elapsed, tokens, repr), LocalExecutor init (3: defaults, custom, repr), Execute (5: basic, provider, messages, verbose, no-usage), Timeout (2: raises, no-timeout), Errors (2: agent-error, preserves-cause), Stream (5: basic, no-text, missing-stream, error, with-provider), Display (3: print-result, verbose, print-error)
- **Learnings for future iterations:**
  - Lazy import `from orbiter.runner import run` inside `execute()` / `stream()` methods to avoid import errors at class instantiation time when orbiter-core isn't fully initialized
  - `monkeypatch.setattr(orbiter.runner, "run", mock_run)` patches the lazy import target — works because `from orbiter.runner import run` re-reads from the module at call time
  - `MagicMock(spec=[])` creates a mock with NO attributes — useful for testing "stream not available" when `run.stream` is missing
  - `getattr(usage_obj, "field", 0) or 0` handles both missing and None usage fields
  - 2477 tests total across full suite (28 new executor tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-074
- What was implemented: Plugin system for extending Orbiter CLI functionality. `PluginManager` discovers/loads plugins from entry points (`orbiter.plugins` group) and directories, manages lifecycle hooks (startup, shutdown, pre_run, post_run). `PluginSpec` describes a plugin with name, version, description, and async hook functions. `PluginHook` StrEnum defines the 4 lifecycle hook points.
- Files changed: `packages/orbiter-cli/src/orbiter_cli/plugins.py` (new, ~270 lines), `packages/orbiter-cli/tests/test_cli_plugins.py` (new, 37 tests)
- Key implementation details:
  - `PluginManager.load_entrypoints()` discovers via `importlib.metadata.entry_points()` with `.select(group=...)` for Python 3.12+ compat
  - `PluginManager.load_directory()` scans `.py` files (skipping `_`-prefixed), imports them, and extracts `plugin` attribute
  - `_load_plugin_file()` helper uses `importlib.util.spec_from_file_location` (same pattern as loader.py's `load_python_agent`)
  - Duplicate plugin names rejected with `PluginError`
  - Hook execution is sequential in registration order, errors propagate immediately
- **Learnings for future iterations:**
  - `StrEnum` for `PluginHook` (not `str, Enum`) — ruff UP042 enforces this
  - Entry point callable factory pattern: `obj() if callable(obj) and not isinstance(obj, PluginSpec) else obj` handles both direct PluginSpec and factory functions
  - `importlib.metadata.entry_points().select(group=...)` is the modern API; older Python used dict-like `.get(group, [])`
  - 2514 tests total across full suite (37 new plugin tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-075
- What was implemented: Batch execution module for Orbiter CLI — loads inputs from JSON, CSV, or JSONL files and runs an agent against each input concurrently. `BatchError` exception. `InputFormat` (StrEnum: json/csv/jsonl). `BatchItem` (frozen dataclass: id, input, metadata). `ItemResult` (dataclass: item_id, success, output, elapsed, error). `BatchResult` (aggregate: results, total, succeeded, failed, summary()). `load_batch_items()` with format auto-detection from extension, configurable input_key/id_key, metadata extraction. `batch_execute()` with semaphore-based concurrency control via `asyncio.Semaphore`, per-item error isolation via `asyncio.gather`. Output helpers: `results_to_jsonl()`, `results_to_csv()`.
- Files changed: `packages/orbiter-cli/src/orbiter_cli/batch.py` (new, ~230 lines), `packages/orbiter-cli/tests/test_cli_batch.py` (new, 38 tests in 12 classes)
- Test coverage: BatchError (1), InputFormat (2: values, StrEnum), BatchItem (3: creation, metadata, frozen), ItemResult (2: creation, failure), BatchResult (2: defaults, summary), LoadJSON (6: basic, with-id, auto-id, metadata, not-a-list, missing-key), LoadJSONL (4: basic, blank-lines, invalid-json, not-object), LoadCSV (2: basic, custom-input-key), FormatDetection (3: unsupported, missing-file, forced-format), BatchExecute (7: basic, multiple, failure, mixed, invalid-concurrency, empty, provider-forwarded), ResultsToJSONL (4: basic, error-included, no-error-field, empty), ResultsToCSV (2: basic, multiple)
- **Learnings for future iterations:**
  - `batch_execute` wraps `LocalExecutor` from executor.py — reuses existing execution infrastructure rather than calling `orbiter.runner.run` directly
  - Semaphore-based concurrency (`asyncio.Semaphore(concurrency)`) is the standard async pattern for limiting parallel tasks
  - `asyncio.gather(*tasks)` collects all results including from tasks that caught their own exceptions — individual failures don't crash the batch
  - CSV loading via `csv.DictReader` returns `dict[str, str]` (all values are strings) — callers should handle type conversion if needed
  - ruff auto-fix reformats imports and removes unused ones in one pass — always run `ruff check --fix` followed by `ruff format`
  - 2552 tests total across full suite (38 new batch tests), excluding sqlite/postgres collection errors
---

## 2026-02-15 - US-076
- What was implemented: FastAPI app with /chat endpoint supporting both synchronous JSON responses and streaming SSE. `ChatRequest` (message, agent_name, stream fields) and `ChatResponse` (output, agent_name, steps, usage) Pydantic models. Agent registry per-app (register_agent with default agent support). `_sse_stream()` async generator yields SSE-formatted events (text deltas, tool calls, error events, [DONE] marker). `create_app()` factory creates configured FastAPI instance.
- Files changed: `packages/orbiter-server/src/orbiter_server/app.py` (new, ~130 lines), `packages/orbiter-server/tests/test_server_app.py` (new, 23 tests in 8 classes)
- Test coverage: ChatRequest defaults/all-fields (2), ChatResponse defaults/data (2), RegisterAgent single/multiple/explicit-default (3), GetAgent no-agents/not-found/by-name/resolve-default/no-default-no-name (5), ChatEndpoint success/with-agent-name/no-agents-503/not-found-404/run-error-500 (5), ChatStreaming text-events/tool-call/done-marker/error-event (4), CreateApp creates/has-route (2)
- **Learnings for future iterations:**
  - Module-level imports are needed for `patch()` to work — lazy imports inside endpoint functions can't be patched via `patch("module.attr")` since the attribute doesn't exist at module level
  - `_run_agent` (aliased from `orbiter.runner.run`) is the patchable reference; streaming tests patch the same ref since `_sse_stream()` uses `getattr(_run_agent, "stream", ...)`
  - httpx `ASGITransport` + `AsyncClient` is the standard FastAPI testing pattern (no need for `TestClient` in async tests)
  - FastAPI `StreamingResponse` with `media_type="text/event-stream"` works for SSE without needing `sse-starlette` dependency
  - 2575 tests total across full suite (23 new server tests), excluding sqlite/postgres collection errors
---

## 2026-02-16 - US-077
- What was implemented: Session management CRUD routes (`sessions.py`) with in-memory session store. Models: `Session`, `SessionMessage`, `SessionSummary`, `CreateSessionRequest`, `UpdateSessionRequest`, `AppendMessageRequest`. Routes: POST /sessions (create), GET /sessions (list newest-first), GET /sessions/{id} (get), PATCH /sessions/{id} (update title/agent_name), DELETE /sessions/{id}, POST /sessions/{id}/messages (append), GET /sessions/{id}/messages (list). Wired `session_router` into `create_app()` via `app.include_router()`.
- Files changed: `packages/orbiter-server/src/orbiter_server/sessions.py` (new, ~185 lines), `packages/orbiter-server/tests/test_server_sessions.py` (new, 29 tests in 11 classes), `packages/orbiter-server/src/orbiter_server/app.py` (added session_router import + include_router)
- Test coverage: SessionMessage (2), Session (2), RequestModels (4), CreateSession (3), ListSessions (3), GetSession (2), UpdateSession (4), DeleteSession (2), AppendMessage (3), ListMessages (2), SessionLifecycle (2: full CRUD lifecycle + timestamp updates)
- **Learnings for future iterations:**
  - `APIRouter.app` property has typing issues with pyright (`MethodType` instead of `FastAPI`) — use FastAPI's `Request` dependency (`req: Request`) to access `req.app.state` instead of `router.app.state`
  - `include_router(session_router)` in `create_app()` wires the router's prefix (/sessions) automatically
  - In-memory store via `app.state` works the same for routers when using `Request` — the `Request.app` always points to the root FastAPI app
  - ruff auto-fix sorts imports and removes unused ones (pytest was unused in test file) in one pass
  - 2604 tests total across full suite (29 new session tests), excluding sqlite/postgres collection errors
---

## 2026-02-16 - US-078
- What was implemented: Agent management and workspace API routes — listing registered agents, getting agent details, listing workspace files, and reading workspace file content.
- Files changed: `packages/orbiter-server/src/orbiter_server/agents.py` (new, ~163 lines), `packages/orbiter-server/src/orbiter_server/app.py` (added agent_router import + include_router), `packages/orbiter-server/tests/test_server_agents.py` (new, 24 tests)
- Key implementation details:
  - `agent_router` with prefix `/agents` registered in `create_app()`
  - `GET /agents` — lists all registered agents with name, model, tools, handoffs, default status
  - `GET /agents/{name}` — agent detail with 404 on missing
  - `GET /agents/{name}/workspace` — lists workspace artifacts (returns empty list if no workspace)
  - `GET /agents/{name}/workspace/{file_name}` — reads artifact content with proper 404 handling
  - `_get_workspace(agent)` navigates `agent.context.workspace` with None-safe attribute access
  - `_agent_info(agent)` builds AgentInfo from duck-typed agent attributes (tools/handoffs as dict keys)
- **Learnings for future iterations:**
  - Agent's workspace is at `agent.context.workspace` — two levels of attribute access, both may be None
  - Use `{file_name:path}` in FastAPI route params to allow slashes in filenames
  - Reuse `_AGENTS_KEY` / `_DEFAULT_AGENT_KEY` constants from app.py — duplicated in agents.py for module independence (could be factored to shared constants)
  - When testing workspace routes, mock both workspace.list() and workspace.get() — list returns artifacts, get takes a name and returns single artifact or None
  - 1745 tests pass across core/models/server/cli/context/trace packages (24 new agent route tests)
---

## 2026-02-16 - US-079
- What was implemented: WebSocket endpoint (`/ws/chat`) and SSE fallback endpoint (`GET /stream`) for real-time streaming of agent output. Shared `_iter_events()` generator produces JSON-serialisable event dicts consumed by both transports. `_resolve_agent()` resolves agents without raising HTTPException (suitable for non-HTTP contexts like WebSocket).
- Files changed:
  - `packages/orbiter-server/src/orbiter_server/streaming.py` (new, ~140 lines)
  - `packages/orbiter-server/src/orbiter_server/app.py` (added stream_router import + include)
  - `packages/orbiter-server/tests/test_server_streaming.py` (new, 21 tests)
- **Learnings for future iterations:**
  - Use `starlette.testclient.TestClient` with `tc.websocket_connect()` for WebSocket tests — httpx `AsyncClient` doesn't support real WebSocket connections
  - WebSocket error handling: use `WebSocketDisconnect` exception, not HTTPException
  - `_resolve_agent()` in streaming.py returns `None` instead of raising HTTPException — WebSocket handlers can't use HTTPException
  - The existing `_sse_stream()` in app.py and the new `_sse_iter()` in streaming.py share the same event generation logic via `_iter_events()`
  - 2649 tests passing across all packages (21 new streaming tests)
---

## 2026-02-16 - US-080
- What was implemented: Trajectory dataset module in `packages/orbiter-train/src/orbiter/train/trajectory.py` (~130 lines). `TrajectoryError` exception. `TrajectoryItem` (frozen dataclass with SAR pattern: id, task_id, agent_id, step, timestamp, input/messages/context for State, output/tool_calls for Action, score/status for Reward, metadata; `to_dict()` and `from_dict()` serialization). `TrajectoryStrategy` ABC with `build_item()` and `validate()`. `DefaultStrategy` extracts input/output/tool_calls from message dicts. `TrajectoryDataset` with: `append_trajectory()` for pre-built items, `from_messages()` using strategy with per-agent step counting, `save_task_trajectory()` for bulk append, `get_task_trajectory()` for task filtering, `validate()` delegation, `to_json()` export, `to_csv()` export with JSON-encoded complex fields, `clear()`.
- Files changed: `packages/orbiter-train/src/orbiter/train/trajectory.py` (new, ~130 lines), `packages/orbiter-train/tests/test_trajectory.py` (new, 38 tests)
- Test coverage: TrajectoryItem creation/defaults/frozen/messages (4), serialization to_dict/from_dict/roundtrip/defaults (4), DefaultStrategy build/tool_calls/empty/validate (4), custom strategy (2), dataset init/custom_strategy/repr (3), capture append/from_messages/step_counter/separate_agents/save/get/get_empty/validate/clear (9), JSON export empty/single/multiple/complex_fields (4), CSV export empty/single/complex_fields/multiple (4), error (1), integration full_lifecycle/custom_strategy/save_then_export (3)
- **Learnings for future iterations:**
  - orbiter-train already had a package stub (pyproject.toml, __init__.py, tests/__init__.py) — just needed trajectory.py
  - `dataclass(frozen=True, slots=True)` is the right pattern for immutable trajectory items — consistent with TokenStep, Checkpoint, ScorerResult patterns
  - Step counters use `task_id:agent_id` composite key for per-agent-per-task step tracking
  - CSV export requires JSON-encoding complex fields (messages, tool_calls, context, metadata) since CSV cells can't hold nested structures
  - TrajectoryStrategy ABC is intentionally minimal (build_item + validate) — more complex strategies (filtered, memory-based) can be added in future without changing the interface
  - 2687 tests total across full suite (38 new trajectory tests), excluding sqlite/postgres collection errors
---

## 2026-02-16 - US-081
- What was implemented: Base Trainer ABC with multi-phase lifecycle for agent fine-tuning
- Files changed: `packages/orbiter-train/src/orbiter/train/trainer.py` (171 lines), `packages/orbiter-train/tests/test_trainer.py` (24 tests)
- Key implementation details:
  - `Trainer` ABC with 4 abstract validation methods: check_agent, check_dataset, check_reward, check_config
  - State machine: CREATED → VALIDATED → TRAINING → COMPLETED/FAILED (TrainerState StrEnum)
  - `mark_validated()` transitions state; `_require_validated()` guard prevents premature training
  - `train()` and `evaluate()` are async abstract methods returning `TrainMetrics`
  - `TrainConfig` dataclass: epochs, batch_size, learning_rate, output_dir, extra dict
  - `TrainMetrics` dataclass: loss, accuracy, steps, extra dict
  - `TrainerError` exception class for all training-specific failures
- **Learnings for future iterations:**
  - Trainer follows the same pattern as old AWorld's TrainerProcessor but modernised: StrEnum states, async methods, dataclass configs
  - Agent/dataset params typed as `Any` since orbiter-core types aren't available at orbiter-train level
  - `__slots__` on ABC works fine — subclasses add their own slots or use `__dict__` as needed
  - 2711 tests total across full suite (24 new trainer tests)
---
