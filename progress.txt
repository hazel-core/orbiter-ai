# Ralph Progress Log
Started: Sun Feb 15 04:58:56 PM IST 2026

## Codebase Patterns
- UV workspace monorepo: 13 packages under `packages/` (including orbiter-context), root pyproject.toml has NO build-system
- New namespace package setup: create `packages/orbiter-<name>/` dir, add to root pyproject.toml workspace members + dev deps + uv.sources, then `uv sync`
- Namespace packages: `orbiter-core/__init__.py` uses `pkgutil.extend_path()` so other packages add to the `orbiter` namespace
- Meta-package at `packages/orbiter/` uses `_orbiter_meta` dummy package for hatchling compatibility
- Quality checks: `uv run ruff check packages/`, `uv run ruff format --check packages/`, `uv run pyright packages/orbiter-core/`, `uv run pytest`
- Use `Sequence[Message]` (not `list[Message]`) for function params that accept subtype lists — avoids pyright invariance errors
- Use `ClassVar[dict[...]]` for mutable class attributes on dataclass-like test fixtures to avoid RUF012 lint errors
- Use `StrEnum` (not `str, Enum`) for string enums — ruff UP042 enforces this
- Test file names must be unique across all packages (pytest collects `tests/` from multiple packages into one `tests` module)
- pytest-asyncio `asyncio_mode = "auto"` configured in root pyproject.toml — no need for `@pytest.mark.asyncio`
- Import sorting: ruff enforces I001 import block sorting — use `uv run ruff check --fix` to auto-sort
- Forward-compatible params: use `Any` type with `None` default for params whose concrete types come from future packages
- Cross-package error handling: since orbiter-core can't import ModelError from orbiter-models, check error attributes (e.g., `.code`) via `getattr()` on caught exceptions
- Mock provider responses MUST include valid `Usage` objects (not `None`) — `parse_response(usage=None)` causes Pydantic validation failure, silently consumed by retry logic
- pyright ignore comments: put `# pyright: ignore[reportMissingImports]` on the import line itself (not a separate comment line) to avoid ruff I001 import sorting issues
- Within-package namespace imports also need `# pyright: ignore[reportMissingImports]` — e.g., `context.py` importing `config.py` in the same `orbiter.context` package
- Ruff RUF023: `__slots__` entries must be sorted alphabetically — run `uv run ruff check --fix` to auto-sort
---

## 2026-02-15 - US-001
- What was implemented: Message builder with build_messages, validate_message_order, extract_last_assistant_tool_calls, merge_usage. Initial commit of entire Orbiter framework infrastructure (Phases 1-4 + partial Phase 5).
- Files changed: packages/ (65 files — all package infrastructure, types, config, registry, events, hooks, tool, models, agent, message_builder, output_parser, and tests)
- **Learnings for future iterations:**
  - The codebase had pre-existing code from prior interactive sessions (Phases 1-4) that was never committed — this first commit captures everything
  - `list[SubType]` is not assignable to `list[BaseType]` in pyright due to list invariance — use `Sequence[BaseType]` for read-only function params
  - `test_agent.py` had RUF012 (mutable class default) and I001 (import sorting) lint errors that needed fixing
  - All 349 tests pass across orbiter-core (222) and orbiter-models (127)
---

## 2026-02-15 - US-002
- What was implemented: Output parser was already fully implemented and committed as part of the US-001 batch commit. Verified all acceptance criteria are met.
- Files: `packages/orbiter-core/src/orbiter/_internal/output_parser.py` (~155 lines), `packages/orbiter-core/tests/test_output_parser.py` (19 tests)
- Key functions: `parse_response()`, `parse_tool_arguments()`, `parse_structured_output()`, `OutputParseError`
- All quality checks pass: ruff check, ruff format, pyright (0 errors), pytest (349 tests)
- **Learnings for future iterations:**
  - US-001's initial commit included code for multiple user stories — check if the next story's code already exists before implementing
  - The PRD's `ParsedOutput` is implemented as `AgentOutput` in the actual code — the types module defines `AgentOutput` with text, tool_calls, usage fields
---

## 2026-02-15 - US-003
- What was implemented: Agent class was already mostly implemented from prior sessions. Added missing `memory` and `context` parameters to `Agent.__init__` (typed as `Any` since orbiter-context and orbiter-memory packages are not yet implemented). Updated test to assert defaults are `None`.
- Files changed: `packages/orbiter-core/src/orbiter/agent.py`, `packages/orbiter-core/tests/test_agent.py`
- **Learnings for future iterations:**
  - Agent class already had 21 tests covering: minimal/full creation, keyword-only enforcement, model parsing, tool/handoff registration with duplicate detection, hook integration, callable instructions, describe(), __repr__
  - `memory` and `context` params use `Any` type since their implementations are in future phases (orbiter-memory Phase 9, orbiter-context Phase 8)
  - Pattern: when PRD references types from future packages, use `Any` with `None` default as a forward-compatible placeholder
---

## 2026-02-15 - US-004
- What was implemented: `Agent.run()` async method with single-turn LLM execution and retry logic. Added `code` parameter to `ModelError` for error classification.
- Files changed: `packages/orbiter-core/src/orbiter/agent.py` (added ~85 lines for run() + _is_context_length_error()), `packages/orbiter-core/tests/test_agent.py` (added 15 tests in 3 new test classes), `packages/orbiter-models/src/orbiter/models/types.py` (added `code` param to ModelError)
- Key implementation details:
  - `run(input, *, messages, provider, max_retries=3)` wires message_builder → LLM call → output_parser
  - PRE_LLM_CALL / POST_LLM_CALL hooks fire at correct points
  - Retry with exponential backoff (2^attempt seconds): 1s, 2s, 4s...
  - Context-length errors (via `ModelError.code == "context_length"` or message text) fail immediately
  - Provider typed as `Any` since orbiter-core doesn't depend on orbiter-models
- **Learnings for future iterations:**
  - orbiter-core can't import from orbiter-models directly — use `Any` type for provider parameter and catch base exceptions
  - `_is_context_length_error()` checks both `.code` attribute and error message text for robustness
  - pyright inline ignore comments on import lines don't break ruff I001 sorting (put `# pyright: ignore[...]` on the same import line, not a separate comment line)
  - All 364 tests pass (15 new: 7 run tests, 4 retry tests, 4 hook tests)
---

## 2026-02-15 - US-005
- What was implemented: Tool execution loop in `Agent.run()` — when LLM returns tool calls, agent executes them in parallel, feeds results back, and re-calls LLM until text response or max_steps.
- Files changed: `packages/orbiter-core/src/orbiter/agent.py` (refactored run() into run() + _call_llm() + _execute_tools(), ~120 new lines), `packages/orbiter-core/tests/test_agent.py` (8 new tests in TestAgentToolLoop class)
- Key implementation details:
  - `run()` now has a `for _step in range(self.max_steps)` loop around `_call_llm()`
  - `_call_llm()` extracted from old `run()` — single LLM call with retry logic and hooks
  - `_execute_tools()` uses `asyncio.TaskGroup` for parallel tool execution
  - Tool errors caught per-tool and returned as `ToolResult(error=...)`, not propagated
  - Unknown tools return `ToolResult(error="Unknown tool '...'")`
  - PRE_TOOL_CALL / POST_TOOL_CALL hooks fire for each tool
  - `parse_tool_arguments()` from output_parser converts ToolCall JSON args to ActionModel
  - Updated existing test `test_run_with_tool_calls_in_response` to account for the tool loop (provider now needs to return text on second call)
- **Learnings for future iterations:**
  - When adding tool loop, existing tests that mock a single tool-call response break because the agent now tries to execute the tool and re-call. Update mocks to return text on the follow-up call.
  - `asyncio.TaskGroup` requires Python 3.11+ — already satisfied by this project
  - The placeholder list pattern `[ToolResult(...)] * len(actions)` creates shared references — must assign by index in the async task, not append
  - All 372 tests pass (8 new tool loop tests)
---

## 2026-02-15 - US-006
- What was implemented: 8 new edge case tests in `TestAgentEdgeCases` class covering: retry during tool loop, agent with handoffs runs normally, handoffs don't appear as tools, sequential tool calls accumulate messages, max_steps=1, empty input, usage from final response, tool with no arguments.
- Files changed: `packages/orbiter-core/tests/test_agent.py` (+161 lines)
- **Learnings for future iterations:**
  - Most edge cases were already covered by earlier test classes (TestAgentToolLoop had 8 tests for the core scenarios)
  - The key gap was retry behavior mid-tool-loop and handoff interaction — these are important to test because they exercise separate code paths in the agent
  - 52 agent tests total across 9 test classes, 380 tests across the full suite
---

## 2026-02-15 - US-007
- What was implemented: Human-in-the-loop tool with `HumanInputHandler` ABC, `ConsoleHandler` (stdin-based), and `HumanInputTool` (Tool subclass with timeout support).
- Files changed: `packages/orbiter-core/src/orbiter/human.py` (~120 lines), `packages/orbiter-core/tests/test_human.py` (21 tests in 4 classes)
- Key implementation details:
  - `HumanInputHandler` ABC with `async get_input(prompt, choices)` — extensible to console, web, Slack, etc.
  - `ConsoleHandler` — reads from stdin via `asyncio.to_thread()`, validates choices, defaults to first choice on invalid input
  - `HumanInputTool` — `Tool` subclass with manually defined JSON schema (prompt required, choices optional array)
  - Timeout via `asyncio.wait_for()` — raises `ToolError` on timeout
  - Tests use `MockHandler` and `SlowHandler` fixtures, plus `monkeypatch` for `ConsoleHandler._read_line`
- **Learnings for future iterations:**
  - `HumanInputTool` manually defines its JSON schema rather than using `_generate_schema()` since it's not a FunctionTool wrapper — this is the pattern for custom Tool subclasses
  - `asyncio.wait_for()` raises `TimeoutError` (Python 3.11+) — catch that and convert to `ToolError` for consistent error handling
  - 401 tests total across full suite (21 new)
---

## 2026-02-15 - US-008
- What was implemented: Run state tracking with `RunNodeStatus` (StrEnum: INIT, RUNNING, SUCCESS, FAILED, TIMEOUT), `RunNode` (Pydantic model with lifecycle transitions: start/succeed/fail/timeout, timing, usage, metadata), and `RunState` (mutable execution tracker with message accumulation, node management, usage aggregation, terminal state detection).
- Files changed: `packages/orbiter-core/src/orbiter/_internal/state.py` (~145 lines), `packages/orbiter-core/tests/test_state.py` (29 tests in 3 classes)
- **Learnings for future iterations:**
  - Use `StrEnum` instead of `str, Enum` — ruff UP042 enforces this pattern
  - `Sequence[Message]` still needed for function params that accept `list[SubType]` — pyright invariance on `list[T]`
  - `RunNode` uses mutable Pydantic model (no `frozen=True`) since state transitions mutate fields — this is the right pattern for stateful objects vs. value objects
  - 430 tests total across full suite (29 new)
---

## 2026-02-15 - US-009
- What was implemented: Core call runner (`call_runner()`) that orchestrates Agent.run() with RunState tracking, node lifecycle management, usage accumulation, and endless loop detection via tool-call signature comparison.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/call_runner.py` (~145 lines), `packages/orbiter-core/tests/test_call_runner.py` (15 tests in 6 classes)
- Key implementation details:
  - `call_runner(agent, input, *, state, messages, provider, max_retries, loop_threshold)` — wraps Agent.run() in RunState lifecycle
  - Creates RunNode per call, tracks INIT → RUNNING → SUCCESS/FAILED transitions
  - Loop detection: `_tool_call_signature()` creates deterministic string from sorted tool name:args pairs; `_check_loop()` counts consecutive matching signatures in node metadata
  - Errors from Agent.run() wrapped in `CallRunnerError`, state/node marked FAILED
  - Agent.instructions resolved via callable check + str() for pyright compatibility (agent param typed as Any)
  - Returns `RunResult` with output text, accumulated messages, total usage, step count
- **Learnings for future iterations:**
  - Since `agent` is typed as `Any` in call_runner, accessing `agent.instructions` returns `object | Any` — must use `str()` cast or explicit type narrowing, not direct assignment to `str` variable
  - Loop detection works across consecutive `call_runner()` invocations with shared state by storing tool signatures in `RunNode.metadata`
  - The call_runner delegates the actual LLM→tool→LLM loop entirely to Agent.run() — it's a thin orchestration layer for state tracking, not a replacement for Agent's internal loop
  - 445 tests total across full suite (15 new)
---

## 2026-02-15 - US-010
- What was implemented: Public `run()` async entry point and `run.sync()` blocking wrapper as the primary API for executing agents. Auto-provider resolution via orbiter.models registry when available.
- Files changed: `packages/orbiter-core/src/orbiter/runner.py` (~100 lines), `packages/orbiter-core/tests/test_runner.py` (13 tests in 5 classes)
- Key implementation details:
  - `run(agent, input, *, messages, provider, max_retries, loop_threshold) -> RunResult` — async, delegates to `call_runner()`
  - `run.sync(...)` — attached as attribute on `run` function, uses `asyncio.run()` internally
  - `_resolve_provider(agent)` — tries `orbiter.models.provider.get_provider()` with graceful fallback to `None`
  - Provider typed as `Any` since orbiter-core doesn't depend on orbiter-models
- **Learnings for future iterations:**
  - Python functions are objects — you can attach attributes like `run.sync = _sync` with `# type: ignore[attr-defined]` for pyright
  - `asyncio.run()` creates a new event loop, so `run.sync()` can't be called from within an existing async context — this is the expected behavior
  - Auto-provider resolution uses try/except to gracefully handle missing orbiter-models package
  - 458 tests total across full suite (13 new)
---

## 2026-02-15 - US-011
- What was implemented: `run.stream()` async generator attached to the `run` function, yielding `TextEvent` for text deltas and `ToolCallEvent` for tool invocations. Supports full tool execution loop with re-streaming after tool results.
- Files changed: `packages/orbiter-core/src/orbiter/runner.py` (added `_stream()` ~110 lines), `packages/orbiter-core/tests/test_runner.py` (added 10 tests in 3 new test classes + streaming helpers)
- Key implementation details:
  - `run.stream(agent, input, ...)` uses `provider.stream()` for chunk-by-chunk text delivery
  - Tool call deltas accumulated from `StreamChunk.tool_call_deltas` by index, then assembled into `ToolCall` objects
  - After tool calls: executes tools via `agent._execute_tools()`, appends results to conversation, re-streams
  - Loop continues until text-only response or `max_steps` reached
  - Error in no-provider case raises `AgentError` immediately
- **Learnings for future iterations:**
  - `_resolve_provider` passes `agent.provider_name` to `get_provider()`, which calls `parse_model_string()` again — a bare name like "nonexistent" gets parsed as `("openai", "nonexistent")` and resolves to OpenAI provider. To test no-provider scenarios, monkeypatch `_resolve_provider` to return `None`
  - Same pyright issue with `agent.instructions` returning `object | Any` — use `str()` cast pattern (instr/raw_instr) consistent with call_runner.py
  - Streaming doesn't use `call_runner()` or `Agent.run()` — it operates at a lower level, directly calling `provider.stream()` and managing the tool loop itself. This is by design for real-time event delivery
  - 468 tests total across full suite (10 new streaming tests)
---

## 2026-02-15 - US-012
- What was implemented: Handler system with `Handler[IN, OUT]` ABC (generic async generator base), `AgentHandler` (routes between agents in swarms), `SwarmMode` enum (workflow/handoff/team), handoff detection, and topology-aware stop checks.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/handlers.py` (~130 lines), `packages/orbiter-core/tests/test_handlers.py` (28 tests in 7 classes)
- Key implementation details:
  - `Handler[IN, OUT]` is a generic ABC with abstract `handle(input) -> AsyncIterator[OUT]` — non-async def returning AsyncIterator avoids pyright type issues with abstract async generators
  - `AgentHandler` implements workflow (sequential, output→input chaining), handoff (follow handoff chains with max_handoffs guard), and team (run lead agent) modes
  - Handoff detection: exact match of `result.output.strip()` against agent's handoff target names, with additional check that the target exists in the swarm's agents dict
  - Stop checks are separate methods (`_check_workflow_stop`, `_check_handoff_stop`, `_check_team_stop`) for composability
  - Delegates actual agent execution to `call_runner()` from the existing call_runner module
- **Learnings for future iterations:**
  - Abstract async generator methods in ABCs: use `def handle(...) -> AsyncIterator[T]` (not `async def`) to avoid pyright issues with `yield` in abstract methods yielding `None` instead of `T`
  - Handoff cycle test: when testing A→B→A→B cycles, the mock provider must alternate responses ("b", "a", "b", "a") since each agent checks handoff targets against its own handoffs dict
  - The handler system is the bridge between the runner layer (run/call_runner) and the swarm layer (US-017+). AgentHandler will be used by Swarm to orchestrate multi-agent execution
  - 496 tests total across full suite (28 new handler tests)
---

## 2026-02-15 - US-013
- What was implemented: ToolHandler (dynamic tool loading, parallel execution via asyncio.TaskGroup, result aggregation) and GroupHandler (parallel and serial agent group execution with dependency resolution via Kahn's topological sort).
- Files changed: `packages/orbiter-core/src/orbiter/_internal/handlers.py` (added ~130 lines for ToolHandler + GroupHandler), `packages/orbiter-core/tests/test_handlers.py` (added 23 tests in 6 new test classes)
- Key implementation details:
  - `ToolHandler` — receives dict of `{tool_call_id: {"name": str, "arguments": dict}}`, resolves tools from registry, executes in parallel, yields `ToolResult` objects. Also has `register()`, `register_many()`, `aggregate()` methods
  - `GroupHandler` — `parallel=True` runs all agents concurrently (same input, TaskGroup), `parallel=False` runs serially with output→input chaining and dependency resolution
  - `_resolve_order()` implements Kahn's algorithm for topological sort with cycle detection — raises `HandlerError` on cyclic dependencies
  - Both handlers follow the `Handler[IN, OUT]` ABC pattern from US-012
- **Learnings for future iterations:**
  - When testing with `_make_provider`, response count must match total LLM calls across all agents — each `call_runner()` invocation triggers at least one `provider.complete()` call
  - Custom mock providers in tests need to return objects with `content`, `tool_calls`, and `usage` attributes matching what `parse_response()` expects — `usage=None` will fail
  - To test "missing agent" in serial mode, either override `_resolve_order()` in a subclass or manipulate the agents dict after construction (since `_resolve_order` only includes keys from `self.agents`)
  - 519 tests total across full suite (23 new handler tests)
---

## 2026-02-15 - US-014
- What was implemented: BackgroundTaskHandler with hot-merge and wake-up-merge patterns. BackgroundTask lifecycle (INIT→RUNNING→SUCCESS/FAILED), PendingQueue for async result queuing, merge callbacks, state node integration.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/background.py` (~230 lines), `packages/orbiter-core/tests/test_background.py` (28 tests in 8 classes)
- Key implementation details:
  - `BackgroundTask` — tracks task_id, parent_task_id, payload, result, error, status, merge_mode
  - `PendingQueue` — async-aware queue with `push()`, `pop_all()`, `wait(timeout)` using `asyncio.Event`
  - `BackgroundTaskHandler` — `submit()` registers tasks, `handle_result()` routes to hot or wake-up merge, `handle_error()` for failures, `drain_pending()` async iterator for wake-up pattern
  - Hot-merge: fires registered callbacks when main task is still running
  - Wake-up-merge: queues to PendingQueue when main task completed; drain via `drain_pending()`
  - State integration: creates RunNode with `bg:{task_id}` agent name, marks SUCCESS/FAILED on completion
  - `on_merge(callback)` for registering async merge callbacks
  - `list_tasks(status=...)` for filtered task listing
- **Learnings for future iterations:**
  - BackgroundTaskHandler is NOT a Handler[IN, OUT] subclass — it's a standalone manager rather than a pipeline handler, since background tasks have their own lifecycle separate from the main execution flow
  - `asyncio.TimeoutError` is deprecated in favor of builtin `TimeoutError` (ruff UP041) — just catch `TimeoutError`
  - Unused imports (ruff F401) must be removed even from type-only usage — `RunNode` was imported but only `RunNodeStatus` and `RunState` were needed
  - 547 tests total across full suite (28 new background handler tests)
---

## 2026-02-15 - US-015
- What was implemented: Runner integration tests covering end-to-end Agent + @tool + run() flows, handler pipelines (workflow, handoff, team), ToolHandler/GroupHandler integration, and background task scenarios (hot-merge, wake-up-merge, error handling, callbacks). Updated `packages/orbiter-core/src/orbiter/__init__.py` with public API exports (Agent, run, tool, Tool, FunctionTool).
- Files changed: `packages/orbiter-core/src/orbiter/__init__.py` (added imports + __all__), `packages/orbiter-core/tests/test_runner_integration.py` (22 new tests in 8 test classes)
- **Learnings for future iterations:**
  - `run.sync()` uses `asyncio.run()` which can't be called from within an async test function (already has a running event loop) — make sync tests use `def test_...` (not `async def`)
  - Ruff N817 flags `import X as A` when `A` is a CamelCase name used as an acronym — use longer aliases like `AgentImport` instead of `A`
  - The `__init__.py` for orbiter-core already uses `pkgutil.extend_path()` for namespace packages — imports of `Agent`, `run`, `tool`, `Tool` go after that line
  - 569 tests total across full suite (22 new integration tests)
---

## 2026-02-15 - US-016
- What was implemented: Graph utilities module with `Graph` dataclass (adjacency list), `topological_sort()` (Kahn's algorithm with deterministic ordering), cycle detection, and `parse_flow_dsl()` for parsing flow DSL strings like `"a >> b >> c"` and `"(a | b) >> c"` into Graph objects.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/graph.py` (~130 lines), `packages/orbiter-core/tests/test_graph.py` (31 tests in 4 classes)
- Key implementation details:
  - `Graph` is a `@dataclass` with `_adjacency: dict[str, list[str]]` — add_node (idempotent), add_edge (duplicate-safe, auto-creates nodes), nodes/edges properties, successors(), in_degree()
  - `topological_sort()` uses Kahn's algorithm with `deque` — sorts queue entries for deterministic ordering
  - `parse_flow_dsl()` tokenizes by `>>`, handles `(a | b)` parallel groups via regex, creates edges between all members of consecutive stages
  - `GraphError` raised for cycles, unknown nodes, empty/malformed DSL
- **Learnings for future iterations:**
  - GroupHandler in `handlers.py` already has an inline topo sort (`_resolve_order`) — could be refactored to use graph.py in a future iteration, but not required now
  - `deque.popleft()` is O(1) vs `list.pop(0)` which is O(n) — prefer deque for BFS-style queue operations
  - The `parse_flow_dsl` returns a `Graph` (not just edges) so callers can use `topological_sort()` directly on the result
  - 600 tests total across full suite (31 new graph tests)
---

## 2026-02-15 - US-017
- What was implemented: Swarm class with workflow mode (`packages/orbiter-core/src/orbiter/swarm.py`, ~120 lines). Workflow mode runs agents sequentially with output→input chaining. Uses `parse_flow_dsl()` and `topological_sort()` from graph.py for execution ordering. Updated `runner.py` to detect Swarm (via `hasattr(agent, "flow_order")`) and delegate to `swarm.run()`.
- Files changed: `packages/orbiter-core/src/orbiter/swarm.py` (new, ~120 lines), `packages/orbiter-core/tests/test_swarm.py` (new, 20 tests in 5 classes), `packages/orbiter-core/src/orbiter/runner.py` (added Swarm detection in `run()`)
- Key implementation details:
  - `Swarm.__init__` accepts `agents` (list), `flow` (DSL string, optional), `mode` (default "workflow")
  - Without flow DSL, agents execute in list order. With flow DSL, topological sort determines order
  - `Swarm.run()` delegates to `call_runner()` per agent, chaining output→input
  - Validates: no duplicate agent names, all flow DSL nodes are known agents, no cycles
  - `SwarmError` for all swarm-level errors
  - `describe()` and `__repr__()` for introspection
  - Swarm has a `name` attribute for runner compatibility
- **Learnings for future iterations:**
  - Swarm detection in `run()` uses duck-typing (`hasattr(agent, "flow_order")`) rather than isinstance to avoid circular imports — this works because Agent doesn't have a `flow_order` attribute
  - Swarm.run() has its own `provider` and `max_retries` params, but doesn't take `loop_threshold` (that's Agent-level via call_runner)
  - The AgentHandler from handlers.py already has workflow mode — Swarm is a higher-level API that wraps the same call_runner() directly without going through AgentHandler. Future handoff/team modes (US-018, US-019) may leverage AgentHandler's existing implementations
  - 620 tests total across full suite (20 new swarm tests)
---

## 2026-02-15 - US-018
- What was implemented: Swarm handoff mode (`mode='handoff'`) with dynamic agent-to-agent delegation. Added `_run_handoff()` (handoff chain execution with conversation history transfer), `_detect_handoff()` (output-based handoff detection matching agent's declared handoff targets), and `max_handoffs` parameter for loop detection.
- Files changed: `packages/orbiter-core/src/orbiter/swarm.py` (added ~70 lines for handoff mode), `packages/orbiter-core/tests/test_swarm.py` (added 15 tests in 4 new test classes)
- Key implementation details:
  - `_run_handoff()` starts with the first agent in flow_order, runs it via `call_runner()`, checks output against handoff targets
  - `_detect_handoff()` matches `result.output.strip()` against agent's `handoffs` dict keys, also requires target exists in `swarm.agents`
  - `max_handoffs` uses `>` semantics (default 10): allows exactly `max_handoffs` transitions before raising `SwarmError`
  - Conversation history from each agent's run (`result.messages`) is passed to the next agent as `all_messages`
  - Handoff target not in swarm's agents dict → no handoff (agent output returned as-is)
- **Learnings for future iterations:**
  - `max_handoffs` boundary: use `>` not `>=` so that `max_handoffs=N` allows exactly N handoffs. The AgentHandler in handlers.py uses `>=` which is slightly different semantics
  - `call_runner` builds messages internally per agent — the `result.messages` from RunState are minimal (system + user + assistant). Passing them as `all_messages` to the next call_runner allows conversation history transfer, but each agent still builds its own message list
  - Ruff RUF043: regex metacharacters in `pytest.raises(match=...)` require raw strings (e.g., `match=r"Max handoffs.*3.*exceeded"`)
  - 635 tests total across full suite (15 new handoff tests)
---

## 2026-02-15 - US-019
- What was implemented: Swarm team mode (`mode='team'`) with lead-worker delegation pattern. Lead agent gets auto-generated `_DelegateTool` instances (`delegate_to_{worker_name}`) that invoke worker agents when called. Workers run via `call_runner()` and return their output as tool results. Lead synthesizes final output after receiving worker results.
- Files changed: `packages/orbiter-core/src/orbiter/swarm.py` (added `_run_team()` ~50 lines, `_DelegateTool` class ~50 lines), `packages/orbiter-core/tests/test_swarm.py` (added 13 tests in 4 new test classes)
- Key implementation details:
  - `_DelegateTool` is a `Tool` subclass with manually defined JSON schema (task parameter), calls `call_runner()` on the worker
  - `_run_team()` temporarily adds delegate tools to lead's `self.tools`, runs `call_runner(lead, ...)`, then restores original tools in a `finally` block
  - Team mode requires at least 2 agents (lead + at least one worker)
  - Workers receive the lead's tool-call argument `task` as their input, not the original user input
- **Learnings for future iterations:**
  - Mock providers for team mode need `Usage` objects (not `None`) in dict-form responses — `parse_response(usage=None)` causes `AgentOutput` Pydantic validation to fail, which gets caught by `_call_llm`'s retry loop, consuming the next response instead
  - The provider `complete()` call count is shared across lead + worker agents since the mock is a single closure — responses must be ordered accounting for worker calls interleaved with lead calls
  - `_DelegateTool` follows the same pattern as `HumanInputTool` — custom `Tool` subclass with manually defined JSON schema rather than `_generate_schema()` from a function
  - Using `finally` block to restore tools ensures cleanup even on errors (important for tool-loop exceptions propagating up)
  - 648 tests total across full suite (13 new team mode tests)
---

## 2026-02-15 - US-020
- What was implemented: ParallelGroup (concurrent agent execution via `asyncio.TaskGroup` with configurable result aggregation) and SerialGroup (sequential output→input chaining) in `packages/orbiter-core/src/orbiter/_internal/agent_group.py`. Both integrate as nodes in Swarm workflow via `is_group` marker attribute. Swarm's `_run_workflow()` updated to detect groups and delegate to their `run()` method.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/agent_group.py` (new, ~236 lines), `packages/orbiter-core/tests/test_agent_group.py` (new, 27 tests in 7 classes), `packages/orbiter-core/src/orbiter/swarm.py` (updated `_run_workflow` for group detection)
- Key implementation details:
  - `ParallelGroup` — concurrent execution via `asyncio.TaskGroup`, default join with `\n\n` separator, optional custom `aggregate_fn(list[RunResult]) -> str`, usage/steps summed across all agents
  - `SerialGroup` — sequential execution with output→input chaining, accumulated usage/steps, final agent's output is the group output
  - Both have `is_group = True` marker, `name` attribute, `run()` method matching Agent/Swarm interface, and `describe()`/`__repr__()` for introspection
  - Swarm detects groups via `getattr(agent, "is_group", False)` in `_run_workflow()` — similar duck-typing pattern as Swarm detection in `runner.py`
  - Groups can be used standalone (without Swarm) or as nodes in Swarm flow DSL
- **Learnings for future iterations:**
  - Groups need the same interface as agents from Swarm's perspective: `name` attribute and `run(input, *, messages, provider, max_retries)` method
  - Duck-typing via `is_group` marker is cleaner than isinstance checks since it avoids circular imports
  - The existing `GroupHandler` in `handlers.py` has similar parallel/serial logic but operates at the handler layer — `ParallelGroup`/`SerialGroup` are the public-facing API while `GroupHandler` is the internal handler abstraction
  - 675 tests total across full suite (27 new agent group tests)
---

## 2026-02-15 - US-021
- What was implemented: Nested swarm support via `SwarmNode` wrapper class in `packages/orbiter-core/src/orbiter/_internal/nested.py`. `SwarmNode` wraps a Swarm so it can be used as a node in another Swarm's agent list. Context isolation: inner swarm gets clean message history (outer messages NOT forwarded). Updated `Swarm._run_workflow()` to detect `is_swarm` marker via duck-typing.
- Files changed: `packages/orbiter-core/src/orbiter/_internal/nested.py` (new, ~107 lines), `packages/orbiter-core/tests/test_nested.py` (new, 14 tests in 5 classes), `packages/orbiter-core/src/orbiter/swarm.py` (1-line change in `_run_workflow`)
- Key implementation details:
  - `SwarmNode` has `is_swarm = True` marker, `name` attribute, and `run()` method — same interface pattern as `ParallelGroup`/`SerialGroup` with `is_group`
  - `_run_workflow()` condition: `getattr(agent, "is_group", False) or getattr(agent, "is_swarm", False)` — both groups and nested swarms use `agent.run()` directly
  - Context isolation: `SwarmNode.run()` does NOT forward outer `messages` to inner swarm — each level maintains its own conversation context
  - Inner swarm can use any mode (workflow, handoff, team) — tested with both workflow and handoff modes
  - `NestedSwarmError` for validation errors, `describe()` includes inner swarm metadata
- **Learnings for future iterations:**
  - The duck-typing pattern (`is_group`, `is_swarm`) is consistent across the codebase for detecting node types without isinstance checks
  - `Agent.__init__` expects `handoffs` as `list[Agent]`, NOT `dict` — the dict is built internally by `_register_handoff()`
  - SwarmNode's context isolation is a design choice: inner swarm starts fresh each time, which prevents message pollution between nesting levels
  - 689 tests total across full suite (14 new nested swarm tests)
---

## 2026-02-15 - US-022
- What was implemented: Swarm integration with the public `run()` API and public API exports. Updated `packages/orbiter-core/src/orbiter/__init__.py` to export `Swarm`, `SwarmNode`, `ParallelGroup`, `SerialGroup`. Created comprehensive integration tests covering all swarm modes and features via the public `run()` entry point.
- Files changed: `packages/orbiter-core/src/orbiter/__init__.py` (added 6 new exports), `packages/orbiter-core/tests/test_swarm_integration.py` (new, 21 tests in 8 classes)
- Integration test coverage:
  - Workflow mode: 2-agent, 3-agent pipeline, no-flow-DSL, sync wrapper
  - Handoff mode: simple handoff, A→B→C chain, no-handoff-returns-directly
  - Team mode: lead-delegates-to-worker, lead-no-delegation
  - Groups: ParallelGroup in workflow, SerialGroup in workflow, custom aggregation
  - Nested swarms: nested workflow, nested handoff-inside-workflow
  - Public API: Swarm/SwarmNode/ParallelGroup/SerialGroup importable from `orbiter`, run() detects Agent vs Swarm
  - Tools in workflows: agent uses @tool then chains to next agent
- **Learnings for future iterations:**
  - Swarm was already wired into `run()` via `hasattr(agent, "flow_order")` from US-017 — this story only needed to add public exports and integration tests
  - The `_make_provider` mock must account for ALL LLM calls across ALL agents in a swarm (e.g., 3-agent pipeline = 3 responses, team with delegation = lead + worker + lead = 3 responses)
  - `__init__.py` imports must be sorted alphabetically by module path for ruff I001 compliance
  - 710 tests total across full suite (21 new swarm integration tests)
---

## 2026-02-15 - US-023
- What was implemented: Created `orbiter-context` package from scratch — added workspace registration, pyproject.toml, directory structure. Implemented `ContextConfig` (Pydantic v2 frozen model with `AutomationMode` enum: pilot/copilot/navigator, history_rounds, summary_threshold, offload_threshold, enable_retrieval, neuron_names tuple, extra dict, threshold validation) and `make_config()` factory with preset defaults per automation level. Implemented `ContextState` (hierarchical key-value store with parent chain lookup, write isolation, get/set/update/delete/pop/clear/to_dict/local_dict/keys).
- Files changed:
  - `pyproject.toml` (root — added orbiter-context to workspace members, dev deps, uv.sources)
  - `packages/orbiter-context/pyproject.toml` (new package config)
  - `packages/orbiter-context/src/orbiter/context/__init__.py` (new)
  - `packages/orbiter-context/src/orbiter/context/config.py` (~120 lines — AutomationMode, ContextConfig, make_config)
  - `packages/orbiter-context/src/orbiter/context/state.py` (~130 lines — ContextState)
  - `packages/orbiter-context/tests/test_context_config.py` (22 tests: defaults, frozen, validation, neuron coercion, serialization, factory)
  - `packages/orbiter-context/tests/test_context_state.py` (35 tests: read/write, delete/pop/clear, update, parent inheritance, introspection, bool, repr)
- **Learnings for future iterations:**
  - Creating a new namespace package requires adding it to 3 places in root pyproject.toml: `[tool.uv.workspace] members`, `[dependency-groups] dev`, and `[tool.uv.sources]`
  - Same pyright `reportMissingImports` issue applies to orbiter-context test files — use `# pyright: ignore[reportMissingImports]` on import lines
  - `ContextState` uses `__slots__` for memory efficiency — all instance attributes (`_data`, `_parent`) must be declared there
  - Pydantic v2 frozen models: use `model_validator(mode="after")` for cross-field validation (e.g., summary_threshold <= offload_threshold)
  - Use `tuple[str, ...]` (not `list`) for frozen model fields that should be immutable; accept `list` via `model_validator(mode="before")` coercion
  - 767 tests total across full suite (57 new context tests)
---

## 2026-02-15 - US-024
- What was implemented: Context class with fork/merge for hierarchical task decomposition. `ContextError` exception. `Context.__init__` accepts task_id (required), config, parent, state. Properties: task_id, config, parent, state, children, token_usage. `add_tokens()` for token tracking. `fork(task_id)` creates child context with state inheritance and token snapshot. `merge(child)` consolidates child local state and net token deltas back into parent.
- Files changed: `packages/orbiter-context/src/orbiter/context/context.py` (new, ~160 lines), `packages/orbiter-context/tests/test_context.py` (new, 35 tests in 8 classes), `packages/orbiter-context/tests/test_context_config.py` (import sorting fix from ruff)
- Key implementation details:
  - `_token_snapshot` stores parent's usage at fork time (immutable copy), separate from `_token_usage` which tracks current usage. Merge computes net = current - snapshot
  - `fork()` auto-sets child's config from parent (shared immutable reference), creates ContextState with parent chain, copies token usage as starting point
  - `merge()` validates child.parent identity, merges child's `local_dict()` state, adds net-positive token deltas
  - `__slots__` for memory efficiency, sorted alphabetically per ruff RUF023
- **Learnings for future iterations:**
  - Within-package imports (e.g., `context.py` importing from `config.py` in the same `orbiter.context` namespace package) also need `# pyright: ignore[reportMissingImports]` due to `.pth`-based editable installs
  - Ruff RUF023 requires `__slots__` entries to be sorted alphabetically — use `--fix` to auto-sort
  - For net token merge calculation, storing a separate `_token_snapshot` at fork time is essential — the `_token_usage` dict gets mutated by `add_tokens()` and can't serve as its own baseline
  - 802 tests total across full suite (35 new context tests)
---

## 2026-02-15 - US-025
- What was implemented: TokenTracker — per-agent, per-step token tracking for cost analysis and budget enforcement. `TokenStep` (frozen dataclass with agent_id, step index, prompt/output tokens, total_tokens property). `TokenUsageSummary` (frozen dataclass for aggregated usage). `TokenTracker` (add_step with auto step indexing, get_trajectory, total_usage, agent_usage, agent_ids, steps, len/repr).
- Files changed: `packages/orbiter-context/src/orbiter/context/token_tracker.py` (new, ~130 lines), `packages/orbiter-context/tests/test_token_tracker.py` (new, 24 tests in 7 classes)
- **Learnings for future iterations:**
  - TokenTracker is standalone (no dependencies on Context/ContextState) — it can be used independently or composed into Context
  - `dataclass(frozen=True, slots=True)` is the right pattern for immutable value objects like TokenStep/TokenUsageSummary
  - Step index is per-agent (computed by counting existing steps for the agent), not global — this makes trajectories self-contained
  - The `field` import from dataclasses wasn't needed (no mutable defaults) — ruff F401 catches unused imports
  - 826 tests total across full suite (24 new token tracker tests)
---
