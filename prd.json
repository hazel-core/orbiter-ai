{
  "project": "Orbiter",
  "branchName": "ralph/orbiter-smart-agents",
  "description": "Orbiter Smart Agents — audit fixes, comprehensive logging, auto-wired context engine and persistent memory, pluggable backends, vector search, conversation branching, dynamic tool loading, agent self-spawn, large-output offloading for @tool and MCP, and MCP progress stream events.",
  "userStories": [
    {
      "id": "US-001",
      "title": "B-1: Fix sandbox code injection via repr() serialization",
      "description": "As an Orbiter platform operator, I want user-submitted code to be safely serialized so no crafted payload can escape the sandbox string-literal context.",
      "acceptanceCriteria": [
        "In orbiter-web/services/sandbox.py _build_runner_script(), replace the manual .replace()-based escaping with repr() or json.dumps() serialization of the user code string",
        "Verify that code containing \\r, \\t, \\0, null bytes, \\u0041, and embedded triple-quotes does not break the generated script",
        "Add test test_sandbox_escape_sequences: assert code with those characters executes safely and produces the correct output (no injection)",
        "uv run pytest packages/orbiter-web/",
        "Typecheck passes"
      ],
      "priority": 1,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-002",
      "title": "B-2: Reject default secret key at startup in production",
      "description": "As an Orbiter platform operator, I want the server to refuse to start with the default secret key so production deployments are never silently insecure.",
      "acceptanceCriteria": [
        "In orbiter-web/app.py lifespan startup, raise RuntimeError('ORBITER_SECRET_KEY must be changed in production') when settings.debug is False and settings.secret_key == 'change-me-in-production'",
        "When ORBITER_DEBUG=1 (debug=True), the check is skipped — local dev is unaffected",
        "Add inline comment in orbiter-web/config.py on the secret_key field: '# Override via ORBITER_SECRET_KEY — MUST change in production'",
        "Add test test_startup_rejects_default_key: assert RuntimeError is raised when debug=False and key is default",
        "uv run pytest packages/orbiter-web/",
        "Typecheck passes"
      ],
      "priority": 2,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-003",
      "title": "B-4: Validate webhook URL token against stored value",
      "description": "As an Orbiter platform operator, I want webhook trigger endpoints to validate the url_token so only callers with the correct token can trigger workflows.",
      "acceptanceCriteria": [
        "In orbiter-web/routes/webhooks.py, at the top of the POST /api/v1/webhooks/{workflow_id}/{hook_id} handler, fetch the webhook row from the database",
        "Return 404 Not Found if the row does not exist",
        "Compare the url_token query parameter against the stored value using hmac.compare_digest() (constant-time comparison)",
        "Return 403 Forbidden with body {\"detail\": \"Invalid token\"} if the comparison fails or the parameter is missing",
        "Add test test_webhook_trigger_requires_token: assert 403 on wrong/missing token, 200 on correct token",
        "uv run pytest packages/orbiter-web/",
        "Typecheck passes"
      ],
      "priority": 3,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-004",
      "title": "B-8: Remove plaintext password reset token from logs",
      "description": "As an Orbiter platform operator, I want password reset tokens to never appear in log files so account takeover via log access is not possible.",
      "acceptanceCriteria": [
        "Remove the log line at orbiter-web/routes/auth.py:389 that emits the raw token entirely",
        "Replace with logger.debug('Password reset email sent to %s', body.email) — no token in any log output",
        "Grep the entire orbiter-web package for any other log lines that emit tokens, session IDs, or raw credentials and remove them",
        "uv run pytest packages/orbiter-web/",
        "Typecheck passes"
      ],
      "priority": 4,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-005",
      "title": "L-2: Fix stream_agent to use the full agent tool loop",
      "description": "As an Orbiter platform user, I want agent streaming to execute tool calls correctly so LLM tool calls are not silently dropped in streaming mode.",
      "acceptanceCriteria": [
        "Rewrite AgentService.stream_agent() in orbiter-web/services/agent_runtime.py to call agent.run.stream(input, messages=messages) instead of calling provider.stream() directly",
        "Tool calls emitted by the LLM during streaming are executed by the agent tool loop and their results included in the stream",
        "The streaming response format to the WebSocket/HTTP caller is unchanged (same event types as before)",
        "Add test test_stream_agent_executes_tools: a tool registered on the agent is called when the LLM emits a tool_call during streaming",
        "uv run pytest packages/orbiter-web/",
        "Typecheck passes"
      ],
      "priority": 5,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-006",
      "title": "B-15: Await async callable instructions at all 3 call sites",
      "description": "As an Orbiter developer, I want agents to correctly handle async callables passed as instructions so the system prompt is never a stale coroutine object.",
      "acceptanceCriteria": [
        "At each of the 3 call sites (orbiter-core/agent.py:214-215, runner.py:242-245, _internal/call_runner.py:93-96), replace the sync call with: if asyncio.iscoroutinefunction(raw_instr): instructions = await raw_instr(self.name) else: instructions = raw_instr(self.name)",
        "All 3 code paths are fixed — verify by searching for callable(raw_instr) or equivalent and confirming each uses the awaited pattern",
        "Add test test_async_callable_instructions: passing async def make_prompt(name): return f'You are {name}' as instructions produces the correct string in the system prompt (not a coroutine object)",
        "uv run pytest packages/orbiter-core/",
        "Typecheck passes"
      ],
      "priority": 6,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-007",
      "title": "US-011a: orbiter-observability — ORBITER_LOG_LEVEL and ORBITER_DEBUG env vars",
      "description": "As an Orbiter developer, I want a single env var to control log verbosity globally so I can toggle debug output without code changes.",
      "acceptanceCriteria": [
        "In orbiter-observability/src/orbiter/observability/logging.py, read ORBITER_LOG_LEVEL at import time (default WARNING; valid: DEBUG, INFO, WARNING, ERROR)",
        "ORBITER_DEBUG=1 sets root level to DEBUG and takes precedence over ORBITER_LOG_LEVEL",
        "Both vars are applied to the root 'orbiter' logger so all child loggers inherit the setting automatically",
        "Log format set to: '%(asctime)s %(levelname)-8s %(name)s  %(message)s'",
        "get_logger(name) returns a child of orbiter.* so the root-level config propagates",
        "uv run pytest packages/orbiter-observability/",
        "Typecheck passes"
      ],
      "priority": 7,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-008",
      "title": "US-011b: Add logging to orbiter-context and orbiter-memory",
      "description": "As an Orbiter developer, I want orbiter-context and orbiter-memory to emit detailed logs so I can trace context windowing, summarization, and memory lifecycle events.",
      "acceptanceCriteria": [
        "All files use stdlib logging: import logging / logger = logging.getLogger(__name__)",
        "orbiter-context/config.py: logger.debug('ContextConfig created mode=%s history_rounds=%d') in make_config()",
        "orbiter-context/processor.py: logger.debug('Processing context with %d neurons') + logger.debug('ToolResultOffloader: offloading tool=%s size=%d bytes') when offloading fires",
        "orbiter-context/token_tracker.py: logger.debug('TokenTracker: used=%d / total=%d (%.0f%%)') after each usage update",
        "orbiter-context/summary.py: logger.info('Summarization triggered: threshold=%d messages=%d') + logger.debug('Summary generated length=%d')",
        "orbiter-context/workspace.py: logger.debug('Artifact stored: id=%s size=%d bytes') + logger.debug('Artifact retrieved: id=%s')",
        "orbiter-memory/persistence.py: logger.debug pre-run load_history and post-run save messages",
        "orbiter-memory/short_term.py: logger.debug on add and search",
        "orbiter-memory/long_term.py: logger.debug on add + logger.info on long-term extraction trigger",
        "orbiter-memory/backends/sqlite.py and postgres.py: logger.debug on search results",
        "uv run pytest packages/orbiter-context/ packages/orbiter-memory/",
        "Typecheck passes"
      ],
      "priority": 8,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-009",
      "title": "US-011c: Add logging to orbiter-a2a, orbiter-cli, orbiter-distributed",
      "description": "As an Orbiter developer, I want orbiter-a2a, orbiter-cli, and orbiter-distributed to emit structured logs so I can trace A2A calls, CLI commands, and distributed task lifecycle.",
      "acceptanceCriteria": [
        "All files use stdlib logging: import logging / logger = logging.getLogger(__name__)",
        "orbiter-a2a/server.py: logger.info run start/complete + logger.error on failure with exc_info=True",
        "orbiter-a2a/client.py: logger.debug on describe and run calls",
        "orbiter-cli entry point(s): logger.debug('CLI command=%s args=%r') at start of each command + logger.error on failure",
        "orbiter-distributed/client.py: logger.info on task submitted and received",
        "orbiter-distributed/worker.py: logger.info on task received/complete + logger.error on failure with exc_info=True",
        "orbiter-distributed/broker.py: logger.debug on enqueue and dequeue",
        "uv run pytest packages/orbiter-a2a/ packages/orbiter-distributed/",
        "Typecheck passes"
      ],
      "priority": 9,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-010",
      "title": "US-011d: Add logging to orbiter-eval, orbiter-sandbox, orbiter-server, orbiter-train",
      "description": "As an Orbiter developer, I want orbiter-eval, orbiter-sandbox, orbiter-server, and orbiter-train to emit logs so scorer failures, sandbox execution, and training stubs are visible.",
      "acceptanceCriteria": [
        "All files use stdlib logging: import logging / logger = logging.getLogger(__name__)",
        "orbiter-eval/runner.py: logger.info run start with dataset/case count + logger.warning('Scorer failed case=%d: %s') replacing bare except: pass (fixes audit C-10)",
        "orbiter-eval/trajectory_scorers.py: logger.debug per-case score",
        "orbiter-sandbox/base.py: logger.info on start/stop + logger.debug on run_tool",
        "orbiter-sandbox/tools.py: logger.debug on command + logger.warning when blocklist fires",
        "orbiter-server entry point: logger.info on server start with host/port",
        "orbiter-train/train/verl.py: logger.info train start + logger.warning('VeRLTrainer.train: STUB — no real training performed') to flag C-3",
        "orbiter-train/train/evolution.py: logger.info per generation + logger.debug best fitness",
        "uv run pytest packages/orbiter-eval/ packages/orbiter-sandbox/ packages/orbiter-train/",
        "Typecheck passes"
      ],
      "priority": 10,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-011",
      "title": "US-011e: Add logging to orbiter-web engine and services",
      "description": "As an Orbiter developer, I want the orbiter-web workflow engine and services to emit logs so I can trace workflow execution, node steps, agent runtime calls, and scheduler triggers.",
      "acceptanceCriteria": [
        "All files use stdlib logging: import logging / logger = logging.getLogger(__name__)",
        "orbiter-web/engine.py: logger.info workflow start + logger.debug node execute with type + logger.info node complete with elapsed + logger.error node failed with exc_info=True",
        "orbiter-web/engine.py: replace contextlib.suppress(Exception) on WebSocket send with try/except + logger.warning('WebSocket send failed: %s', exc) (fixes audit B-16)",
        "orbiter-web/services/agent_runtime.py: logger.info on run_agent/stream_agent start + logger.debug tool call + logger.error on failure",
        "orbiter-web/services/scheduler.py: logger.info on trigger + logger.debug next_run",
        "orbiter-web/services/memory.py: logger.debug on search",
        "orbiter-web/services/sandbox.py: logger.debug code len + logger.warning on timeout",
        "uv run pytest packages/orbiter-web/",
        "Typecheck passes"
      ],
      "priority": 11,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-012",
      "title": "US-001a: AgentMemory dataclass + MemoryStore protocol + idempotent attach()",
      "description": "As an Orbiter developer, I need the AgentMemory dataclass and extended MemoryStore protocol defined so memory backends are swappable via a single entry point.",
      "acceptanceCriteria": [
        "Add AgentMemory dataclass to orbiter-memory/src/orbiter/memory/base.py with fields: short_term: MemoryStore, long_term: MemoryStore",
        "Extend MemoryStore protocol to include search(query: str, limit: int = 10) -> list[MemoryItem] with a keyword-search default in the base class",
        "Make MemoryPersistence.attach() idempotent: track attached agent IDs in an internal set; second call for the same agent is a no-op (fixes audit L-6)",
        "Export AgentMemory from orbiter-memory __init__.py",
        "uv run pytest packages/orbiter-memory/",
        "Typecheck passes"
      ],
      "priority": 12,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-013",
      "title": "US-001b: MemoryPersistence.load_history() + conversation_id + ORBITER_MEMORY_PATH",
      "description": "As an Orbiter developer, I need MemoryPersistence to expose a load_history() method and the default SQLite path to be env-var-configurable so conversation history can be loaded before each run.",
      "acceptanceCriteria": [
        "Add load_history(agent_name: str, conversation_id: str, rounds: int) -> list[Message] to MemoryPersistence in orbiter-memory/src/orbiter/memory/persistence.py",
        "load_history queries short_term memory for the last `rounds` message pairs scoped to the conversation_id",
        "Default SQLiteMemoryStore path reads ORBITER_MEMORY_PATH env var (default: ~/.orbiter/memory.db, expanding ~)",
        "uv run pytest packages/orbiter-memory/",
        "Typecheck passes"
      ],
      "priority": 13,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-014",
      "title": "US-001c: Wire default AgentMemory into Agent.__init__ and Swarm",
      "description": "As an Orbiter user, I want Agent() to automatically create short-term and long-term memory with safe defaults so I never have to configure memory manually.",
      "acceptanceCriteria": [
        "Agent.__init__ gains memory: AgentMemory | None parameter — when omitted (sentinel default), auto-creates AgentMemory(short_term=ShortTermMemory(), long_term=SQLiteMemoryStore(path=default_path))",
        "Agent(memory=None) fully disables memory — no persistence, no history loading anywhere in the lifecycle",
        "Agent(memory=AgentMemory(short_term=X, long_term=Y)) uses the provided backends",
        "Swarm propagates the same memory defaults to its lead agent when no memory is specified",
        "conversation_id: str | None added as Agent instance attribute (None initially; auto-assigned UUID4 on first run())",
        "uv run pytest packages/orbiter-core/ packages/orbiter-memory/",
        "Typecheck passes"
      ],
      "priority": 14,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-015",
      "title": "US-006: Pre-run history loading and post-run persistence in Agent.run() and stream()",
      "description": "As an Orbiter user, I want agents to automatically continue conversations where they left off so I never have to manually pass messages= between runs.",
      "acceptanceCriteria": [
        "At the start of Agent.run(), when memory is set: auto-assign conversation_id UUID4 if not yet set; call load_history() and prepend the returned messages before the LLM call",
        "agent.run(input, messages=[...]) still works — explicit messages take precedence and are merged with history (not replaced)",
        "agent.run(input, conversation_id='...') overrides the instance conversation_id for that call only",
        "After Agent.run() completes, new messages are persisted via MemoryPersistence",
        "Same pre-run load and post-run save lifecycle applies inside Agent.stream()",
        "A new run queries fresh from the store each time — does not reuse in-memory message objects from previous runs",
        "Add test test_second_run_picks_up_history: second run() on the same agent instance sees messages from the first run prepended in history",
        "uv run pytest packages/orbiter-core/ packages/orbiter-memory/",
        "Typecheck passes"
      ],
      "priority": 15,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-016",
      "title": "US-002a: context_mode param + ContextConfig auto-creation in Agent and Swarm",
      "description": "As an Orbiter user, I want Agent() to automatically create a copilot-level context config so context windowing and summarization are on by default without any setup.",
      "acceptanceCriteria": [
        "Agent.__init__ gains context_mode: str | AutomationMode | None parameter accepting 'pilot', 'copilot', 'navigator' or AutomationMode enum values",
        "When context_mode is omitted (not explicitly set to None), Agent auto-creates ContextConfig(mode='copilot') via make_config()",
        "Agent gains context: ContextConfig | None parameter for passing a fully custom ContextConfig (takes precedence over context_mode when provided)",
        "Agent(context=None) or Agent(context_mode=None) fully disables the context engine",
        "ContextConfig.token_budget_trigger: float = 0.8 field added to orbiter-context/config.py",
        "Swarm gains the same context_mode parameter and propagates it to member agents",
        "uv run pytest packages/orbiter-core/ packages/orbiter-context/",
        "Typecheck passes"
      ],
      "priority": 16,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-017",
      "title": "US-002b: Wire ContextConfig windowing + summarization into Agent.run()",
      "description": "As an Orbiter user, I want the context engine to actively window, summarize, and offload messages during run() so my agent never exceeds its token limit.",
      "acceptanceCriteria": [
        "Before the LLM call in Agent.run() and stream(), when context is set: apply message windowing per ContextConfig.history_rounds (trim oldest messages beyond the window)",
        "When message count hits summary_threshold, call orbiter-memory summary.check_trigger() + generate_summary() and replace old messages with the summary",
        "When offload_threshold is hit, the context engine fires offloading",
        "After each run(), new messages are persisted via MemoryPersistence (does not double-persist if US-015 already handles this — verify and deduplicate)",
        "uv run pytest packages/orbiter-core/ packages/orbiter-context/",
        "Typecheck passes"
      ],
      "priority": 17,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-018",
      "title": "US-003a: ModelConfig.context_window_tokens + context window registry for well-known models",
      "description": "As an Orbiter developer, I need ModelConfig to expose a context_window_tokens field and well-known models to have their sizes registered so token-fill ratio can be computed.",
      "acceptanceCriteria": [
        "Add context_window_tokens: int | None = None field to ModelConfig in orbiter-core/src/orbiter/types.py",
        "Add MODEL_CONTEXT_WINDOWS dict in orbiter-models mapping model name strings to int token counts, covering at minimum: gpt-4o: 128000, gpt-4o-mini: 128000, o1: 200000, claude-sonnet-4-6: 200000, claude-opus-4-6: 200000, claude-haiku-4-5-20251001: 200000, gemini-2.0-flash: 1048576, gemini-1.5-pro: 2097152",
        "When resolving a model string to ModelConfig, look up context_window_tokens in MODEL_CONTEXT_WINDOWS and populate the field (None if not found)",
        "uv run pytest packages/orbiter-models/ packages/orbiter-core/",
        "Typecheck passes"
      ],
      "priority": 18,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-019",
      "title": "US-003b: Wire TokenTracker to ModelResponse.usage + system prompt token augmentation",
      "description": "As an Orbiter agent, I need token usage tracked automatically after every LLM call and my system prompt augmented with context fill percentage so the system can trigger early summarization.",
      "acceptanceCriteria": [
        "After every LLM call in the agent runner, feed ModelResponse.usage into TokenTracker (orbiter-context/token_tracker.py)",
        "TokenTracker accepts Usage from orbiter.types and updates used/total counts internally",
        "When context_window_tokens is known and token fill ratio exceeds ContextConfig.token_budget_trigger (default 0.8), trigger summarization regardless of message count threshold",
        "When token info is available, append to the agent system prompt: [Context: {used}/{total} tokens ({pct}% full)]",
        "uv run pytest packages/orbiter-context/ packages/orbiter-core/",
        "Typecheck passes"
      ],
      "priority": 19,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-020",
      "title": "US-004: Complete PostgresMemoryStore with asyncpg",
      "description": "As an Orbiter developer, I want a fully implemented PostgresMemoryStore so I can use Postgres as the long-term memory backend in production.",
      "acceptanceCriteria": [
        "Complete all methods in orbiter-memory/src/orbiter/memory/backends/postgres.py: add(), search(), clear(), get_recent() using asyncpg",
        "search() implements the same 4-field metadata filter logic as SQLiteMemoryStore.search()",
        "_row_to_item() and _extra_fields() helpers implemented consistent with the sqlite backend",
        "Agent(..., memory=AgentMemory(long_term=PostgresMemoryStore(url='postgresql://...'))) works end-to-end (use asyncpg mock or in-process test double)",
        "asyncpg listed as an optional dep in orbiter-memory/pyproject.toml — verify or add",
        "uv run pytest packages/orbiter-memory/",
        "Typecheck passes"
      ],
      "priority": 20,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-021",
      "title": "US-005a: EmbeddingProvider protocol + VectorMemoryStore ChromaDB implementation",
      "description": "As an Orbiter developer, I need a fully implemented VectorMemoryStore using ChromaDB so agents can semantically search their own memory.",
      "acceptanceCriteria": [
        "Define EmbeddingProvider runtime-checkable protocol in orbiter-memory/src/orbiter/memory/backends/vector.py: async def embed(text: str) -> list[float]",
        "Implement OpenAIEmbeddingProvider using text-embedding-3-small (reads OPENAI_API_KEY)",
        "Implement SentenceTransformerEmbeddingProvider as local fallback (optional dep: sentence-transformers)",
        "Implement VectorMemoryStore with ChromaDB: add(), search(query, limit), clear(), get_recent()",
        "Add chromadb>=0.6 as an optional dep in orbiter-memory/pyproject.toml",
        "uv run pytest packages/orbiter-memory/tests/test_vector.py (mock ChromaDB client in tests — do not require installed chromadb for CI)",
        "Typecheck passes"
      ],
      "priority": 21,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-022",
      "title": "US-005b: Wire vector search into pre-run KnowledgeNeuron injection + ChromaDB fallback warning",
      "description": "As an Orbiter user, I want agents to inject semantically relevant past context before each run so retrieved memory is relevant, not just the most recent N messages.",
      "acceptanceCriteria": [
        "When LongTermMemory backend is VectorMemoryStore: pre-run search fires with the current user input as query; top results are injected via KnowledgeNeuron into the agent system message",
        "When LongTermMemory is SQLiteMemoryStore (no ChromaDB): keyword search used instead, no error raised",
        "When chromadb is not importable, LongTermMemory defaults to SQLiteMemoryStore and emits: logger.warning('chromadb not installed; falling back to keyword search. Install with: pip install chromadb')",
        "When chromadb IS importable, LongTermMemory auto-selects VectorMemoryStore as its default backend",
        "uv run pytest packages/orbiter-memory/ packages/orbiter-core/",
        "Typecheck passes"
      ],
      "priority": 22,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-023",
      "title": "US-007: Conversation branching via agent.branch()",
      "description": "As an Orbiter user, I want to branch a conversation at any point so I can explore multiple response paths without losing the original thread.",
      "acceptanceCriteria": [
        "Add agent.branch(from_message_id: str) -> str to Agent — returns a new conversation_id (UUID4)",
        "Branched conversation inherits all messages up to and including from_message_id, copied to a new conversation scope (not referenced in place)",
        "The original conversation is unaffected by activity in the branch",
        "Context.fork() used internally to create a child context with inherited state",
        "ShortTermMemory supports filtering by conversation_id (maps to existing task_id scope — verify or add the mapping)",
        "Summarization is tracked per branch-id, not shared with the parent",
        "uv run pytest packages/orbiter-memory/tests/test_branching.py packages/orbiter-core/",
        "Typecheck passes"
      ],
      "priority": 23,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-024",
      "title": "US-008: Dynamic runtime loading — add_tool, add_mcp_server, add_handoff, remove_tool",
      "description": "As an Orbiter user, I want agents to load new tools and sub-agents at runtime without restarting so they can expand their capabilities mid-task.",
      "acceptanceCriteria": [
        "Add async def add_mcp_server(self, config: MCPServerConfig) -> None to Agent: connects the MCP server and appends its tools to the agent's tool list",
        "Add async def add_tool(self, tool: Tool) -> None to Agent: appends a single tool, asyncio-safe via asyncio.Lock",
        "Add async def add_handoff(self, target: Agent) -> None to Agent: registers the target as a sub-agent for delegation",
        "Add def remove_tool(self, tool_name: str) -> None to Agent: unregisters a tool by name, asyncio-safe via the same Lock",
        "All mutations use asyncio.Lock — reuse the pattern from orbiter-mcp/tools.py _reconnect_lock",
        "SkillNeuron re-enumerates agent.tools on each context build so dynamically loaded tools appear automatically",
        "uv run pytest packages/orbiter-core/tests/test_dynamic_loading.py",
        "Typecheck passes"
      ],
      "priority": 24,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-025",
      "title": "US-009: Agent self-spawn capability (opt-in)",
      "description": "As an Orbiter user, I want agents to spawn copies of themselves for parallel sub-tasks when enabled, without setting up a full Swarm.",
      "acceptanceCriteria": [
        "Add allow_self_spawn: bool = False and max_spawn_depth: int = 3 parameters to Agent.__init__",
        "Add internal _spawn_depth: int = 0 attribute to Agent (not in public API / not a Pydantic field)",
        "When allow_self_spawn=True, automatically add a spawn_self(task: str) tool to the agent's tool list in __init__",
        "spawn_self creates a new Agent with same model/instructions/tools, fresh ShortTermMemory, allow_self_spawn=False, and _spawn_depth = parent._spawn_depth + 1",
        "Spawned agents share the parent's LongTermMemory store instance (same object, same namespace)",
        "When _spawn_depth >= max_spawn_depth, spawn_self() returns an error string instead of spawning",
        "Spawned agent run is awaited; result string returned as tool result to parent",
        "uv run pytest packages/orbiter-core/tests/test_self_spawn.py",
        "Typecheck passes"
      ],
      "priority": 25,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-026",
      "title": "US-010a: @tool(large_output=True) + Python ToolResultOffloader wiring",
      "description": "As an Orbiter agent, I want large Python tool results stored in the Workspace instead of injected raw into my context window so token overflow is prevented.",
      "acceptanceCriteria": [
        "Add large_output: bool = False parameter to the @tool decorator in orbiter-core/src/orbiter/tool.py",
        "When a large_output=True tool result is produced, store it in Workspace (orbiter-context/workspace.py) and inject a pointer string instead: [Result stored as artifact '{id}'. Call retrieve_artifact('{id}') to access.]",
        "retrieve_artifact(id: str) -> str tool is auto-added to any agent that has at least one large_output=True Python tool",
        "Wire ToolResultOffloader in orbiter-context/processor.py to intercept large_output=True tool results via the post-tool-call hook",
        "logger.debug('ToolResultOffloader: offloading %s result size=%d bytes artifact_id=%s') emitted on every offload",
        "uv run pytest packages/orbiter-core/tests/test_large_tool_results.py",
        "Typecheck passes"
      ],
      "priority": 26,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-027",
      "title": "US-010b/c: MCPServerConfig.large_output_tools + threshold-based auto-offload for all tools",
      "description": "As an Orbiter agent, I want large MCP tool results and any tool result exceeding a size threshold automatically offloaded so neither MCP nor Python tools overflow my context window.",
      "acceptanceCriteria": [
        "Add large_output_tools: list[str] = [] to MCPServerConfig in the orbiter-mcp config or types file",
        "MCPToolWrapper gains large_output: bool attribute, set at registration time from MCPServerConfig.large_output_tools membership check",
        "When an MCP tool with large_output=True returns a result, offload to Workspace with the same pointer injection as Python tools (US-026)",
        "Any tool result (Python or MCP) exceeding ORBITER_LARGE_OUTPUT_THRESHOLD bytes (default 10240 = 10 KB) is automatically offloaded regardless of the large_output flag",
        "ORBITER_LARGE_OUTPUT_THRESHOLD env var overrides the default threshold",
        "retrieve_artifact is auto-added to all agents (since any tool could exceed the threshold at runtime)",
        "Threshold-based offloading uses the same ToolResultOffloader + Workspace path as the explicit large_output flag",
        "uv run pytest packages/orbiter-core/tests/test_large_tool_results.py packages/orbiter-mcp/",
        "Typecheck passes"
      ],
      "priority": 27,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-028",
      "title": "US-012a: MCPProgressEvent type + MCP client progress notification subscription",
      "description": "As an Orbiter streaming user, I want MCP progress notifications captured during tool calls so they can be forwarded as stream events without polluting the LLM context.",
      "acceptanceCriteria": [
        "Add MCPProgressEvent to orbiter-core/src/orbiter/types.py as a StreamEvent subtype with fields: tool_name: str, progress: int, total: int | None, message: str",
        "In orbiter-mcp/src/orbiter/mcp/client.py, subscribe to notifications/progress messages during call_tool() for all transport types (stdio, SSE, streamable-http)",
        "Captured progress notifications are stored in an asyncio.Queue rather than returned as part of the tool result",
        "MCPToolWrapper.execute() returns only the final tool result — progress notifications never appear in the result string",
        "The progress queue is accessible to the agent runner for draining during agent.stream()",
        "uv run pytest packages/orbiter-mcp/tests/test_progress.py",
        "Typecheck passes"
      ],
      "priority": 28,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-029",
      "title": "US-012b: Wire MCPProgressEvent into agent.stream() output",
      "description": "As an Orbiter streaming user, I want MCPProgressEvent items yielded from agent.stream() as they arrive so I can display real-time MCP tool progress to users.",
      "acceptanceCriteria": [
        "During agent.stream(), drain the MCPToolWrapper progress queue after each tool call and yield MCPProgressEvent items to the caller before continuing",
        "MCPProgressEvent is NOT yielded during agent.run() — only during agent.stream()",
        "The final tool result (not progress notifications) is what gets added to the agent's message history and sent to the LLM",
        "Example usage: async for event in agent.stream('search'): isinstance(event, MCPProgressEvent) is True for progress items, isinstance(event, TextEvent) is True for LLM text",
        "uv run pytest packages/orbiter-mcp/tests/test_progress.py packages/orbiter-core/",
        "Typecheck passes"
      ],
      "priority": 29,
      "passes": false,
      "notes": ""
    }
  ]
}
